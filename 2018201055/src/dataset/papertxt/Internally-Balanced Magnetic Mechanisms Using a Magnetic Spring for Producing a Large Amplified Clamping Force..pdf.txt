2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Reinforcement Learning for Adaptive Illumination with X-rays
Jean-Raymond Betterton1, Daniel Ratner2, Samuel Webb2, and Mykel Kochenderfer1
Abstract—We propose a learning algorithm for automating the time elapsed increases with the number and overall
image sampling in scientiﬁc applications. We consider settings quality of the measurements, we seek to learn a policy that
whereimagesaresampledbycontrollingaprobebeam’sscan-
trades off image reconstruction quality with elapsed time.
ningtrajectoryovertheimagesurface.Weexplorealternatives
Furthermore, we desire for our method to be compatible
to obtaining images by the standard rastering method. We
formulate the scanner control problem as a reinforcement with black box image quality metrics, image reconstruction
learning (RL) problem and train a policy to adaptively sample algorithms, and path planning algorithms that take a set of
only the highest value regions of the image, choosing the points to visit for a speciﬁed time as input. The ﬁrst two
acquisition time and resolution for each sample position based
compatibilities are to make the approach general while the
on an observation of previous readings. We use convolutional
latter compatability is to abstract away the complexity of
neural network (CNN) policies to control the scanner as a
way to generalize our approach to larger samples. We show path planning across large images.
simulation results for a simple policy on both synthetic data Wefocusonx-rayﬂuorescenceimaging(XRF)toevaluate
and real world data from an archaeological application. our methodology. For XRF, the duration of a raster scan
scales as the 4th power of pixel size when using an aper-
I. INTRODUCTION
ture to govern resolution. Several XRF imaging beam lines
In image sampling applications, we take measurements
are employed to perform a variety of raster-based imaging
of an unknown image with the goal of collecting a set of
techniques. Many of these beam lines cover a large range of
measurementssufﬁcienttoreconstructtheimagewhilemini-
analysis pixel sizes, from microns to hundreds of microns
mizingthecostofmeasurementcollection.Typically,images
[1]. The experiment rasters the sample across the incident
are formed by ‘raster’ scanning an analysis beam across a
x-ray beam and collects the XRF spectrum at each pixel in
sample pixel-by-pixel. There are a wide range of different
theimage.Differentelementsinthesampledisplaydifferent
raster-based imaging techniques that are applied across a
characteristic ﬂuorescence lines that can be used to quantify
variety of scientiﬁc applications for these purposes. Exam-
theconcentrationofelementsinthepixel.TheXRFspectrum
plesincludex-rayﬂuorescenceimaging,laserablationmass-
canbeintegratedoverregionsofinterestorﬁtdirectlyusing
spectrometry,secondaryionmass-spectrometry,andelectron
ﬁrstprinciples[2]toextractthisinformation.Whiletheraster
probemicroanalysistonameafew.Duetotheextremespar-
method has existed for some time [3], [4], and has been
sity encountered in scientiﬁc samples, the raster approach
extended to cover more extensive analyses (e.g. imaging at
is often suboptimal. For example, for particle detection, a
a series of selected excitation energies to extract chemical
large fraction of the pixels may be uninformative. Instead,
information [5], [6], [7], [8]), the data collection process is
by adaptively changing the resolution during the scan, it is
slow, and much of that time is spent in areas where there is
possible to focus the costly high resolution measurements
limited signal, or signal of limited scientiﬁc interest.
on only the highest value portions of the sample. While
Several analytical approaches have been implemented to
it is possible to manually adapt experimental parameters
try to overcome some of the drawbacks of raster imaging.
during acquisition, human intervention is typically slow and
These have included measuring the data on continuous
handwrittenalgorithmsarecostlytodevelopandoftenmust
straight trajectories [9], [10], [11], [1], arbitrary or circular
be rewritten for each new application. Therefore, general
trajectories [12], [13], [14], as well as Lissajous scanning
algorithms that can automate the measurement collection
[15]. While these approaches improve scan speeds by mini-
process are of value.
mizing the changes in raster accelerations, the overall dwell
In this paper, we use reinforcement learning to control
timespentonanygivenpixelistypicallythesame,nomatter
a probe beam using acceleration and aperture controls to
the level of signal or interest.
adaptively probe a sample. We must balance two competing
Our work follows most directly from previous works that
objectives. The ﬁrst objective is to collect a high quality set
use reinforcement learning to do active learning [16], [17],
ofmeasurementsthatcanbeusedtocreateahighresolution
[18], [19]. The main difference in our work is that we adapt
estimate of the sample scanned. The second objective is to
the methodology to imaging applications.
minimize the time required to collect measurements. Since
Ourapproachisalsorelatedtopreviousworksonadaptive
sampling methods for images. Within the compressive sens-
1 Authors are with the Department of Computer Science, Stanford
University.[jbetterton, mykel]@stanford.edu. ingliterature,algorithmsexistthatcanrecoversparseimages
2 Authors are with the SLAC National Accelerator Laboratory. using fewer measurements than suggested by the Nyquist-
[dratner, samwebb]@slac.stanford.edu.
Shannon sampling theorem [20], [21], [22]. Amongst these,
This work was partially supported by the SLAC National Accelerator
Laboratory. the adaptive algorithms are often referred to as active learn-
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 328
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. ing or adaptive sampling algorithms [23], [24], [25], [26], II. BACKGROUND
[27], [28], [29], [30], [31]. These works are similar in that
A. Reinforcement Learning
theyseektoidentifythemostvaluablemeasurementstotake
Reinforcement learning considers the problem of training
for the purposes of reconstructing an image. However, the
anagenttomakedecisionsunderuncertaintythatmaximizes
problem we investigate here differs in the following three
anobjective[34].Inreinforcementlearning,theagentlearns
ways.First,insteadofstartingwithadataselectioncriterion,
we seek to learn a heuristic criterion for choosing data a function, π, that takes as input the current observation
points, which in our case, depends on a training image data of the environment,(cid:80)st, and outputs an action at. At every
set and the choices of image reconstruction algorithm and timestep, the agent receives a reward signal rt. The policy π
istrainedtomaximizetheexpected,weightedsumofrewards
image quality metric. Second, while prior adaptive sampling
algorithms optimize the number of measurements taken, in overanepisode,Eπ[ Nt=0γtrt],whereγisthediscountrate.
this work, we optimize the cumulative time spent collecting
B. X-ray Imaging
measurements, a function of individual measurement expo-
sure times and the path that the XRF beam takes across The general setting is to scan an X-ray beam across a
the sample surface. Third, we desire a method that requires sample, taking measurements pixel by pixel. Measurements
minimalcomputationbetweenmeasurements,particularlyfor can be as simple as transmission intensity, or as complex
large images. as measuring a full 2-D spectrum (energy-in, energy-out)
at each pixel. Here, we consider a simple example of a
singlescalarmeasuredateachpixel.Inthissetting,theaper-
Adaptive acquisition is gaining traction in x-ray applica-
ture controls resolution. Using aperture rather than focusing
tions.Onerecentexampleusesdeeplearning[31].Anadap-
means X-ray intensity scales as the area of the aperture,
tivesamplingmaskgeneratingnetworkandimageinpainting
requiring longer exposure for the same signal to noise ratio.
network are trained end to end and tested in XRF applica-
1) ImageMeasurementDeﬁnitions: Considera2Dimage,
tions. The mask generating network takes an accompanying ×
v, with dimension n n . Let n be the number of pixels
RGBimageasinput.Ourapproachdiffersinthatweassume h w
in image v where n=n n . We assume that we can take a
no initial measurements; the only input to our algorithm at h w
measurement at one of the n pixel locations with one of m
runtime is the history of previous measurements. Secondly,
different apertures. Each aperture takes measurements at a
ouralgorithmcollectsmeasurementsovermultipletimesteps
different resolution as explained below. Let r be the radius
with multiple resolutions, and we vary the exposure time k
of the kth aperture with r decreasing with k. We deﬁne
for each measurement. A second recent work uses Kriging, k { (cid:48) (cid:48) |(cid:107) −
a neighborhood function neigh (i,j) = (i,j ) (i,j)
a form of Gaussian process regression, to guide sampling (cid:48) (cid:48) (cid:107)(cid:80)≤ } k
(i,j ) r , for some norm (e.g. L or L∞). The
at a synchrotron [30]. Here, Kriging both reconstructs the k 2
noiseless reading for aperture k at pixel coordinate (i,j) is
image from measurements and quantiﬁes uncertainty over
pixel values, guiding future measurements. Our approach zijk = (i(cid:48),j(cid:48))∈neigh (i,j)vi(cid:48)j(cid:48).
Whentakingmeaskurements,ourreadingsareperturbedby
differsinthatwedirectlytraintheRLalgorithmonsimulated
noise.Letxbea3Dtensorwherex istheexposuretimeat
and archived data, allowing the solution to learn arbitrarily ijk
pixel coordinate (i,j) with aperture k. Let y be a 3D tensor
complex priors.
where y is the observed measurement at coordinate (i,j)
ijk ∼
withaperturek.Wehavethaty Poisson(x (z +c ))
ijk ijk ijk k
AnotherrelatedresearchareaisInformativePathPlanning for some noise constant c as a function of k.
k
(IPP) [32]. Past research has focused on problems where
2) Generating Measurements from Scanner Controls:
an agent must plan a path in order to optimally collect
Sincethepositionofthebeamiscontrolledwithacceleration
measurements while minimizing travel time or another re-
inputs, for some desired set of exposure times x, we must
lated cost. Within this literature, our approach is similar to
generate a trajectory, τ, with the beam such that the beam
approaches that choose which points to measure ﬁrst, and
visitsthesetoflocationsoftheimageforthetimesspeciﬁed
then determine the path that will visit those points [33].
by x. From here, we let the set of measurements generated
However, our approaches differ both in application and in
by trajectory τ be g(τ). If we desire to execute exposure
methodology for selecting which points to measure.
times x, we must select a trajectory, τ, such that g(τ)=x.
In addition, switching between apertures causes a short
Ourmaincontributionsare1)ageneralformulationofthe delay during which the beam cannot collect measurements
measurementcollectionproblemasareinforcementlearning which we must account for when planning a trajectory. We
problem that abstracts away the low level controls of the denotethetotaltimecostofasetofmeasurements,asL (τ).
C
scanner itself, 2) a convolutional neural network policy that 3) ImagingObjectivesandProblemFormulation: Wecol-
enablesourpoliciestogeneralizetoimagesofarbitraryshape lectmeasurementstooptimizetwocompetingobjectives.Let
and scale, and 3) a set of implementation techniques that f be an image reconstruction function such that f(x,y)=vˆ
can be used for solving the reinforcement learning problem, is an estimate of the image, v. For our ﬁrst objective, let
achievingperformanceabovearasterbaselinewhilepreserv- L (v,vˆ)=L (v,f(x,y)) be a loss function that decreases
Q Q (cid:107) − (cid:107)
ing computational efﬁciency. asthequalityofvˆincreases,thatis,as v vˆ approaches0.
329
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. −
Our second objective is L (τ), the time cost for following We perform at most m 1 aperture switching operations
C
a trajectory to generate exposure times x=g(τ). per episode, as opposed to arbitrarily many switches per
If we consider a distribution over images v, and recall action. Although this makes our solution less general, pro-
∼
y Poisson(g(τ) (z +c)), a nonadaptive version of gressingfromlowresolutiontohighseemstobeareasonable
ijk ijk ijk
the problem is restriction in practice and reduces the complexity of the
solution space. Since exposure times can only be output for
min E[L (v,f(g(τ),y))+λL (τ)] (1)
τ Q C at most one aperture at a time, the policy outp∗ut, at, need
for some hyperparameter λ>0 that controls how much we only be two dimensional to specify a desired x˜ . Also, note
t
favor scan speed over image reconstruction quality. thatwiththesechanges,wemuststillhavesomemechanism
for switching apertures.
III. METHODOLOGY ∗
We deﬁne h such that x˜ =h(a ,t) where a is of shape
A. Reinforcement Learning Formulation n × n . Let h˜ be a funtction dteﬁned suchtthat h˜(t) is
h w
In this section, we present a reinforcement learning prob- the aperture to use at timestep t. Then, we specify that
∗
lem formulation that abstracts away the low level accelera- h(a ,t) =(x˜ ) =(a ) fork =h˜(t)andh(a ,t) =
∗t ijk t ijk (cid:54) t ij t ijk
tion and aperture switching controls of the scanner. (x˜ ) = 0 for k = h˜(t). In this work, apertures are
t ijk
1) Sequential Decision Formulation: To solve the prob- switched after each timestep, that is h˜(t) = t. We leave
lemfromtheprevioussectionadaptively,wecanreformulate the exploration of deﬁning or learning more complex h to
it as a sequential decision problem where at every timestep future work.
t, we observe all previous measurements and then choose a 4) RL Problem Formulation: Now, suppose that we have
new set of measurements to take at the next timestep. an imaging problem, where we have chosen a distribution
At each timestep t, let x be the cumulative acquisition over images v, image reconstruction function f, aperture
t
time tensor up to timestep t, and y the cumulative sensor switching schedule h, trajectory planner q, image quality
t
readingtensoruptotimestept.Then,letτ bethetrajectory metric L , trajectory cost metric L , and cost tradeoff
t Q C
to execute at timestep t. Let x˜ = g(τ ) be the set of hyperparameter λ. Then, our original imaging problem can
t t
(cid:88)
exposure times at time t, deﬁned such that x =x +x˜ , be rewritten as a sequential decision problem
t+1 t t
and similarly, let y˜ be the read values from measurements
t T
taken at time t, such that y = y + y˜. Note that
∼ t+1 t t min E [L (v,f(x ,y ))+λ L (q(h(π(s ),t))]
since (y˜) Poisson((x˜ ) (z + c)), we have that π v,y Q T T C t
t ∼ijk t ijk ijk t=1
(y ) Poisson((x ) (z +c)) (2)
t+1 ijk t+1 ijk ijk
We deﬁne the problem state to be s = (x ,y ). At each for some number of timesteps T >0.
t t t
timestep, we must select τ . Let π be a policy function and Inprinciple,wecansolvethesequentialdecisionproblem
t
let the action a = π(s ). Rather than having π directly with a reinforcement learning algorithm. Let L(x ,y ) =
t t t t
output τ , we instead compute it as τ = q(h(a ,t)). Here, L (v,f(x ,y )) + λL (q(h(a ,t))). Then, let r =
t t t −Q t t −C t − 1 ∈
h and q are both functions designed with the purpose of L(x ,y ), and r = (L(x ,y ) L(x − ,y − )), t
{ 1 1} t t t t 1 t 1
abstractingawaylowlevelapertureandaccelerationcontrols 2,...,T where T is the total number of steps in the
as explained in the following two subsections. episode. We can express Equation 2 explicitly as a rein-
∗
2) Managing Acceleration Constraints: Let x˜ be some forcementlearningproblemwithstates,actions,andrewards
t (cid:80)
set of exposure times that we desire to collect. We introduce deﬁnedrespectivelyass ,a ,andr .Notethat,ifwesetthe
t t t
a function q that takes as input some desired set of exposure RL discount rate, γ, equal to 1, then the sum of rewards
∗ −
times x˜ and produces a trajectory τ . we seek to maximize, T r , is equal to L(x ,y ), the
t t t=1 t T T
In general, we assume that q is a search algorithm that negative of the loss function we are attempting to minimize.
searches over feasible trajectories for a trajectory such that
∗ B. Convolutional Policy Design
the resulting set of measurement times x˜ = g(q(x˜ ))
(cid:107) ∗− (cid:107) t t∗ ×
approximately minimizes x˜ x˜ . By letting τ =q(x˜ ), Sincea isofshapen n ,thereareafewissues.First,
t t t t t h w
we abstract away the low level acceleration controls and the shape of a varies with v. Since we sample a v every
∗ t
focus on outputting desirable sets of measurement times x˜ . episode, each episode may require a different shaped output
t∗
3) Managing Aperture Switches: Even if we output x˜ , and in general, we would like our policy π to generalize
t
there is still the complication of determining when to switch to v of arbitrary shape. A second issue is that, even for
apertures. Discussed previously, switching apertures causes relatively small images, a is very high dimensional which
t
adelaywheremeasurementscannotbecollected.Wereduce may lead to difﬁculty or infeasiblity when it comes to doing
the complexity of the problem by constraining our actions reinforcement learning.
∗ ∗
inthesequentialproblemthroughx˜ .First,werestrictx˜ to In order to address these potential issues, we let the
t t
onlycontainnonzeroexposuretimesforatmostoneaperture target exposure time for a pixel be a function of the local
at a time. Second, we constrain the policy to progress from observation around that pixel. This addresses the scaling
∗
low resolution to high. Hence, (x˜ ) can only be nonzero issue as the policy output for each pixel is a function of
∗t ijk
for a single value of k and if (x˜ ) is nonzero, then, for a local region of ﬁxed size. This also addresses some of the
(cid:48) ∗ t ijk (cid:48) ≥
t >t, (x˜t(cid:48))i(cid:48)j(cid:48)k(cid:48) can only be nonzero for k k. issues with the dimensionality of at as now the complexity
330
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. of π scales with the size of the local observation that we row from left to right, otherwise from right to left. With the
consider. To do this, we elect to use convolutional neural orderofmeasurementstoacquireﬁxed,wethenseektoﬁnd
network [35], [36] policies where the size of the receptive a feasible trajectory that approximately minimizes the total
ﬁeld dictates the size of the local observation that we use. required time to visit the pixels in that order for at least as
We only consider CNN architectures that preserve the long as is speciﬁed by a. For this, we can plan for each
dimensionality of the input in the ﬁrst two dimensions. That row independently of the others. For each row, we solve
× ×
is, our policy function takes an input of shape n n n thisproblemapproximatelywithaniterativemethod.Onthe
h w f
where n is the number of input features for each pixel ﬁrstiteration,weconsiderthepixelwiththelongestspeciﬁed
f
location derived from s . The policy function outputs an exposure time, requiring the slowest speed to measure. We
× t
action of shape n n , an approximate exposure time for calculate the maximum speed that we can achieve over the
h w
each pixel location at the current aperture, as desired. two adjacent pixels that still enables the scanner to slow
down enough to fulﬁll the original point and the original
C. Efﬁcient Implementation
speciﬁed exposure time. We adjust the exposure times of
Depending on f, the cost of reconstructing an image and the left and right neighbors to reﬂect this maximum speed if
calculating the reward function can bottleneck our training theircurrentspeedisfaster.Oneachsubsequentiteration,we
algorithms. One way to reduce the computational cost of consider the point with the next longest speciﬁed exposure
image reconstruction is to limit the size of the images time and repeat. In this way, we can construct a feasible
processed. We train with smaller images to reduce the trajectory and generate approximate exposure times for that
computation time required for each individual episode. We trajectory.
found this to be very beneﬁcial for computational efﬁciency
during our experiments. B. Training Image Data and Aperture Pairings
A second way to reduce the cost of image reconstruction We refer to the ﬁrst environment as the sparse environ-
×
is through approximation. We may use a fast approximation ment.Eachimageis20 20.Threerandompixelsarechosen
of f, call it fˆwhen estimating our reward values. We note to have a value of 1 while all the remaining pixels are
thatalthoughwedonotdemonstratethisinthecurrentwork, assigned avalue of 0. Thebackground noiseis Poisson with
it is an interesting area for future work. alevelof0.1.Inthisenvironment,ourscannerhasaccessto
A third way we can improve computational efﬁciency three square shaped apertures corresponding to resolutions
× × ×
is by evaluating the reward signal less frequently as each of 1 1, 3 3, and 5 5 pixels. We train with λ values of
× − × − × − × −
reward signal requires an image reconstruction. This leads 1 10 4, 1 10 3, 1 10 2, 1 10 1, and 1.
to a tradeoff between density of rewards and faster runtimes Oursecondenvironmentiscalledthecheckerboardtexture
×
for simulations. In our experiments, we only evaluate the environment. Each image is 20 20 and ﬁlled with a
cumulative reward over the entire episode at the end. random number of randomly generated shapes. The number
of random shapes is drawn from a Poisson distribution with
IV. EXPERIMENTS
mean equal to 1. Each shape is assigned a random base
A. Simulation Environment
signal that is uniformly sampled between 0 and 1. Then,
WereconstructallimagesusingL-BFGS[37]tominimize a checkerboard mask of the image is taken and all pixels in
the weighted sum of the negative log likelihood of the the mask have their value reduced by a factor of 2. The
reconstructed image given the collected measurements and background noise is Poisson with a level of 0.1. In this
(cid:80) (cid:80)
a TV regularizer. We evaluate image quality using the Mean environment, our scanner has access to three square shaped
× ×
Squared Error (MSE) between the reconstructed and ground apertures corresponding to resolutions of 1 1, 3 3, and
− × × − × −
truthimages.Thatis,L (v,vˆ)= 1 nh nw (v vˆ )2. 5 5 pixels. We train with λ values of 1 10 6, 1 10 5,
Q n i=1 j=1 ij ij × − × − × −
All environments impose constraints on the maximum ve- 1 10 4, 1 10 3, and 1 10 2.
locity (200mm/s) and maximum acceleration (500mm/s2) In our third environment, the realistic environment, each
×
of the XRF beam. Every pixel is square shaped with a image is a 50 50 patch sampled from a small dataset
side length of 0.02mm. We assume that, in practice, the of 17 real XRF images. The image signal levels range
images we scan will be large such that the maximum cost between 0 and 26 with an average value of approximately
−
of switching apertures at most m 1 times is negligible, 0.5 and a background Poisson noise level of 1.5. In this
(cid:80) (cid:80) (cid:80)
therefore we do not account for aperture switching costs environment,ourscannerhasaccesstoﬁvecircularapertures
during these experiments and we set L equal to the total with diameters of 1, 2.5, 7.5, 20, and 50 pixels respectively.
C
elapsed time, where L (x)= nh nw m x . We train with λ values of 10, 100, and 1000.
C i=1 j=1 k=1 ijk
All environments make use of the same q function for
C. Methods
transforming arbitrary sets of exposure times speciﬁed by
h(a,t)torealtrajectoriesq(h(a,t)).Forthis,weﬁrstﬁxthe 1) Rastering Baseline: We compare our learned policies
order in which each measurement is taken. Recall that the to a baseline based on rastering, a technique where we use
∈{ }
rows of the image are indexed with i for i 1,2,...,n . one ﬁxed aperture and every pixel is measured for the same
h
We proceed one row at a time from i = 1 to i = n . amount of time with the aperture of choice. We considered
h
For row i, if i is odd, we take the measurements in that other heuristic methods, such as randomized scans, however
331
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. Sparse on Training Images Texture on Training Images Realistic on Training Images
· − · −
10 3 10 3
8 Adaptive 3 Adaptive 0.3 Adaptive
Raster Raster Raster
E 6 E 2 E 0.2
S S S
M 4 M M
1 0.1
2
0 0 0
0 0.2 0.4 0 0.2 0.4 0.6 0 0.1 0.2
Seconds per Pixel Seconds per Pixel Seconds per Pixel
Sparse on New Images Texture on New Images Realistic on New Images
· − · −
10 3 10 3
0.1
Adaptive Adaptive · − Adaptive
1.5 1.5 8 10 2
Raster Raster · − Raster
E E E 6 10 2
S 1 S 1 S · −
M M M 4 10 2
0.5 0.5 · −
2 10 2
0 0 · − 0
0 0.1 0.2 0 5 10 2 0.1 0 2 4 6 8
Seconds per Pixel Seconds per Pixel Seconds per Pixe·l10−2
Fig.1:Thisplotshowseachsamplingmethod’smeansquarederrorversustimecurve.Fortheadaptivepolicies,thetoprow
showsperformancewithinthetrainingenvironment,thebottomrowshowsperformanceoutsideofthetrainingenvironment,
and each column corresponds to a different training environment for the adaptive policy. Also, each point in the plot
corresponds to a model trained with a different λ value. We compare the adaptive policies to raster scans at all available
resolutions that scan for the same average time per pixel. Only the best performing raster baseline is depicted.
Original Image Adaptive Image Raster Image Adaptive Exp 1 Adaptive Exp 2 Adaptive Exp 3
0 0.5 1 0 0.2 0.4 0.6 0 2 4 6
0 0.5 1 0 0.2 0.4 0.6 0 2 4
Fig. 2: This plot shows the reconstructed images for the learned adaptive policy trained in the texture environment with
× −
λ=1 10 4 sidebysidewiththehighestresolutionrasterbaselinesettoscanforthesameamountoftimeastheadaptive
method. The ﬁrst row shows the performance on the texture environment data. The second row shows the performance of
the same policy applied to a real image. Progressing from left to right, the columns depict the original image, the adaptive
reconstruction, the highest resolution raster reconstruction, and the exposure times with aperture 1, aperture 2, and aperture
3 for the adaptive method. The colorbars for the exposure time plots indicate seconds per pixel spent in each region.
these were either on par with or dominated by the raster information is lost and learned behavior is likely to be
baseline.Techniquesbasedoncompressivesensingandprior suboptimal in general, we found the reduction in the size
learningbasedapproachesmaybeapplicable,butwillrequire of s helpful and noted no signiﬁcant drop in performance
t
dedicated research in the future to adapt to this problem when compared to s = (x ,y ), likely due to simplicity in
t t t
formulation. our policy architectures.
2) Proposed Method: In this work, we use a simpliﬁed For our policy architecture, we use a combination of m
× ×
observation s = y with shape n(v) n(v) m. Although CNNs,referredtoasπ .Eachπ controlsoneofthemaper-
t t h w k k
332
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. × −
tures. Since we switch apertures after each timestep, we use in the texture environment with λ = 1 10 4 in addition
a different π each timestep. More formally π(s )=π (s ). to a visualization of where the learned policy spent its time
k t t t
For these experiments, we design the π CNN architectures scanning. These results show that we can learn to perform
k
to be minimalistic while still maintaining a receptive ﬁeld at well on new images drawn from the same distribution that
least as large as the aperture being controlled. We found it we trained on.
helpful to manually convolve (s ) with a binary mask 2) Performance outside Training Environments: We also
t :,:,k
of 1s in the shape of the kth aperture, the aperture that test the performance of policies on data that is from a
collected the measurements. Although a similar operation different distribution than the training data. In this setting
×
can also be learned by a more complex CNN, we found all images are larger at size 100 100. Each policy is tested
this to be a helpful preprocessing step for our minimalistic on 1000 new images.
architectures.Withthispreprocessingexpandingtheeffective For the policies trained in the simple environment, the
receptive ﬁeld, each CNN, π , is comprised of a single large images are generated such that a random number of
k ×
convolutional layer with a receptive ﬁeld of just 1 1, a randomly selected pixels have value 1 while the rest have
ReLunonlinearity,andacustomizedsparsityenforcinglayer. value 0. The number of pixels is Poisson with mean 10.
The sparsity layer is controlled by two additional weights For the policies trained in the checkerboard texture envi-
×
that control the spacing of measurements horizontally and ronment, the large images are selected as random 100 100
vertically. Conceptually, the weights control the length and patches from a hand-selected set of 15 real images from
×
width of a rectangular window with shape w w . The XRFapplications(Figure2).Theimageswereselectedtobe
h w
image is then divided into nonoverlapping tiles of shape similar to the texture environment data in terms of sparsity.
×
w w . Finally, all measurements values within a tile For the policies trained in the realistic environment, we
h w ×
are concentrated into the center of the tile. In this way, again sample 100 100 patches from a set of 4 sparse,
larger windows lead to sparser measurements. Window size real images from XRF applications. These images were not
×
islim√itedtob√enolargerthan2r 2r forsquareapertures included in the training set.
× k k
and 2r 2r for circular apertures. In the results we show here, we found that the learned
k k
Since we only use one aperture per step and proceed in adaptive policy was able to outperform all baseline rastering
order from low resolution to high, by the time we use π policiesacrossallλvalues,showingthepotentialforpolicies
× × k+1
only a subset of the input of shape n(v) n(v) k can be to generalize to new image distributions. A plot showing
h w
nonzero. Therefore, the π policy functions progressing in the average MSE and time spent scanning is shown in
k
order from low resolution to high, have k+3 weights each. Figure 1. Figure 2 shows an example image reconstruction
Forthesparseandtextureenvironmentwith3apertures,this and exposure time visualizations for a policy trained in the
× −
correspondstoatotalof15weightswhilethepoliciesinthe texture environment with λ=1 10 4.
realistic environment train a total of 30 weights. It should be noted that in some preliminary trials not
We use Evolution Strategies [38] as our policy learning shown here, we did not always observe the adaptive method
algorithmbutwithrewardsreplacedbyﬁtnessshapingvalues outperforming baselines on new image distributions. We
[39]. For both environments, we set step size α = 1 and foundthathowwellthelearnedpolicygeneralizedseemedto
population variance σ = 1 and ran for 500 iterations. Per dependonthedegreeofsimilaritybetweenthesparsitylevels
iteration, we sample 20 sets of policy weights and evaluate of the two image distributions. We believe that the extent to
each one on 20 episodes. Since Evolution Strategies is which policies can generalize to new distributions of images
unaffectedbysparserewards,weonlyevaluatetherewardat is highly domain speciﬁc and could be an interesting topic
theend ofeachepisode topreserve computationalefﬁciency for future work.
as image reconstructions are relatively costly operations.
Lastly, we found that a policy of collecting no measure- V. CONCLUSIONANDFUTUREWORK
mentsinsomecasesbehavedasalocaloptimathatprevented These results demonstrate that reinforcement learning is a
exploration to better policies. To counter this effect, we viable framework for generating adaptive sampling policies
augment the reward signal with a relatively large constant for images in XRF applications. Our experiments show that
penalty for each pixel that is not measured by the scanner. the method can outperform simple raster policies on both
synthetic and real data using policy architectures containing
D. Results
relatively few weights. Our approach is compatible with
1) Performance within Training Environments: After black box image reconstruction functions, image quality
training, we test each model within the environment it was metrics, and trajectory generating functions.
trained on. Each model is tested on 1000 new images from For future work, we believe that several of the modular
its training environment. components of this framework can be further developed.
In all three environments, we found that the learned Some examples include exploring more complex image
adaptive policy was able to outperform all baseline rastering quality metrics, image reconstruction processes, and path
policiesacrossalllambdavalues.Aplotshowingtheaverage planning algorithms. Further, with more complex policy ar-
MSEandtimespentscanningisshowninFigure1.Figure2 chitecturesandrichertrainingdata,futureworkmayproduce
shows an example image reconstruction for a policy trained policiesthatexploitmorecomplexpatternsintheimagedata.
333
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. REFERENCES learning,” CoRR, vol. abs/1806.04798, 2018. [Online]. Available:
http://arxiv.org/abs/1806.04798
[1] N.P.Edwards,S.M.Webb,C.M.Krest,D.vanCampen,P.L.Man-
[18] P. Bachman, A. Sordoni, and A. Trischler, “Learning algorithms for
ning, R. A. Wogelius, and U. Bergmann, “A new synchrotron rapid-
active learning,” in International Conference on Machine Learning,
scanning x-ray ﬂuorescence (SRS-XRF) imaging station at SSRL
06–11Aug2017,pp.301–310.
beamline 6-2,” Journal of Synchrotron Radiation, vol. 25, no. 5, pp.
[20] E.J.Candes,J.Romberg,andT.Tao,“Robustuncertaintyprinciples:
1565–1573,2018.
exact signal reconstruction from highly incomplete frequency infor-
[2] V. Sole´, E. Papillon, M. Cotte, P. Walter, and J. Susini, “A multi-
mation,” IEEE Transactions on Information Theory, vol. 52, no. 2,
platformcodefortheanalysisofenergy-dispersivex-rayﬂuorescence
pp.489–509,Feb2006.
spectra,” Spectrochimica Acta Part B: Atomic Spectroscopy, vol. 62,
[21] E. J. Candes and M. B. Wakin, “An introduction to compressive
no.1,pp.63–68,2007.
sampling,”IEEESignalProcessingMagazine,vol.25,no.2,pp.21–
[3] K. Jones, W. Berry, D. Borsay, H. Cline, W. Conner Jr, and
30,2008.
C.Fullmer,“Applicationsofsynchrotronradiation-inducedx-rayemis-
sion(SRIXE),”X-RaySpectrometry:AnInternationalJournal,vol.26, [22] D. L. Donoho, “Compressed sensing,” IEEE Transactions on Infor-
no.6,pp.350–358,1997. mationTheory,vol.52,no.4,pp.1289–1306,April2006.
[4] Z.Cai,B.Lai,W.Yun,I.McNulty,A.Khounsary,J.Maser,P.Ilin- [23] D. A. Cohn, Z. Ghahramani, and M. I. Jordan, “Active learning
ski, D. Legnini, E. Trakhtenberg, S. Xu, et al., “Performance of a withstatisticalmodels,”inJournalofArtiﬁcialIntelligenceResearch,
high-resolution x-ray microprobe at the advanced photon source,” in vol.4,1994,pp.129–145.
AmericanInstituteofPhysics,vol.521,no.1. AIP,2000,pp.31–34. [24] Y. Eldar, M. Lindenbaum, M. Porat, and Y. Y. Zeevi, “The farthest
[5] J. Kinney, Q. Johnson, M. C. Nichols, U. Bonse, and R. Nusshardt, pointstrategyforprogressiveimagesampling,”IEEETransactionson
“Elemental and chemical-state imaging using synchrotron radiation,” ImageProcessing,vol.6,no.9,pp.1305–1315,1997.
AppliedOptics,vol.25,no.24,pp.4583–4585,1986. [25] D. M. Malioutov, S. R. Sanghavi, and A. S. Willsky, “Sequential
[6] S. Sutton, S. Bajt, J. Delaney, D. Schulze, and T. Tokunaga, “Syn- compressed sensing,” IEEE Journal of Selected Topics in Signal
chrotron x-ray ﬂuorescence microprobe: Quantiﬁcation and mapping Processing,vol.4,no.2,pp.435–444,April2010.
ofmixedvalencestatesamplesusingmicro-xanes,”ReviewofScien- [26] Y.C.Pati,R.Rezaiifar,andP.S.Krishnaprasad,“Orthogonalmatching
tiﬁcInstruments,vol.66,no.2,pp.1464–1467,1995. pursuit:recursivefunctionapproximationwithapplicationstowavelet
[7] I.J.Pickering,R.C.Prince,D.E.Salt,andG.N.George,“Quantita- decomposition,” in Asilomar Conference on Signals, Systems and
tive,chemicallyspeciﬁcimagingofseleniumtransformationinplants,” Computers,1993.
ProceedingsoftheNationalAcademyofSciences,vol.97,no.20,pp. [27] B.Settles,“Activelearningliteraturesurvey,”UniversityofWisconsin,
10717–10722,2000. Madison,Tech.Rep.1648,2010.
[8] L. Mayhew, S. Webb, and A. Templeton, “Microscale imaging and
[28] A. Taimori and F. Marvasti, “Adaptive sparse image sampling and
identiﬁcation of fe speciation and distribution during ﬂuid–mineral
recovery,”IEEETransactionsonComputationalImaging,vol.4,no.3,
reactions under highly reducing conditions,” Environmental Science
pp.311–325,Sep.2018.
&Technology,vol.45,no.10,pp.4468–4474,2011.
[29] Z. Devir and M. Lindenbaum, “Blind adaptive sampling of images,”
[9] A. E. Morishige, H. S. Laine, M. A. Jensen, P. X. Yen, E. E.
IEEE Transactions on Image Processing, vol. 21, no. 4, pp. 1478–
Looney, S. Vogt, B. Lai, H. Savin, and T. Buonassisi, “Accelerating
1487,April2012.
synchrotron-based characterization of solar materials: Development
of ﬂyscan capability,” in IEEE Photovoltaic Specialists Conference [30] M.M.Noack,K.G.Yager,M.Fukuto,G.S.Doerk,R.Li,andJ.A.
(PVSC),2016. Sethian, “A kriging-based approach to autonomous experimentation
[10] K. Medjoubi, N. Leclercq, F. Langlois, A. Buteau, S. Le´, S. Poirier, withapplicationstox-rayscattering,”ScientiﬁcReports,vol.9,no.1,
P. Mercere, M. C. Sforna, C. M. Kewish, and A. Somogyi, “Devel- p.11809,2019.
opmentoffast,simultaneousandmulti-techniquescanninghardx-ray [31] Q. Dai, H. Chopp, E. Pouyet, O. Cossairt, M. Walton, and A. Kat-
microscopyatsynchrotronsoleil,”JournalofSynchrotronRadiation, saggelos, “Adaptive image sampling using deep learning and its
vol.20,no.2,pp.293–299,2013. application on x-ray ﬂuorescence image reconstruction,” ArXiv, vol.
[11] M. W. Jones, N. W. Phillips, G. A. Van Riessen, B. Abbey, D. J. abs/1812.10836,122018.
Vine, Y. S. Nashed, S. T. Mudie, N. Afshar, R. Kirkham, B. Chen, [32] A.Singh,A.Krause,C.Guestrin,andW.Kaiser,“Efﬁcientinforma-
etal.,“Simultaneousx-rayﬂuorescenceandscanningx-raydiffraction tive sensing using multiple robots,” Journal of Artiﬁcial Intelligence
microscopyattheaustraliansynchrotronXFMbeamline,”Journalof Research,vol.34,pp.707–755,2009.
SynchrotronRadiation,vol.23,no.5,pp.1151–1157,2016. [33] G.A.Hollinger,B.Englot,F.S.Hover,U.Mitra,andG.S.Sukhatme,
[12] D.J.Ching,M.Hidayetog˘lu,T.Bic¸er,andD.Gu¨rsoy,“Rotation-as- “Active planning for underwater inspection and the beneﬁt of adap-
fast-axisscanning-probex-raytomography:theimportanceofangular tivity,”InternationalJournalofRoboticsResearch,vol.32,no.1,pp.
diversity for ﬂy-scan modes,” Applied Optics, vol. 57, no. 30, pp. 3–18,2013.
8780–8789,2018. [34] R.S.SuttonandA.G.Barto,ReinforcementLearning:AnIntroduc-
[13] J.Deng,C.Preissner,J.A.Klug,S.Mashraﬁ,C.Roehrig,Y.Jiang, tion. MITPress,1998.
Y.Yao,M.Wojcik,M.D.Wyman,D.Vine,etal.,“Thevelociprobe: [35] K. Fukushima, “Neocognitron: A self-organizing neural network
An ultrafast hard x-ray nanoprobe for high-resolution ptychographic model for a mechanism of pattern recognition unaffected by shift in
imaging,”ReviewofScientiﬁcInstruments,vol.90,no.8,2019. position,”BiologicalCybernetics,vol.36,pp.193–202,1980.
[14] M. Odstrcˇil, M. Holler, and M. Guizar-Sicairos, “Arbitrary-path ﬂy-
[36] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,
scan ptychography,” Optics Express, vol. 26, no. 10, pp. 12585–
W. Hubbard, and L. D. Jackel, “Backpropagation applied to hand-
12593,2018.
writtenzipcoderecognition,”NeuralComputation,vol.1,no.4,pp.
[15] K.Hwang,Y.-H.Seo, J.Ahn,P.Kim,andK.-H. Jeong,“Frequency
541–551,Dec1989.
selection rule for high deﬁnition and high frame rate lissajous scan-
[37] D. C. Liu and J. Nocedal, “On the limited memory bfgs method for
ning,”ScientiﬁcReports,vol.7,no.1,p.14075,2017.
largescaleoptimization,”MathematicalProgramming,vol.45,no.1,
[16] M.Fang,Y.Li,andT.Cohn,“Learninghowtoactivelearn:Adeep
pp.503–528,Aug1989.
reinforcement learning approach,” in Empirical Methods in Natural
LanguageProcessing,2017. [38] T. Salimans, J. Ho, X. Chen, and I. Sutskever, “Evolution strate-
[17] K. Pang, M. Dong, Y. Wu, and T. M. Hospedales, “Meta- gies as a scalable alternative to reinforcement learning,” ArXiv, vol.
learning transferable active learning policies by deep reinforcement abs/1703.03864,032017.
[19] M. Woodward and C. Finn, “Active one-shot learning,” [39] D. Wierstra, T. Schaul, T. Glasmachers, Y. Sun, J. Peters, and
CoRR, vol. abs/1702.06559, 2017. [Online]. Available: J. Schmidhuber, “Natural evolution strategies,” Journal of Machine
http://arxiv.org/abs/1702.06559 LearningResearch,vol.15,no.1,pp.949–980,Jan.2014.
334
Authorized licensed use limited to: Carleton University. Downloaded on September 19,2020 at 11:15:13 UTC from IEEE Xplore.  Restrictions apply. 