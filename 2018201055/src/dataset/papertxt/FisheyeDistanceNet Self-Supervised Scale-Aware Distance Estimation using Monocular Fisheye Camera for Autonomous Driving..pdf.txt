2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Redesigning SLAM for Arbitrary Multi-Camera Systems
Juichung Kuo, Manasi Muglikar, Zichao Zhang, Davide Scaramuzza
Abstract—AddingmorecamerastoSLAMsystemsimproves
robustnessandaccuracybutcomplicatesthedesignofthevisual
front-endsigniﬁcantly.Thus,mostsystemsintheliteratureare
tailored for speciﬁc camera conﬁgurations. In this work, we
aim at an adaptive SLAM system that works for arbitrary
multi-camera setups. To this end, we revisit several common
building blocks in visual SLAM. In particular, we propose an
adaptive initialization scheme, a sensor-agnostic, information-
theoretic keyframe selection algorithm, and a scalable voxel-
based map. These techniques make little assumption about
the actual camera setups and prefer theoretically grounded
methods over heuristics. We adapt a state-of-the-art visual-
inertial odometry with these modiﬁcations, and experimental
results show that the modiﬁed pipeline can adapt to a wide
rangeofcamerasetups(e.g.,2to6camerasinoneexperiment)
without the need of sensor-speciﬁc modiﬁcations or tuning.
Fig. 1: Multi-camera systems achieve superior performance in perception
algorithms and are widely used in real-world applications, such as omni-
SUPPLEMENTARYMATERIAL directional mapping [6], autonomous drones [5], and VR headsets [4]. To
facilitate the use of such systems in SLAM, we propose several generic
Video: https://youtu.be/JGL4H93BiNw designsthatadapttoarbitraymulti-camerasystemsautomatically.
I. INTRODUCTION commonly visible features in the current frame with respect
to the last keyframe. While this works well for monocular
Asanimportantbuildingblockinrobotics,visual(-inertial)
setups or stereo pairs with highly overlapping ﬁeld-of-views
odometry (VO/VIO), or more general, simultaneous local-
(FoV), it quickly becomes complicated as more cameras are
ization and mapping (SLAM) has received high research
added, as different cameras may have drastically different
interest. Modern SLAM systems are able to estimate the
view conditions (e.g., the number of features).
local motion accurately as well as build a consistent map
Toremovethedependenceonsensor-speciﬁcassumptions
for other applications. One of the remaining challenges for
andheuristics,weresorttoadaptiveandmoreprincipledso-
vision-based systems is the lack of robustness in challeng-
lutions. First, instead of using hard-coded rules, we propose
ing environments, such as high dynamic range (HDR) and
anadaptiveinitializationschemethatanalyzesthegeometric
motion blur [1]. Among different approaches that have been
relation among all cameras and selects the most suitable
explored for better robustness (e.g., [2] [3]), adding more
initialization method online. Second, instead of engineering
cameras in SLAM systems proves to be effective and is
heuristics, we choose to characterize the uncertainty of the
already exploited in successful commercial products, such
current pose estimate with respect to the local map using
as Oculus Quest [4] and Skydio [5].
the information from all cameras, and use it as an indicator
As the workhorse for modern (keyframe-based) SLAM
of the need for a new keyframe. Third, instead of relying
systems,bundleadjustment(BA)likenonlinearoptimization
on the covisiblity graph, we organize all the landmarks in a
naturally generalizes to multiple sensors, including visual-
voxel grid and sample the camera frustums via an efﬁcient
inertial and multi-camera systems, as long as the measure-
voxel hashing algorithm, which directly gives the landmarks
ment process is modeled correctly. On the other hand, the
within the FoVs of the cameras. These methods generalize
design of the so-called front-ends is much less theoretically
well to arbitrary camera setups without compromising the
grounded. Many details, such as initialization, keyframe
performance for more standard conﬁgurations (e.g., stereo).
selection, and map management, are designed heuristically.
Moreover, such designs are often tailored to speciﬁc sensor Contributions: To summarize, the contribution of this
setups, and it is not clear to what extent they can be work is an adaptive design for general multi-camera
applied to more general sensor conﬁgurations. For example, VO/VIO/SLAM systems, including
one popular method for selecting keyframes is to consider • an adaptive initialization scheme,
• asensor-agnostic,information-theoretickeyframeselec-
The authors are with the Robotics and Perception Group, Dep. of
tion algorithm,
Informatics,UniversityofZurich,andDep.ofNeuroinformatics,University
ofZurichandETHZurich,Switzerland—http://rpg.ifi.uzh.ch. • a scalable, voxel-based map management method.
This research was supported by the National Centre of Competence in
Since the proposed method is not limited to speciﬁc im-
Research(NCCR)Robotics,throughtheSwissNationalScienceFoundation,
theSNSF-ERCStartingGrantandSonyR&DCenterEurope. plementations or sensing modalities, we will use the term
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 2116
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. SLAM in general for the rest of the paper.
Thepaperisstructuredasfollows.InSectionII,wereview
the common methods for initialization, keyframe selection,
and map management in visual SLAM. In Section III, we
describe our adaptive initialization process based on overlap
check. In Section IV, we detail our entropy-based keyframe
selection algorithm. In Section V, we introduce our voxel-
basedmaprepresentationforvisiblepointsretrieval.Finally,
we apply our method to a state-of-the-art VIO system and Fig.2:Anillustrationofthestereooverlappingcheckbetweentwocameras,
present the experimental results in Section VI and conclude Ci and Cj. The blue stars are the sampled points on the image plane of
camerai.Thegreenstarsarethe3Dpointsthataresuccessfullyprojected
our work in Section VII. tocameraj,andtheredonesarethepointsthatfalloutoftheimageplane.
II. RELATEDWORK condition makesthe tracking against oldkeyframes difﬁcult.
Hence, [13] also uses the relative brightness as a criterion.
A. Initialization
Usingthecombinationofdifferentheuristicsusuallyrelies
The initialization in SLAM typically incorporates as- on certain assumptions of the sensor conﬁgurations and
sumptions that are speciﬁc to camera conﬁgurations. For scenes, which makes parameter tuning as well as the ap-
monocular systems, homography and 5-point relative pose plication to general multi-camera setups complicated.
algorithm from [7] are popular ways to obtain the poses of 2) Information-theoreticmethods: Thesemethodsrelyon
the ﬁrst two keyframes and the initial map (e.g., [8]), which more principled metrics and are less common in literature.
usually requires the camera to undergo certain motion, such Dasetal.[15]chosethekeyframestobeincludedintheBA.
as strong translation and no pure rotation. In contrast, stereo Their method favors the frames that bring the most entropy
cameras can recover the depth information and initialize the reduction in the map points and essentially selects the most
map directly [9], [10]. In multi-camera setups, there could informativekeyframesforBA.ThecriterionfromDVO[16]
be various ways of combining different cameras depending is the most related to ours: it selects keyframes based on
on the extrinsic parameters. For example, MCPTAM [11] an entropy ratio that reﬂects the uncertainty of the camera
initializes the monocular cameras individually with a known pose with respect to the last keyframe. Our method follows
target. The pipeline in Liu et al. [12] performs initialization asimilaridea,butconsidersallthecurrentkeyframes,which
withstereomatchingfrompredeﬁnedstereopairs.Whilethe reﬂects the information contained in the entire local map.
possible ways for initialization inevitably depend on sensor
conﬁgurations, we would like a system to be able to select C. Map Management and Query
thepropermethodautomatically,insteadofhard-codedrules. To estimate the pose of newly coming frames, the front-
end usually needs to ﬁnd the 2D-3D correspondences be-
B. Keyframe Selection
tween the observations in the new images and the map. A
It is common to maintain a ﬁxed number of keyframes in common method is the covisibility check: only search for
the front-end as the local map, against which new frames the matches of the 3D points in the keyframes that reproject
are localized. Hence, the selection of keyframes is crucial onto the new images, such as in [8], [13], [17], [18]. As
for the performance of SLAM systems. In general, the more cameras are added, the complexity of the covisiblity
keyframe selection criteria can be categorized into heuristic- check increases quadratically, and keyframes from cameras
based methods and information-theoretic methods. with large common FoVs introduce high redundancy. For
1) Heuristics-based methods: In many SLAM systems, example, for stereo pairs with highly overlapping FoVs,
the keyframe selection criteria are the combinations of dif- it is usually sufﬁcient to keep one of the two frames as
ferent heuristics. We list the most common ones below. keyframes. Obviously, it is not clear how this strategy can
Camera motion: In ORB-SLAM [8], one of the criteria is generalize to arbitrary camera conﬁgurations. To the best of
to check whether the current frame is a certain number of ofourknowledge,thereisnopreviousstudyaboutefﬁciently
frames away from the last keyframe. Similarly, DSO [13] querying map points in a general multi-camera setup.
and SVO [10] select a new keyframe if the current pose is
away from the last keyframe by a certain amount of motion. III. ADAPTIVEINITIALIZATION
Number of tracked features: A new keyframe is selected Our initialization method has no hard-coded assumptions
if the number or the percentage of tracked features in the regarding the camera conﬁguration. For any multi-camera
current frame falls below a certain threshold. However, the setups with known intrinsic and extrinsic calibrations, it is
speciﬁc threshold usually varies greatly between different able to select the proper initialization method accordingly,
scenarios. This criterion in used in [8], [10], [11], and [14]. without the need to change the algorithm settings manually.
Optical ﬂow: The Euclidean norm between the correspond- Speciﬁcally, it utilizes an overlapping check between the
ing features from the current frame and the last keyframe. camera frustums to identify all the possible stereo camera
This criterion, for example, is used in [13] and [12]. pairs. If there exists stereo pairs, the initial 3D points are
Brightness change: For direct methods, changes in image created from the stereo matching of these stereo pairs.
brightness caused by camera exposure time and lighting Otherwise, the 5-point algorithm is run on every camera as
2117
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. 120 120
trial0 E(T)
115 trial1 115 Ee(T)
E(T)111001050 trial2 NegativeEntropy111001050 95%Ee(T)
95 95
910800 1825 1850 1875 1900 1925 1950 1975 2000 910800 1825 1850 1875 1900 1925 1950 1975 2000
FrameBundleNumber FrameBundleNumber
Fig. 3: Negative entropy evolution of 3 runs in EuRoC MH01. E(T) for Fig.4:RunningaverageE˜(T)andkeyframeselection.Therunningaverage
each run is shown in a different color, and the red dots indicates where a ﬁlter(yellow)tracksthelocalizationqualitysincethelastkeyframe.When
frameisselectedasakeyframe.E(T)increasesafterakeyframeinsertion the negative entropy of the current frame (blue) falls below a certain
anddecreasesasthesensormovesawayfromthemap. percentageoftherunningaverage(greendash),anewkeyframeisselected
(reddots)andtherunningaverageﬁlterisreset.
in a standard monocular setup, and the map is initialized
whenever there exists a camera that triangulates the initial keyframe bundle contains the frames from all the cam-
map successfully (i.e., enough parallax, and the camera is eras at the same time. In the following, we will use the
not undergoing strong rotation). terms keyframe and keyframe bundle interchangeably. To
The core part of the aforementioned initialization scheme determine when a keyframe should be added, we design
is the overlapping check. The overlapping checking al- an entropy-based mechanism. In particular, the local map
gorithm checks all the possible pairs in a multi-camera contains 3D points (organized as keyframes or voxels as
∈ (cid:54)
conﬁguration, denoted as C , where i,j 1...n, i = in Section V) against which new frames can localize. In-
ij
j, and n is the total number of cameras in the system, tuitively, a keyframe should be selected when the current
and ﬁnds all possible stereo pairs. For each pair C , the map is not sufﬁcient for tracking, since new points will
ij
algorithm is illustrated in Fig. 2. We denote a 3D point in be initialized at the insertion of a keyframe. Therefore, we
homogeneous coordinates as (x,y,z,1)(cid:62). With the camera select keyframes based on the uncertainty of the keyframe
projection function π, a 2D point u in the image plane bundleposewithrespecttothecurrentmap.Comparedwith
can be back-projected to a 3D point in the camera frame heuristics,ourmethodismoreprincipled,haslessparameters
for a depth value z as p = π−1(u,z). We also know the (only 1) and generalizes to arbitrary camera conﬁgurations.
corresponding relative transformation Tij from the extrinsic Inthissection,weﬁrstprovidenecessarybackgroundonthe
calibration of the camera system. In detail, the overlapping uncertainties in estimation problems and then describe our
check ﬁrst uniformly samples (or possibly using different keyframe selection method.
sampling methods) a set of points U on the image plane
i A. Uncertainties Estimation in Nonlinear Least Squares
of camera i. Then the points in U are back-projected to
i
the minimal and maximal depths d and d as P For a parameter estimation problem of estimating x from
min max i,max
and P respectively. These depths are speciﬁed by users measurement z with normally distributed noise, a common
i,min
and encloses the effective depth range of the initialization method is to cast the problem as a nonlinear least squares
process. Given the Tij and the intrinsics of camera j, we (NLLS) problem. In iterative algorithms of solving NLLS
then project the 3D points P and P to camera j problems, such as Gauss-Newton, the uncertainties of the
i,min i,max
as U and U and check whether these points fall estimated parameters can be obtained as a side product
j,min j,min
in the image plane of camera j. The projection from u in in each iterative step. Speciﬁcally, the normal equation at
i (cid:62) − (cid:62)
Ui to camera j is considered successful only if both of the step i is (J Σz1J)δxi = J r(xi), where r(xi) is the
backprojected 3D points at dmin and dmax are within the residual given the current estimate xi, δxi the optimal
imageplaneofcameraj.Apairofcamerasisconsideredas update, and J the Jacobian of z with respect to x. With
a stereo pair if the overlapping ratio, #ofSuccessfulProjection, is ﬁrst-order approximation, the covariance of the estimate can
#ofTotalSamples
above a user-deﬁned threshold. beobtainedbybackwardpropagatingthemeasurementnoise
Theproposedsampling-basedmethodisgeneric.Byusing to the parameters, which is simply:
thecameraprojection/backprojectiondirectly,wecanﬁndall (cid:62) − −
stereo pairs across different types of camera models without Σx =(J Σz1J) 1, (1)
the need to explicitly calculate the overlapping volume which is an important tool to quantify the estimation quality
(cid:62) −
of possibly very different frustums (e.g., between pinhole of NLLS solutions [19, Chapter 5, App. 3]. Ix = J Σz1J
and ﬁsheye cameras), which can be non-trivial to compute is also known as the Fisher information.
analytically. Moreover, the check can be computed ofﬂine,
B. Negative Pose Entropy in SLAM
and the valid stereo pairs be directly used at runtime.
In keyframe-based SLAM, the pose of the current camera
IV. ENTROPY-BASEDKEYFRAMESELECTION isusuallyobtainedbysolvingaNLLSproblem.Forexample,
The concept of keyframe naturally generalizes to a onecommonmethodistosolveaPerspective-n-Points(PnP)
keyframe bundle for a multi-camera setup, as in [11]. A problem using the Gauss-Newton method. In this case, the
2118
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. Algorithm 1: Running average ﬁlter. map remains the same until a new keyframe is added, E˜(T)
(cid:101)
Input:newestentropy(cid:101)valueE(T) essentially tracks the average pose estimation quality with
Result:Returnsthecurrentrunningaverage,E(T) respecttothelocalmapuptothecurrenttime.Notethatthe
ifnoirtiealai(cid:101)zcahtiionnc:onm(cid:101)i=ng0E, (ET()Td)o=0 (cid:101) running average ﬁlter is reinitialized every time the map is
n=n+(cid:101)1 − updated with a new keyframe, since the local map changes
E(T)=E(T)+(E(T) E(T))/n
as a new keyframe is inserted. Moreover, we use a relative
returnE(T)
thresholdwithrespecttotherunningaverageE˜(T)sothatthe
Fisher information and the covariance of the camera pose selectionisadaptivetodifferentenvironments.Thisthreshold
can be directly obtained as is the only parameter in our keyframe selection method, and
it is intuitive to tune. A higher value means more frequent
(cid:62) − (cid:62) − −
I =J Σ 1J , Σ =(J Σ 1J ) 1, (2) keyframeinsertion,andviceversa(seeTableII).Anexample
T T u T T T u T
of the running average ﬁlter is shown in Fig. 4.
where u is the observation, and J is Jacobian of u with
T
respect to the camera pose T. 1 Note that in different NLLS V. VOXEL-MAPQUERY
problems, the Fisher information and covariance may be
For new incoming images, the tracking process in SLAM
obtained differently (e.g., marginalization in a BA setup).
is responsible to ﬁnd the correspondences between the ob-
As mentioned above, our goal is to use the estimate
servations in the new images and the 3D points in the map.
uncertainty of the current pose to indicate whether a new
For monocular and stereo setup, this can be efﬁciently done
keyframeshouldbeinserted.While(2)providesaprincipled
bysearchingonlyformatchesofthepointsinthekeyframes
tool, it is more desirable to have a scalar metric as keyframe
thatoverlapwiththenewframes.Forageneralmulti-camera
selection criteria. Therefore, we utilize the concept of the
setup,sincekeyframesfromdifferentcamerascanhavehigh
differential entropy for a multivariate Gaussian distribution,
(cid:12) (cid:12) overlap, this method can introduce considerable redundancy.
which is H(x) = 1m(1 + ln(2π)) + 1ln((cid:12)Σ(cid:12)) for a m-
2 2 Therefore, we organize the map points in a voxel grid, and
dimensional distribution with covariance Σ.(cid:12)N(cid:12)ote that the directly sample the camera frustums for possible 3D points
magnitudeoftheentropyonlydependsonln((cid:12)Σ(cid:12)).Moreover,
to match, as proposed in [20].
in the context of NLLS for pose estimation, from (2), we
| | − | | Map representation: Our voxel-map is a hash table using
haveln(Σ )= ln(I ).SincethattheFisherinformation
T T the voxel hashing technique described in [21]. Each entry
I comes for free in the process of solving NLLS problems,
T in the hash table is a voxel of a user-deﬁned size at a
we can actually avoid the matrix inversion and use
certain position, and it contains the 3D points (from SLAM
(cid:44) | |
E(T) ln(I ) (3) pipeline) that fall in this voxel. The voxels in the hash table
T
are accessed via a hashing function on the integer world
to indicate how well the camera can localize in the current
coordinates.Therefore,togetthe3Dpointsaroundalocation
map.Wereferto(3)asnegativeentropy.Since(2)issimply
of interest, we can directly get the corresponding voxel in
the sum of individual measurements, it is straightforward to
constant time. In addition, the map only allocates voxels
incorporate the observations from all the cameras into one
where there are 3D points and does not store empty voxels.
single scalar (3) in an arbitrary multi-camera setup.
The voxel hash table is synchronized with the map points in
C. Running Average Filter for Keyframe Selection the SLAM pipeline.
Map query: To get the map points to match for a multi-
Examples of the negative entropy E(T) evolution on the
camera system, we sample a ﬁxed number of points in
same dataset (MH 01) with our multi-camera pipeline (see
the camera frustums and ﬁnd corresponding voxels in the
SectionVI)areshowninFig.3.WecanseethatE(T)indeed
voxel-map. The points inside these voxels are then used to
reﬂects the localization uncertainty of the pose with respect
match the observations in the new images. In this way, it is
tothecurrentmap.Afterinsertinganewkeyframetothemap
guaranteed that all and only the 3D points within the FoVs
(red dots on the curves), the negative entropy increases, due
of all cameras are retrieved from the map. Moreover, we
to the triangulation of new points; and as the camera moves
avoid the process of checking overlapping keyframes from
awayfromthelastkeyframe/localmap,E(T)decreasesuntil
different cameras, which may have many points in common
anotherkeyframeisselected.Ontheotherhand,evenforthe
and introduce redundant computation.
same environment, the absolute value of E(T) varies from
Note that we only use voxel-map for querying visible
run to run. This indicates that using an absolute threshold
landmarks. Keyframes are still selected for triangulation and
for E(T) as the keyframe selection criterion is not feasible.
potentially bundle adjustment.
Instead, we propose to track the negative entropy value
using a running average ﬁlter (see Algo. 1) in the local VI. EXPERIMENTS
map and selects a keyframe when E(T) of a frame is below
To validate the proposed method, we applied the afore-
certain percentage of the tracked average E˜(T). Since we
mentioned adaptations to a state-of-the-art keyframe-based
localize the camera with respect to the latest map, and the
visual-inertial odometry pipeline that consists of an efﬁcient
visual front-end [10] and an optimization-based backend
1Technically,theJacobianiswithrespecttoaminimalparameterization
of6DoFposes,whichisomittedhereforeasypresentation. similarto[22].Weperformedexperimentsonbothsimulated
2119
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. 5 2cameras
3cameras
error[%]34 45ccaammeerraass
Translation12
0
5.0 11.0 17.0 23.0 28.0
Distancetraveled[m]
Fig.6:Overallrelativetranslationerrorinsimulationfor5runs.
Fig. 5: Simulated ﬁgure 8 trajectory in the simulation environment. The
tcrareanadmjd.eecTrrtahoesera.ylmT-wwhageaoessrneltegdasmtdidmeoantastttaeaw.drehInebtrhyeseitrmthureanucnmklianeotdgniooltacnhnue,dlawmradaesraekpvtsuteepbdryilﬁoVSseLtIdOAtrtaMhpciekpseyrislsoitnbememuassrwk.tnietdhesi5ns Time (millisecs) Visible Landmarks # Pointers
# 
andanalyzedseveralpropertiesofthepipelinewithdifferent
Number of cameras Number of cameras Number of cameras
multi-camera conﬁgurations. For real-world data, we ﬁrst Fig.7:Comparisonoftheproposedvoxel-mapwithstandardkeyframesfor
tested the stereo setup with the EuRoC dataset [23] to show different camera conﬁgurations (2 to 5 cameras). Left: total time for the
front-endinVIO.Middle:retrievedlandmarksformatchingfromthemap.
that the proposed method performs on par with standard
Right:numberofreferences/pointerstolandmarkpositions.
methodsbutismucheasiertotune.Wethentestedthemulti-
keyframes. However, the front-end consumed more time
camerasetupwiththeAutoVisiondataset[24].Forquantita-
in our experiment, and we assume that it can be further
tiveevaluationofaccuracy,wefollowtheevaluationprotocol
reduced by optimizing our voxel-map implementation. In
in [25]. We repeated the experiment on each sequence for
terms of memory footprint (Fig. 7 right), the voxel-map
5 runs using the same setting unless speciﬁed otherwise. In
increased much slower than keyframes. The reason is that
each of the experiment, we kept the parameters the same for
the keyframe-based map stores landmark observations in
different camera conﬁgurations.
each keyframe. For a multi-camera setup with large FoV
A. Simulation Experiment overlap, it is very likely different cameras observe the same
landmarks, resulting in redundant copies in keyframes. In
We tested the pipeline on a drone with various camera
contrast, the voxel-map stores the references only once.
conﬁgurations: 2 cameras (a front mono; a side mono), 3
cameras (a front stereo; a side mono), 4 cameras (a front B. Real-world Experiment
stereo; a side stereo), and 5 cameras (a front stereo; a side 1) EuRoC Dataset: We tested the multi-camera VIO
stereo; a down mono). We refer the reader to the accompa- pipeline on EuRoC dataset for the stereo setup. The number
nying video for the visualization of our setup. We set the of keyframes in the sliding window was set to 10. To
drone to ﬂy a ﬁgure 8 trajectory in the environment (Fig. 5). showtheeffectoftherelativenegativeentropyforkeyframe
Note that a monocular setup from either the front or side selection, we also experimented with different relative en-
stereo failedwhen thedrone wentaround atextureless pillar tropy thresholds. We use the notation “er-m” to denote our
(markedinredinFig.5),andthecorrespondingquantitative experimentalconﬁgurations,whereristheentropythreshold
results are omitted. Next, we analyzed the accuracy and inpercentage,andmthemaprepresentationused(i.e.,voxel
timing, and the performance of voxel-map and keyframes. orkeyframes).Thedefaultpipelinethatiscarefullytunedfor
Accuracy: The relative pose error of different camera con- stereo setups is denoted as “default-kf”.
ﬁgurations is shown in Fig. 6. Adding more cameras to the The median values of the absolute trajectory error in 5
system improved the trajectory estimation accuracy, but the runs are shown in Table I. While there is no deﬁnite winner,
improvementbecamemarginalafterthe3-cameraconﬁgura- the adapted pipeline in general performed similar or better
tion.Thisisbecauseaddingthethirdcameraformedastereo than the default pipeline. This can also be conﬁrmed from
pair(frontstereo)comparedwiththe2-cameraconﬁguration, theodometryerrorsinFig.8(weselectthreesequencesonly
which made direct triangulation possible. due to the limit of space). The adapted pipeline has lower
Timing:Thetotalfront-endtimefordifferentconﬁgurations estimateerrorin10outof11sequencesandtheentropyratio
is shown in Fig. 7 (left). As we increased the number of of 98% has the most. Regarding the number of keyframes,
cameras in the conﬁguration, we observe an increase in the it is clearly seen in Table II that increasing the relative
totalprocessingtimeofthefront-end.Theincreaseintimeis entropy ratio resulted in more keyframes. In addition, for
notassigniﬁcantbetweenthe4and5cameraconﬁgurations, relativeentropyratioof95%,fewerkeyframeswereselected
as the 5th camera (downlooking) did not produce as many in general but the accuracy was still similar to the default
landmarks as the other cameras. pipelineaccordingtoTableI.Thisindicatesthattheproposed
Voxel-map vs. Keyframes: In general, the voxel-map method selected keyframes more effectively and introduced
method retrieved more landmarks (Fig. 7 middle) than the less redundancy than the default pipeline.
keyframe based method, because some of the visible land- To summarize, as a generic pipeline, our method per-
marks in the current frame may not be stored in nearby formed at least similarly good compared with a carefully
2120
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. MH_01 V2_02 V2_03
Fig.8:RelativetranslationerrorpercentagesfromtheEuRoCdatasetwithBA.
TABLEI:MedianRMSE(meter)onEuRoCdatasetover5runs.Lowesterrorhighlightedinbold.
Algorithm MH01 MH02 MH03 MH04 MH05 V101 V102 V103 V201 V202 V203
default-kf 0.140 0.078 0.091 0.119 0.330 0.042 0.070 0.047 0.056 0.066 0.127
e93-voxel 0.104 0.390 0.107 0.177 0.262 0.038 0.036 0.043 0.080 0.103 0.169
e95-voxel 0.078 0.084 0.093 0.182 0.237 0.040 0.047 0.049 0.056 0.087 0.171
e98-voxel 0.095 0.074 0.088 0.128 0.180 0.039 0.053 0.041 0.046 0.057 0.111
TABLEII:Averagenumberofkeyframesfor5runsinEuRoCsequences.
Algorithm MH01 MH02 MH03 MH04 MH05 V101 V102 V103 V201 V202 V203
default-kf 64.00 57.80 91.40 76.00 70.20 70.60 119.60 238.80 74.80 172.00 281.40
e93-voxel 46.00 46.30 67.80 58.80 61.80 52.80 56.20 120.40 30.80 63.40 86.80
e95-voxel 71.20 66.00 87.00 74.40 75.80 76.40 86.80 160.00 39.80 85.00 107.80
e98-voxel 154.20 137.20 181.20 138.60 143.60 176.80 177.80 305.20 84.40 169.00 203.60
TABLE III: The average number of keyframes by different keyframe
selectioncriteriaformonocularandstereosetups.
365320
Algorithm MH01 MH02 V201 V202
heuristic,mono 202.75 190.75 150.75 379.75
heuristic,stereo 90.00 117.25 84.75 204.5 m]365300
entropy,mono 129.5 128.25 100.00 193.5 [
x
entropy,stereo 122.25 125.25 98.5 195 365280
TABLEIV:Differenttrajectoryerrormetricsfromthemulti-camerapipeline 365260 Estimate
ontheScienceParkdaysequence.TheﬁrstrowcontainstheabsoluteRMSE Groundtruth
ofthefulltrajectory(547.488m)
142475 142500 142525 142550 142575
Metric F FR FRB y[m]
Abs.Trajectoryerror(meter) 1.184 2.366 1.766 Fig. 9: Top view of the estimated and groundtruth trajectory of the FRB
Rel.Trans.Percentage@200m 0.582 1.808 1.320 conﬁgurationfromtheScienceParkdaysequence.
Rel.Trans.Percentage@400m 0.642 1.07 0.760
sequence in a autonomous driving scenario. The trajectory
is 547.448 m long and the maximum speed is 3.941 m/s.
tuned stereo pipeline, and our method was able to achieve
Following [12], we tested our pipeline with F, FR, and FRB
similar accuracy with fewer keyframes. More importantly,
conﬁgurations. The trajectory errors, computed in the same
we would like to emphasize that our method has only one
way as in [12], are shown in Table IV, and the estimated
parameter for keyframe selection, which makes the task of
trajectory (FRB) in Fig. 9. While the estimation accuracy is
parameter tuning much easier.
Sensor Agnostic We also performed an experiment compar- acceptable and proves the effectiveness of our method, we
indeed observed that the accuracy of the trajectory estimates
ing the number of selected keyframes between monocular
does not necessarily increase as we add more cameras to
and stereo conﬁgurations. We only ran the visual front-end
the pipeline. We suspect that the reason to be the inaccurate
inthiscasetoremovetheinﬂuenceoftheoptimizationback-
extrinsic (similar behavior can be observed in [12]).
end, which caused the different keyframe numbers between
Table II and III. The average number of keyframes on some
VII. CONCLUSION
sequences in EuRoC is shown in Table III. The heuristic
method selected drastically different numbers of keyframes In this work, we introduced several novel designs for
between monocular and stereo conﬁgurations because they common building blocks in SLAM to make an adaptive
had to be tuned differently for these conﬁgurations. In system for arbitrary camera conﬁgurations. In particular,
contrast, our entropy-based method selected very similar we proposed an adaptive initialization scheme that is able
numbers of keyframes. This is due to fact that our method to automatically ﬁnd the suitable initialization method, an
essentially summarizes the information in the map instead information-theoretic keyframe selection method that incor-
of relying on camera-dependent quantities. In particular, the porates the information from all cameras elegantly and a
stereo pair in EuRoC dataset has largely overlapping FoVs, voxel-map representation from which we can directly re-
andthusthevisibleareasoftheenvironmentweresimilarfor trieve the landmarks in the camera FoVs. We applied these
monocular and stereo setups, leading to similar information techniques to a state-of-the-art VIO pipeline, and extensive
for our keyframe selection method. experimental results showed that the resulting pipeline was
2) AutoVision Dataset: We evaluated our pipeline on the abletoadapttovariouscameraconﬁgurationswithminimum
Science Park day sequence, which is a large-scale outdoor parameter tuning.
2121
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [15] A.DasandS.Waslander,“Entropybasedkeyframeselectionformulti-
cameravisualslam,”inIEEE/RSJInt.Conf.Intell.Robot.Syst.(IROS),
[1] C.Cadena,L.Carlone,H.Carrillo,Y.Latif,D.Scaramuzza,J.Neira,
2015. 2
I.D.Reid,andJ.J.Leonard,“Past,present,andfutureofsimultaneous
[16] C.Kerl,J.Sturm,andD.Cremers,“DensevisualSLAMforRGB-D
localization and mapping: Toward the robust-perception age,” IEEE
cameras,”inIEEE/RSJInt.Conf.Intell.Robot.Syst.(IROS),2013. 2
Trans.Robot.,vol.32,no.6,pp.1309–1332,2016. 1
[17] G.KleinandD.Murray,“ParalleltrackingandmappingforsmallAR
[2] Z. Zhang, C. Forster, and D. Scaramuzza, “Active exposure control
workspaces,” in IEEE ACM Int. Sym. Mixed and Augmented Reality
for robust visual odometry in hdr environments,” in IEEE Int. Conf.
(ISMAR),Nara,Japan,Nov.2007,pp.225–234. 2
Robot.Autom.(ICRA),2017. 1
[18] C. Forster, M. Pizzoli, and D. Scaramuzza, “SVO: Fast semi-direct
[3] A. Rosinol Vidal, H. Rebecq, T. Horstschaefer, and D. Scaramuzza,
monocularvisualodometry,”inIEEEInt.Conf.Robot.Autom.(ICRA),
“Ultimate SLAM? combining events, images, and IMU for robust
2014,pp.15–22. 2
visualSLAMinHDRandhighspeedscenarios,”IEEERobot.Autom.
[19] R. Hartley and A. Zisserman, Multiple View Geometry in Computer
Lett.,vol.3,no.2,pp.994–1001,Apr.2018. 1
Vision. CambridgeUniversityPress,2003,2ndEdition. 3
[4] “OculusQuest,”https://www.oculus.com/quest/. 1
[20] M. Muglikar, Z. Zhang, and D. Scaramuzza, “Voxel map for visual
[5] “SkydioR1,”https://robots.ieee.org/robots/skydior1/. 1
slam,”inIEEEInt.Conf.Robot.Autom.(ICRA),2020. 4
[6] D. Anguelov, C. Dulong, D. Filip, C. Frueh, S. Lafon, R. Lyon,
[21] M.Niessner,M.Zollho¨fer,S.Izadi,andM.Stamminger,“Real-time
A.Ogale,L.Vincent,andJ.Weaver,“Googlestreetview:Capturing
3dreconstructionatscaleusingvoxelhashing,”ACMTrans.Graph.,
theworldatstreetlevel,”Computer,2010. 1
2013. 4
[7] D. Niste´r, “An efﬁcient solution to the ﬁve-point relative pose prob-
[22] S. Leutenegger, S. Lynen, M. Bosse, R. Siegwart, and P. Furgale,
lem,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 26, no. 6, pp.
“Keyframe-basedvisual-inertialSLAMusingnonlinearoptimization,”
756–777,2004. 2
Int.J.Robot.Research,2015. 4
[8] R. Mur-Artal, J. M. M. Montiel, and J. D. Tardo´s, “ORB-SLAM: a
[23] M.Burri,J.Nikolic,P.Gohl,T.Schneider,J.Rehder,S.Omari,M.W.
versatileandaccuratemonocularSLAMsystem,”IEEETrans.Robot.,
Achtelik,andR.Siegwart,“TheEuRoCmicroaerialvehicledatasets,”
vol.31,no.5,pp.1147–1163,2015. 2
Int.J.Robot.Research,vol.35,pp.1157–1163,2015. 5
[9] R.Mur-ArtalandJ.D.Tardo´s,“ORB-SLAM2:Anopen-sourceSLAM
[24] L. Heng, B. Choi, Z. Cui, M. Geppert, S. Hu, B. Kuan, P. Liu,
system for monocular, stereo, and RGB-D cameras,” IEEE Trans.
R. Nguyen, Y. C. Yeo, A. Geiger, G. H. Lee, M. Pollefeys, and
Robot.,vol.33,no.5,pp.1255–1262,Oct.2017. 2
T. Sattler, “Project autovision: Localization and 3d scene perception
[10] C.Forster,Z.Zhang,M.Gassner,M.Werlberger,andD.Scaramuzza,
foranautonomousvehiclewithamulti-camerasystem,”inIEEEInt.
“SVO: Semidirect visual odometry for monocular and multicamera
Conf.Robot.Autom.(ICRA),2019. 5
systems,”IEEETrans.Robot.,vol.33,no.2,pp.249–265,2017. 2,4
[25] Z. Zhang and D. Scaramuzza, “A tutorial on quantitative trajectory
[11] A.Harmat,I.Sharf,andM.Trentini,“Paralleltrackingandmapping
evaluationforvisual(-inertial)odometry,”inIEEE/RSJInt.Conf.Intell.
withmultiplecamerasonanunmannedaerialvehicle,”inIntelligent
Robot.Syst.(IROS),2018. 5
RoboticsandApplications,2012. 2,3
[12] P.Liu,M.Geppert,L.Heng,T.Sattler,A.Geiger,andM.Pollefeys,
“Towards robust visual odometry with a multi-camera system,” in
IEEE/RSJInt.Conf.Intell.Robot.Syst.(IROS),2018. 2,6
[13] J.Engel,V.Koltun,andD.Cremers,“DirectSparseOdometry,”IEEE
Trans.PatternAnal.Mach.Intell.,vol.40,no.3,pp.611–625,Mar.
2018. 2
[14] T. Qin, P. Li, and S. Shen, “VINS-Mono: A robust and versatile
monocularvisual-inertialstateestimator,”IEEETrans.Robot.,vol.34,
pp.1004–1020,2018. 2
2122
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:09:29 UTC from IEEE Xplore.  Restrictions apply. 