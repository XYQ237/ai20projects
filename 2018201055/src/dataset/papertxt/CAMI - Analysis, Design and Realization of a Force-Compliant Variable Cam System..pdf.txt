2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
OmniTact: A Multi-Directional High-Resolution Touch Sensor
∗
Akhil Padmanabha1, Frederik Ebert1, Stephen Tian1, Roberto Calandra2, , Chelsea Finn3, Sergey Levine1
Abstract—Incorporating touch as a sensing modality for
robots can enable ﬁner and more robust manipulation skills.
Existing tactile sensors are either ﬂat, have small sensitive
ﬁelds or only provide low-resolution signals. In this paper, we
introduce OmniTact, a multi-directional high-resolution tactile
sensor. OmniTact is designed to be used as a ﬁngertip for
robotic manipulation with robotic hands, and uses multiple
micro-camerastodetectmulti-directionaldeformationsofagel-
basedskin.Thisprovidesarichsignalfromwhichavarietyof
different contact state variables can be inferred using modern
imageprocessingandcomputervisionmethods.Weevaluatethe
capabilities of OmniTact on a challenging robotic control task
that requires inserting an electrical connector into an outlet,
as well as a state estimation problem that is representative of Fig.1:HumanthumbnexttoOmniTact,andaUSpennyfor
those typically encountered in dexterous robotic manipulation, scale. OmniTact is a high-resolution multi-directional tactile
wherethegoalistoinfertheangleofcontactofacurvedﬁnger sensor designed for robotic manipulation.
pressing against an object. Both tasks are performed using
only touch sensing and deep convolutional neural networks to
process images from the sensor’s cameras. We compare with a
state-of-the-art tactile sensor that is only sensitive on one side, Most current tactile sensors fall into either of two cate-
aswellasastate-of-the-artmulti-directionaltactilesensor,and gories: they provide high spatial resolution on a ﬂat surface,
ﬁndthatOmniTact’scombinationofhigh-resolutionandmulti-
as in the case of the GelSight sensors [1], [2], [3], or they
directionalsensingiscrucialforreliablyinsertingtheelectrical
allow sensitivity on strongly curved surfaces, but with much
connectorandallowsforhigheraccuracyinthestateestimation
task. Videos and supplementary material can be found here.4 lower spatial resolution. Curved sensor designs based on ca-
pacitive [4], resistive [5], optical [6], [7], sensor arrays have
I. INTRODUCTION
limited spatial resolution due to manufacturing constraints.
In order to manipulate an object, a robot needs precise High resolution tactile sensing is crucial for high-ﬁdelity
information about the contact state between the gripper and manipulation, where precise sensing of the contact state is
theobjectbeingmanipulated.While3Dsensorsandcameras vital to completing tasks.
can provide a global view of a scene, tactile sensors can In this paper, we propose an optical tactile sensor that
provide arguably the most direct information about the state uses a similar high-resolution optical sensing principle as
of a system, as these sensors can perceive precisely those the GelSight sensor, but with two crucial differences: 1)
forcesthatarobotexertstomanipulateobjects.However,the Oursensoroffersamulti-directionalﬁeldofview,providing
design of effective tactile sensors for robotic manipulation sensitivity on a curved surface. 2) In our sensor, the gel is
has consistently proven challenging. For a tactile sensor to directly cast on top of the cameras. This results in a more
beusefulinroboticmanipulation,itmustbecompactenough compactformfactorcomparedtopreviousGelSightsensors,
to ﬁt inside a robot’s ﬁnger and must provide a sufﬁciently as we entirely remove the support plate and thus eliminate
rich signal to give the robot relevant information about the empty spaces between the camera and the gel.
contact state. For general-purpose robotic manipulation, it is
We show that such a sensor can be built using multiple
alsocrucialforthetactilesensortobesensorizedonasmuch
micro-cameras oriented in different directions to capture de-
of the ﬁnger’s curved surface as possible. A robotic ﬁnger
formations of a thumb-shaped gel-based skin from all sides.
withmulti-directionalsensingcanmakecontactwithobjects
In principle, similar micro-camera arrangements embedded
at a variety of points and angles, and therefore should be
into a gel-based skin can be designed for virtually any
able to localize objects in a broader range of the state space.
surface, and could potentially cover a complete robot hand.
Since OmniTact provides an array of high-resolution im-
1Department of Electrical Engineering and Computer Sciences,
UniversityofCalifornia,Berkeley,CA,USA ages (shown in Figures 2 and 3), like GelSight sensors [8],
{
akhil.padmana}bha, febert, stephentian, [9], [10], the signals can readily be used in learning-based
sergey.levine @berkeley.edu
computer vision pipelines [11].
2FacebookAIResearch,MenloPark,CA,USA
rcalandra@fb.com This paper presents a novel tactile sensor, shown in
3Stanford,DepartmentofComputerScience,PaloAlto,CA,USA Figure 1, which combines the beneﬁts of multi-directional
cbfinn@cs.stanford.edu
∗ sensing on strongly curved surfaces with the high resolution
WorkdonewhileatUCBerkeley
4https://sites.google.com/berkeley.edu/omnitact and accuracy of optical tactile sensors such as previous
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 618
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. Fig. 2: Tactile readings from OmniTact with various objects. From left to right: M3 Screw Head, M3 Screw Threads,
Combination Lock with numbers 4 3 9, PCB, Wireless Mouse USB. All images are taken from the upward-facing camera.
Top Camera Side Camera Top Camera Side Camera Top Camera Side Camera Top Camera Side Camera
Fig. 3: Tactile readings from the OmniTact being rolled over a gear rack. The multi-directional capabilities of OmniTact
keep the gear rack in view as the sensor is rotated.
GelSightsensors.Wedemonstratethehighspatialresolution difﬁcult to apply in a wide range of applications. The
andmulti-directionalsensingcapabilityonastateestimation GelSlim sensor [14] integrated mirrors and light guides to
task,wherethesensorisusedtoestimatetheangleofcontact make the sensor more compact, decreasing thickness to
when the sensor is pressing against an object. We also use 20mm. Like this design, OmniTact provides a more slim
theOmniTactsensortosolvearoboticcontroltask,wherean design (30mm diameter), while providing sensitivity on all
electrical connector must be inserted into a wall outlet, and sides, whereas GelSlim is only sensitive on one side. A
observe that OmniTact’s multidirectional sensing capability unidirectional version of our sensor would only measure
is critical to solving this task. 15mm in thickness.
II. RELATEDWORK Sensors that only provide sensitivity on one side restrict
the complexity of the tasks that can be performed. While a
Our sensor builds on the GelSight design [1] which con-
unidirectional sensor can be mounted inside a parallel jaw
sists of a camera that captures deformations on an elastomer
gripper, which is sufﬁcient for grasping, it can be difﬁcult
slab. As illustrated on the left side of Figure 4, the gel slab
to use for more complex tasks that require both localizing
of the GelSight sensor is coated with a layer of reﬂective
objectsintheworldandperceivingtheobjectthatisgrasped.
paint and illuminated by LEDs of different colors. A key
Aﬁngertipthatissensitiveonallsidescanbeusedonrobotic
advantage of GelSight sensors over other tactile sensors is
hands in tasks where contacts occur on multiple sides of the
that the images provide a rich signal from which a wide
ﬁngertip, as illustrated in our experiments.
range of relevant information, such as object geometry [8],
grasp stability [9], [10] and object hardness [12] can be As discussed by Donlon et al. [14], integrating multi-
extracted. The images from the camera can easily be used directionality into existing GelSight sensor designs is chal-
with standard convolutional networks [9], [10], [12], which lenging, due to the lack of space on robotic grippers. Our
have been tremendously successful in computer vision [13]. sensor, shown in Figure 4 on the right, aims to tackle
Despite these advantages, previous GelSight sensor designs this challenge using microcameras, allowing for integrated
[8] are bulky (35mm x 35mm x 60mm), making them multi-directionality. Instead of using cameras to sense the
619
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. Coating TABLE I: Key Speciﬁcations of manufactured OmniTact
prototype. * excluding blind spots.
Elastomer 
Gel Verticalcutﬁeldofview* 270◦
◦
Horizontalcutﬁeldofview* 360
LEDs Numberofcameras 5
Cameraresolution 400x400pixels
Cameras Cameraframerate 30fps
DiameterD 30mm
HeightofsensitiveareaH 33mm
by providing more accurate and comprehensive information
GelSight Sensor OmniTact
aboutthecontactstatebetweentherobotanditsenvironment.
1) High resolution.: The sensor should provide rich sig-
nals from which features relevant for control, such as object
positions,canbeextractedaccurately.Achievinghighspatial
resolution has proven challenging with capacitive, resistive,
or photodiode-based sensors. However, the resolution of
camera-based sensors is limited only by the resolution of
the camera and the sensitivity of the sensor skin.
2) Thumb-like form factor.: It is important for the sensor
Fig. 4: Comparison of our OmniTact sensor (right side) to a to ﬁt into robot ﬁngertips. In many cases, the size of the
GelSight-style sensor [3] (left side). Using an arrangement ﬁngertip restricts the possible tasks it can be used for. For
ofmultiplemicro-camerasandcastingthegeldirectlyonthe example, a large manipulator may have difﬁculty picking up
cameras (without the need for support plates and the empty small or thin objects such as plates or forks.
space between the camera and the gel) allows for a more 3) Omni-directional sensing.: Sensitivity on multiple
compact design while enabling a wide ﬁeld of sensitivity on sides enables the estimation of contacts in a wider range
surfaces with strong curvature. of settings. While sensitivity on the inner surface between
ﬁngers is necessary for grasping, sensitivity on the other
sides can be crucial for localizing objects of interest, or for
deformationofthegelskin,similarmulti-directionalsensors performing non-prehensile manipulation.
have been proposed that use arrays of photodiodes [6] to Motivatedbythesedesigndecisions,wepresentthedesign
support curved surfaces such as robotic ﬁngertips. However, oftheOmniTactsensorinthefollowingsection,followedby
using single sensing elements, such as photodiodes, does details of the fabrication process.
not provide the same spatial resolution as camera chips.
An example of a multi-directional sensor is the BioTac B. OmniTact Sensor Design
sensor [15], [16], which features similar dimensions to a Similar to the GelSight sensor [1], our proposed sensor
human ﬁnger and provides sensitivity on its tip and side. uses cameras to record the deformation of a gel skin coated
It uses an array of 19 electrodes, a pressure sensor, and a with a reﬂective layer (additional details on the GelSight
thermistor, providing far lower resolution than cameras used sensor are discussed in Section II). However, unlike the
in GelSight sensors or our proposed sensor. GelSight sensor, which uses a single camera, our sensor
To evaluate our sensor, we compare it to a conventional providesforsensingonallsidesofaroundedﬁngertip,using
ﬂatGelSightsensorandamulti-directionalOptoForcesensor ﬁve micro-cameras, as illustrated in Figure 4 on the right.
on tactile state estimation and control tasks. Tactile state Moreover, the gel is not mounted on top of a support plate
estimationhasbeenstudiedinanumberofpriorworks[17], asintheGelSight,butrathercastdirectlyaroundthecameras
[16], [18], [19], [20], [21], [22]. In our experiments, we to reduce the size of the sensor.
show that our sensor can result in improved performance a) Cameras: The most important factor determining
overaﬂatGelSightsensoronstateestimation,andimproves thesizeofanopticaltouchsensoristhechoiceofcameraand
over a curved OptoForce sensor on touch-based control for the cameras’ arrangement relative to the gel. The cameras
connector insertion. are chosen to have the maximum possible ﬁeld of view
and the smallest possible minimal focus distance1. Cameras
III. DESIGNANDFABRICATION
with wider ﬁelds of view observe larger portions of the
In this section, we provide a summary of the design goals
sensor’s surface area, thus minimizing the total number
for the multi-directional OmniTact sensor, and then describe
of cameras required to obtain full coverage of the inner
the design in detail, including the fabrication methodology.
surfaceofthesensor.Smallminimumfocusdistancesreduce
A. Design Goals the required thickness of the gel skin and overall sensor
The main goal of this work is to build a universal tactile
1The minimal focus distance is the smallest distance between an object
sensor that increases the capabilities of robot manipulation andthelensatwhichtheobjectremainsinfocus.
620
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. A C D
B
Fig. 5: Showing the ﬁelds of view and arrangement of the
5 micro-cameras inside the sensor. Using this arrangement,
mostoftheﬁngertipcanbesensitizedeffectively.Inthever-
◦
ticalplane,showninA,weobtainα=270 ofsensitivity.In
◦
thehorizontalplane,showninB,weobtain360 sensitivity,
except for small blind spots between the ﬁelds of view.
AA B C D Fig. 7: A shows the unrolled ﬂex-PCB with the positions
of LEDs of different color, B shows the fully assembled
ﬂex-PCB. C shows the positions of the LEDs relative to the
cameras (in black), and the ﬂex-PCB wrapped around the
camera mount. D ﬂex-PCB assembled on camera mount.
the camera images. As shown in Figure 7C, we place 3
Fig. 6: The micro-cameras are inserted through channels
alongthecentralaxisofthecameramountA,Bandthrough colored LEDs adjacent to each camera, which illuminate the
the sides of the camera mount C, D. gel with red, green, and blue light from different directions.
The red, blue, and green LEDs are equally spaced from the
cameras, ensuring equal distribution of light in the camera
image. In the current design, all LEDs are permanently on,
diameter. We found that commercially available endoscope
which means that light from different LEDs positioned near
camerasprovidetheclosestmatchtotheserequirementsand
different cameras overlaps.
decided to use the 200A CMOS cameras from Shenzhen
c) Camera Mount: The OmniTact uses a custom-
Eastern International Corporation. Our testing found that
designedcameramounttosupportthecamerasandLEDsfor
each camera has a minimum focus distance of 5mm, a
◦ illumination. The mount is designed to minimize blind spots
minimum ﬁeld of view of about 90 and measures 1.35x
and sensor size, while allowing for easy assembly by hand.
1.35mm on the sides and 5mm in length, enabling a very
The top-facing camera is slid in through the z-axis channel
compactarrangementofthecameras.Thesizeofthecameras
(Fig 6A), whereas the side cameras are inserted through x
in relation to the camera mount is illustrated in Figure 6. As
◦ and y axis channels (Fig 6C). To increase the mechanical
showninFigure5,wearrangethecamerastoallowfor270
◦ stability of the ﬁngertip and the gel, we add a thin cone
of sensitivity in the vertical plane and 360 of sensitivity in
structure around the top of the camera mount, which also
the horizontal plane, excluding small blind spots. The blind
helpsreduceinterferencebetweenthelightingfromtheLEDs
spots can be reduced in future designs by choosing lenses
near the top camera and that of the side-facing cameras.
with slightly larger ﬁeld of view2.
b) Illumination: To optimally detect deformations of
C. Sensor Fabrication
the gel in the camera images, the inner surface of the gel
The camera mount of the sensor, shown in Figure 6B,
should be illuminated as evenly as possible. It is advanta-
D is 3D printed using Formlab’s stereo-lithography (SLA)
geous to illuminate the surface with light of different colors
printer,theForm2,allowingustoprintwithhighresolutions
from different directions [8]. In principle, this would allow
(50Microns).TheForm2enablesustomanufactureminute
estimating the directions of surface normals [1]. However,
in our experimental evaluation detailed in Section IV, we features such as the camera channels (1.45mm x 1.45mm).
We use a custom designed and manufactured ﬂexible PCB
show that our sensor can be used for state estimation
for mounting the LEDs around the cameras.
withoutexplicitestimationofnormalsorgeometrybyusinga
a) Assembly process: The ﬁrst step in the assembly
learning-basedapproach,whichdirectlyestimatesstatefrom
process is to insert the micro cameras and secure them by
gluing the cables down in the channels with E6000 glue, a
2Micro-camerasofsimilarcostandlargerﬁeldofviewwerenotavailable
whentheprototypewasbuilt. silicon based adhesive. The next step is to position, wrap,
621
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. and glue the ﬂexible PCB around the camera mount. After
the glue sets, the camera mount is secured to a mold and
ﬁlledwithsiliconerubber.Afterremovingthecuredsilicone
rubber ﬁnger from the the mold, the sensor is coated.
b) Sensor Coating: Similarly to [3], we chose 1µm
aluminum powder mixed with the same silicone rubber as
θ
used for the gel-skin. A solvent is added to the mix to
decreaseviscosity.Thecoatingisthencompletedbypouring
the mix over the sensor surface.
IV. EXPERIMENTALEVALUATION Fig. 8: Experimental setup for estimating angle of contact θ
when pressing against a 2020 aluminum extrusion. Left:
Thespeciﬁctasksthatwestudyincludeend-to-endcontrol
GelSight sensor. Middle: OmniTact.
ofaroboticarm3,forestimatingtheangleofcontactonaﬂat
surface,showninFigure8,aswellasgraspingandinserting
TABLE II: Angle of contact estimation benchmark for dif-
an electrical connector, shown in Figure 10. For the state
ferent angle ranges. Numbers are medians with interquartile
estimationtask,wecomparewithastandardGelSightsensor,
ranges (IQR) in brackets.
which is sensorized only on one ﬂat surface. Our speciﬁc
GelSight sensor is based on the design proposed by Dong et Medianabsoluteerrorin◦ (IQR)
◦ ◦ ◦ ◦ ◦ ◦
al.[3].SincetheOmniTactsensorisnearlysymmetricacross 0 to22.5 22.5 to60 60 to90
OmniTact(Ours) 1.142(1.665) 1.986(3.022) 1.248(1.683)
the four sides, we characterize it using only two cameras –
GelSight[3] 0.325(0.376) 4.228(6.311) 1.990(2.642)
oneofthesidecamerasandthetopcamera.Fortheconnector
insertion task, we compare OmniTact against a state-of-the-
artmulti-directionaltactilesensor:thesingle-channel,3axis attached to the end-effector of a CNC machine. The experi-
version of the OptoForce. ment is illustrated in Figure 8.
Neural-network based estimation and control. Both the Tocollectthedata,thetactilesensorisrotatedtoarandom
state estimation and connector insertion tasks use a deep angle in a speciﬁed range and the sensor is lowered until
neural network to process the tactile readings, and output it contacts the surface. Since the travel range of the CNC
a continuous valued output indicating either the robot arm machineisrestricted,wecollectdatainthreedifferentangle
positioncommandortheinferredcontactangle.Forthestate ranges,from0◦ to22.5◦,22.5◦ to60◦,and60to90◦.Ineach
estimation task, our network is based on a modiﬁed ResNet- range, we collected 1000 samples, where the rotary actuator
50 architecture [23], where the top layer is removed and the is driven to a random angle within the respective range.
ﬂattened features are fed through 4 fully connected layers The results of the angle estimation task are shown in
with 512, 256, 256, and 256 units, respectively. All other Table II. The OmniTact achieves better accuracy than the
layersinthenetworkareinitializedfromamodelpre-trained GelSight sensor in the ranges of 22.5◦ to 60◦ and 60◦ to
on ImageNet, and all layers are ﬁne-tuned during training. 90◦. This is expected, since the ﬂat sensorized surface of
For the electrical connector insertion task, the ResNet-18 the GelSight does not cleanly contact the surface at these
architecture with the top layer removed is used to generate angles, though the network is still able to perform better
ﬂattened features, which are fed through 2 fully connected than random by picking up on deformations in the plastic
layers of 256 and 64 units, respectively, with ReLU non- sensor housing. These experiments illustrate how a curved
linearities in between. Again, all of the ResNet layers are ﬁnger that is sensorized on multiple sides can enable better
initialized from a model pre-trained on ImageNet. For the state estimation at a wider range of angles.
experiments with the OmniTact sensor, the ResNet features
produced by the images from all the cameras are ﬂattened B. Tactile Control - Electrical Connector Insertion
and concatenated. The ResNet weights are independently In this experiment, we compare how an OmniTact sensor
ﬁne-tuned for each camera. The networks are trained with compares with an OptoForce sensor on the task of inserting
theAdamoptimizer[24]usingamean-squared-errorlossfor an electrical connector into a wall outlet solely from tactile
100 epochs. feedback (see Figure 9). This is a challenging task, since it
requires(1)preciselylocalizinghowtheelectricalconnector
A. TactileStateEstimation-EstimatingtheAngleofContact
ispositionedrelativetotheend-effector,asthewayinwhich
In this experiment, we evaluate how well our sensor can
the electrical connector is initially placed into the gripper
estimate the angle of contact with a surface: a basic tactile
varies,and(2)localizingthewalloutletrelativetotherobot.
state estimation task useful in a variety of grasping and
Inthistask,ourneuralnetworkmodeldirectlyoutputsthe
manipulation scenarios. To simulate a ﬁngertip contacting
desiredend-effectorpositiontargetforasuccessfulinsertion.
a surface at different angles, we set up a state estimation
The model is trained on 100 demonstrations of insertions
task where we mount the tactile sensor on a rotary actuator
of the electrical connector, provided by commanding the
robot’s motions via keyboard control. The robot starts off
3Videos and supplementary material can be found here: https://
sites.google.com/berkeley.edu/omnitact holding the plug a few centimeters away from the outlet,
622
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. z
y
x
Fig. 9: Successful insertion of electrical connector into wall
outlet using OmniTact sensor. From left to right: 1. Connec-
torisplacedbetweengripperjawsbyahuman.2.Arandom
offset is applied to the gripper position. The sensor touches
the arena ﬂoor and saves a reading from the top camera.
Top Camera Side Camera
3. Using a pre-scripted pick-up policy, gripper jaws close
Fig. 10: Experimental setup for grasping and inserting
and connector is lifted. 4. Gripper and connector approach
an electrical connector into a wall outlet. Left: OmniTact
the outlet, and the policy network is queried to determine
touching the bottom plate, causing visible indentation in
howtoadjustgripperpositionforinsertion.5.Robotapplies
the top camera image. Middle: Tactile reading from the
adjustment and inserts the connector.
side-camera after picking up the textured plug. Right: End-
effector approaching wall outlet.
TABLE III: Results of electrical connector insertion bench-
mark showing that including sensor readings from both
camerasinthepolicyinputsoutperformsusingonlyasingle V. DISCUSSIONANDFUTUREWORK
camera as well as using readings from an OptoForce sensor. Wepresentedadesignforamulti-directionaltactilesensor
PolicyInputs Successrate(30trials) using multiple micro-cameras to perceive deformations in
OmniTact(Ours)SideCameraonly 50% a gel-coated ﬁngertip. Our design demonstrates that high
OmniTact(Ours)TopCameraonly 67% resolution tactile sensing and the ability to sensorize curved
OmniTact(Ours)Side&TopCamera 80%
surfaces are not conﬂicting design goals, and that both
OptoForce 17%
can be achieved at the same time by using an arrange-
ment of multiple micro-cameras. We further showed how
a convolutional neural network can be used to estimate the
with the tip of the ﬁnger contacting a textured ﬂoor plate
angle of contact for a ﬁnger pressing against a ﬂat surface
(see Figure 10). In order to correctly determine the insertion
and perform tactile control to insert an electrical connector
pose, the model must determine how it is holding the plug
into an outlet. Experimental results show that our multi-
from the sideways-pointing camera, and correctly determine
directional OmniTact sensor obtains high sensitivity for a
where the end-effector is positioned relative to the outlet by
wider range of angles than a GelSight sensor, and results
using the pattern on the ﬂoor plate to infer the offset.
in higher success rates at inserting an electrical connector
Wecomparemodelsthatuseonlythetopcamera,onlythe purely based on touch sensing.
sidecamera,andbothcameras.Wealsocomparetoamethod A limitation of the current design is the price of the cam-
that uses inputs from an OptoForce sensor in place of our eras, the most expensive part of the sensor. The endoscope
OmniTact sensor.4 For each combination of sensor inputs, camera used in our sensor cost US$600 each, for a total
we measure the success rate over 30 trials, only counting cost of US$3200 for the complete sensor prototype with
fullpluginsertionsassuccesses.AslistedinTableIII,using 5 cameras. This price could be reduced by producing the
both the tip and side camera of our OmniTact sensor results sensor in larger quantities, or by using different cameras.
in the best performance, while using only the top camera However, once sensors of this type can be produced at scale
resultsinbetterperformancethanusingonlythesidecamera. and combined with effective algorithms that utilize touch
UsingonlyreadingsfromtheOptoForcesensorresultsinthe sensing, future robotic manipulation systems may achieve
lowest performance (only 5 out of 30 trials are successful). improved robustness and generality, particularly in delicate
Whenusingonlythetopcamera,weobservethattherobot and dexterous manipulation settings where direct perception
often fails to fully insert the plug, reﬂecting the difﬁculty of contacts through touch is critical.
of estimating the plug’s position in the gripper. When only
ACKNOWLEDGEMENTS
using the side camera, we ﬁnd that the policy has high
We thank Dan Chapman, Kuan-Ju Wu, and Chris My-
errorestimatingthecorrectlateralpositionforinsertion.This
ers from the CITRIS Invention Lab at the University of
indicates that the policy uses the top camera to localize the
California, Berkeley for their guidance on designing and
position of the end-effector relative to the plug, and uses the
manufacturing OmniTact. Additionally, we thank Professor
side camera to localize the connector in the gripper, thus
PrabalDutta,BrandenGhena,andNealJacksonfromLab11
utilizing the sensor’s multi-directional capability.
attheUniversityofCalifornia,Berkeleyfortheirelectronics
advice.ThisresearchwassupportedbyBerkeleyDeepDrive,
Honda, the Ofﬁce of Naval Research, and the National
4AnOptoForcesensoroutputsanestimateoftheforcevectoratthetip
ofitshemisphericalsensorpad. Science Foundation under IIS-1651843 and IIS-1700697.
623
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. REFERENCES ConferenceonIntelligentRobotsandSystems(IROS),2016,pp.208–
215.
[1] M. K. Johnson and E. H. Adelson, “Retrographic sensing for the
[13] A.Krizhevsky,I.Sutskever,andG.E.Hinton,“Imagenetclassiﬁcation
measurement of surface texture and shape,” in IEEE Conference on
with deep convolutional neural networks,” in Advances in neural
ComputerVisionandPatternRecognition,2009,pp.1070–1077.
informationprocessingsystems,2012,pp.1097–1105.
[2] W.Yuan,S.Dong,andE.H.Adelson,“Gelsight:High-resolutionrobot
tactilesensorsforestimatinggeometryandforce,”Sensors,2017. [14] E. Donlon, S. Dong, M. Liu, J. Li, E. Adelson, and A. Rodriguez,
[3] S. Dong, W. Yuan, and E. H. Adelson, “Improved gelsight tactile “Gelslim: A high-resolution, compact, robust, and calibrated tactile-
sensor for measuring geometry and slip,” in IEEE/RSJ International sensing ﬁnger,” in IEEE/RSJ International Conference on Intelligent
ConferenceonIntelligentRobotsandSystems(IROS),2017,pp.137– RobotsandSystems(IROS),2018,pp.1927–1934.
144. [15] J. A. Fishel and G. E. Loeb, “Sensing tactile microvibrations with
[4] N. Wettels, J. Fishel, Z. Su, C. Lin, and G. Loeb, “Multi-modal thebiotac—comparisonwithhumansensitivity,”in20124thIEEE
synergistic tactile sensing,” in Tactile sensing in humanoids—Tactile RAS EMBS International Conference on Biomedical Robotics and
sensorsandbeyondworkshop,9thIEEE-RASinternationalconference Biomechatronics(BioRob),June2012,pp.1122–1127.
onhumanoidrobots,2009. [16] N. Wettels and G. E. Loeb, “Haptic feature extraction from a
[5] M.-Y.Cheng,C.-M.Tsao,Y.-T.Lai,andY.-J.Yang,“Anovelhighly- biomimetic tactile sensor: force, contact location and curvature,” in
twistable tactile sensing array using extendable spiral electrodes,” in IEEE International Conference on Robotics and Biomimetics, 2011,
IEEEInternationalConferenceonMicroElectroMechanicalSystems, pp.2471–2478.
2009,pp.92–95.
[17] Z. Su, K. Hausman, Y. Chebotar, A. Molchanov, G. E. Loeb, G. S.
[6] P.Piacenza,W.Dang,E.Hannigan,J.Espinal,I.Hussain,I.Kymissis,
Sukhatme,andS.Schaal,“Forceestimationandslipdetection/classiﬁ-
andM.Ciocarlie,“Accuratecontactlocalizationandindentationdepth
cationforgripcontrolusingabiomimetictactilesensor,”inIEEE-RAS
predictionwithanoptics-basedtactilesensor,”inIEEEInternational
International Conference on Humanoid Robots (Humanoids), 2015,
ConferenceonRoboticsandAutomation(ICRA),2017,pp.959–965.
pp.297–303.
[7] P.Piacenza,K.Behrman,B.Schifferer,I.Kymissis,andM.Ciocarlie,
“Asensorizedmulticurvedrobotﬁngerwithdata-driventouchsensing [18] A. G. Egu´ıluz, I. Ran˜o´, S. A. Coleman, and T. M. McGinnity,
via overlapping light signals,” IEEE/ASME Transactions on Mecha- “Continuous material identiﬁcation through tactile sensing,” in 2016
tronics,pp.1–1,2020. InternationalJointConferenceonNeuralNetworks(IJCNN). IEEE,
[8] R. Li, R. Platt, W. Yuan, A. ten Pas, N. Roscup, M. A. Srinivasan, 2016,pp.4955–4961.
andE.Adelson,“Localizationandmanipulationofsmallpartsusing [20] K. Suwanratchatamanee, R. Saegusa, M. Matsumoto, and
gelsight tactile sensing,” in IEEE/RSJ International Conference on S.Hashimoto,“Asimpletactilesensorsystemforrobotmanipulator
IntelligentRobotsandSystems(IROS),2014,pp.3988–3993. and object edge shape recognition,” in IECON 2007-33rd Annual
[9] R. Calandra, A. Owens, M. Upadhyaya, W. Yuan, J. Lin, E. H. ConferenceoftheIEEEIndustrialElectronicsSociety. IEEE,2007,
Adelson,andS.Levine,“Thefeelingofsuccess:Doestouchsensing pp.245–250.
helppredictgraspoutcomes?”ConferenceonRobotLearning(CORL), [21] Y. Ito, Y. Kim, C. Nagai, and G. Obinata, “Contact state estimation
pp.314–323,2017. byvision-basedtactilesensorsfordexterousmanipulationwithrobot
[10] R. Calandra, A. Owens, D. Jayaraman, W. Yuan, J. Lin, J. Malik, hands based on shape-sensing,” International Journal of Advanced
E.H.Adelson,andS.Levine,“Morethanafeeling:Learningtograsp RoboticSystems,vol.8,no.4,p.54,2011.
andregraspusingvisionandtouch,”IEEERoboticsandAutomation [22] J. Reinecke, A. Dietrich, F. Schmidt, and M. Chalon, “Experimental
Letters(RA-L),vol.3,no.4,pp.3300–3307,2018. comparison of slip detection strategies by tactile sensing with the
(cid:13)
[11] S.Tian,F.Ebert,D.Jayaraman,M.Mudigonda,C.Finn,R.Calandra, biotacR on the dlr hand arm system,” in IEEE international Con-
andS.Levine,“Manipulationbyfeel:Touch-basedcontrolwithdeep ferenceonRoboticsandAutomation(ICRA),2014,pp.2742–2748.
predictivemodels,”inIEEEInternationalConferenceonRoboticsand
[23] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage
Automation(ICRA),2019,pp.818–824.
recognition,” in IEEE Conference on Computer Vision and Pattern
[12] W. Yuan, M. A. Srinivasan, and E. H. Adelson, “Estimating object
Recognition(CVPR),June2016,pp.770–778.
hardness with a gelsight touch sensor,” in IEEE/RSJ International
[24] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimiza-
[19] N.Chen,H.Zhang,andR.Rink,“Edgetrackingusingtactileservo,”
tion,”CoRR,vol.abs/1412.6980,2014.
in Proceedings 1995 IEEE/RSJ International Conference on Intelli-
gentRobotsandSystems.HumanRobotInteractionandCooperative
Robots,vol.2. IEEE,1995,pp.84–89.
624
Authorized licensed use limited to: University of New South Wales. Downloaded on September 20,2020 at 15:47:36 UTC from IEEE Xplore.  Restrictions apply. 