2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Aggregation and localization of simple robots
in curved environments
Rachel A. Moan Victor M. Baez Aaron T. Becker Jason M. O’Kane
Abstract—This paper is about the closely-related problems
50 mm
of localization and aggregation for extremely simple robots,
for which the only available action is to move in a given
directionasfarasthegeometryoftheenvironmentallows.Such
problems may arise, for example, in biomedical applications,
wherein a large group of tiny robots moves in response to
Move 0 0.1 0.9 Move 1
a shared external stimulus. Speciﬁcally, we extend the prior
work on these kinds of problems presenting two algorithms for
localizationinenvironmentswithcurved(ratherthanpolygonal)
boundaries and under low-friction models of interaction with
the environment boundaries. We present both simulations and
physical demonstrations to validate the approach.
Move 2 Move 3 Move 4 Move 5
I. INTRODUCTION
Fig.1. Acollectionofparticlesspreadthroughaknownenvironmentwitha
The problem of localization —that is, the process of de- curvedboundary.Theparticlesareaggregatedinresponsetocarefullyplanned
globaltranslationsoftheunderlyingsubstrate.Theframesmarked0.1and0.9
termining the location of a robot with respect to its cur-
depicttheparticlesintheprocessofexecutingtheﬁrstmove.Thiscorresponds
rent environment— is a fundamental problem in robotics. toSEQUENCE1intheattachedvideo,https://youtu.be/fVhFc41T88I.
Traditional approaches to this problem [7], [10], [11], [26],
[31] are suitable for robots of sufﬁciently large scale and
these kinds of applications —and noting that, at small scales,
sufﬁcientlyhighcomplexitythattheycancarryrangesensors,
localizingasinglerobotandaggregatingmanyrobotsbecome
cameras,orotherinformation-richsensorsforperceivingtheir
the same essential problem— we consider the localization
ownmotionsthroughtheirenvironmentsandrelativelyprecise
problem for a very simple robot with only a single capability:
actuatorsforeffectingthosemotions.Thelocalizationproblem
that of moving in a commanded direction until it reaches the
becomes more challenging when the robots are extremely
obstacle boundary. This behavior could be implemented, for
small, when they lack strong sensing and actuation abilities,
example, using a traditional mobile robot equipped with a
or both.
compass and a contact sensor, or by a swarm of medicine-
Future (and some current) biomedical robots have both
bearing micro-robots suspended in a ﬂuid and responding to
challenges. Micro and nano devices have little room onboard
an externally supplied magnetic ﬁeld [17].
forcomputationandlittlestoragespacefortheenergyrequired
Prior work by O’Kane and LaValle [23] described a family
forpropulsion.Foroverviews,seetheexcellentsurveysin[5],
oflocalizationalgorithmsforseveraltypesofextremelysimple
[6], [22], [25], [30], [32], which outline both the diverse
robots, including a model similar to the setting described
applications of tiny robots inside the body, and the challenges
above. However, the applicability of that work was strongly
of sensing and control of tiny robots. Instead of internal
limited by a deep reliance on polygonal models of the robot’s
computation and propulsion, these biomedical devices are
environment. Moreover, their algorithms depended in crucial
propelled by an external source,by biological processes (such
ways on an assumption that the robot’s motion stops im-
as blood ﬂow) or by diffusion.
mediately when it comes into contact with the environment
Manytasksforsuchrobotsincludingdrugdelivery,clotting,
boundary, without any ‘sliding’ behavior. Many biological
and targeted therapy can be characterized as aggregation
systems are slippery; nearly all are non-polygonal [13], [18],
tasks, in which devices spread through an environment are
[29].Thus,inthispaper,weshowhowtogeneralizethatprior
gatheredinasinglelocation.Motivatedbythethepotentialfor
approach to a substantially more realistic setting that removes
R.A.MoaniswiththeDepartmentofComputerScience,WinthropUniver- these two limitations. Speciﬁcally, we model the environment
sity,RockHill,SouthCarolina,USA.V.MontanoBaezandA.T.Beckerare boundary as a composite cubic Be´zier curve, and consider
with the Department of Electrical and Computer Engineering, University of
movement models and planning algorithms that can account
Houston,Houston,Texas,USA.J.M.O’KaneiswiththeDepartmentofCom-
puterScienceandEngineering,UniversityofSouthCarolina,Columbia,South for robots that may slip along the boundary after reaching it.
{
Carolina, USA. moanr2@mailbox.winthrop.edu, vjmontano, See Figure 1.
}
atbecker @uh.edu; jokane@cse.sc.edu This material is based
The main contribution of this paper is a planning algorithm
uponworksupportedbytheNationalScienceFoundationunderGrant[IIS-
1659514],[IIS-1553063],and[IIS-1619278]. for this problem, along with demonstrations of the effective-
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 165
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. ness of this approach both in simulation and in laboratory Another related problem is that of using gravity to drain
experiments. Our results are applicable both for actively lo- water out of a punctured polygon by rotating the shape [1].
calizing a single robot from a collection of possible starting For a polygon with n vertices, they provide an O(n2logn)
positions, and for aggregating a collection of simple robots time algorithm to determine the minimum number of holes
movinginresponsetocommoncontrolsignalswithinthesame required to drain the polygon.
environment.
The remainder of the paper is organized as follows. Sec- III. PROBLEMSTATEMENT
tions II and III review related work and formally deﬁne the In this section, we give a formal deﬁnition of the problem
problem,respectively.Then,inSectionIV,wedescribehowto addressed by our algorithm. The two central components
solvethepassiveproblemofpredictingtherobot’s(orrobots’) are the environment (Section III-A) and the robot model
movements in response to given movement commands, under (Section III-B).
both ‘sticking’ and ‘sliding’ models of motion. In Section V, We are interested in both localization of individual simple
we present a planning algorithm that generates motion se- robots, and in aggregation of collections of multiple robots in
quencestolocalizetherobot.Resultsfrombothsimulatedand a shared workspace. However, in this context, the problems
physical executions appear in Section VI, before concluding share much of their essential structure: we can use the same
discussion in Section VII. approach to reason about a set of candidate locations for
a robot in the process of localizing itself as for a set of
II. RELATEDWORK actualrobotlocationsduringaggregation.Thus,tosimplifythe
Effective localization, which is widely viewed as essential explanation,wedescribeourapproachusinglanguageattuned
for robot autonomy, has been intensely studied for systems to the localization interpretation.
with a variety of sensor systems [15], [16], [20], [24].
A. The environment
Representatives of the wide variety of well-known solution
approaches include techniques based on the Kalman ﬁlter [7], A robot moves within a bounded, planar, simply-connected
⊂R
[26], Markov approaches [10], [11], and Monte Carlo tech- environment E 2. We assume that the boundary of E, de-
niques [31]. noted∂E,canbedescribedasacompositecubicBe´ziercurve.
An important distinction can be made between passive That is, the boundary of E is described by a ﬁnite sequence
localization, which estimates the robot’s position using an of n curves c(1),...,c(n). Each curve c is a parametric curve
i
incoming stream of data and is based on the assumption deﬁned by four control points P(i), P(i), P(i), and P(i). A
0 1 2 3
that the motion of the robot cannot be controlled, and active scalarparametertvariesacrosstherange[0,1]intheequation
localization, which assumes that the robot’s movement and
− −
orientation can be partially or fully controlled [4]. c(i)(t)=(1 t)3P(i)+3(1 t)2tP(i)
0 1
Relative localization requires that the approximate position −
+3(1 t)t2P(i)+t3P(i). (1)
of the robot is known, whereas global localization can deter- 2 3
mine the position of a robot without any prior knowledge of To ensure that these curves deﬁne a continuous boundary for
its position [12], [28] This paper considers an active global E,werequirethattheendpointsofsuccessivecurvescoincide.
≤ ≤
localization problem. That is, for all 1 i n, we assume that P(i) = P(i+1).
3 0
Speciﬁcally, we are interested in solving such problems Similarly,toensurethatthecurvesdescribeaclosedboundary
with robots whose sensing and movement capabilities are for E, we require that P(n) = P(1). Finally, to ensure that
3 0 ≤ ≤
severely limited. Active, global localization algorithms have the boundary of E is differentiable, for all 1 i n, we
been studied from this perspective [9], [23], but only in assume that P(i), P(i), and P(i+1) are collinear with P(i) in
2 3 1 3
polygonal environments, and only executed on traditionally- the middle of the three. We assume that the curve is oriented
sized (dozens of centimeters) mobile robots. so that increasing values of t travel counterclockwise around
Micro and nano-scale robots are often steered by a global the boundary. See Figure 2 for an example.
ﬁeld, such as a magnetic, gravitational, or electric ﬁeld in
B. The robot model
such a way that all the robots get approximately the same
input commands. See overviews in [3], [5], [6], [25], [30]. For simplicity, we model the robot as a point in E. (If the
Dealingwithswarmsoftinyrobotsoffersanotherapproachto robot has a non-zero radius, as real robots generally do, we
localization, by designing a control sequence that if executed can adjust E so that its boundary corresponds to the set of
would steer all particles to a common destination. pointsthatcanbeoccupiedbytherobot’scenterpointwithout
Huang et al. studied this problem using a magnetic ﬁeld to causing a collision.) Time proceeds in a series of discrete
aggregate microscale iron particles at a goal location in [13]. stages, indexed k = 1,2,3,.... At each stage k, the robot
∈
In a discretized world where particles move on a bounded occupies a state x E.
k
polyominogrid,Mahadevetal.provedthatiterativelymoving The robot’s motion at stage k is determined by its selection
∈
oneparticletoanotherwassufﬁcienttocollectalltheparticles of an action u U, in which U is the set of unit vectors
k
to a single point in O(n3) time, where n is the total number in the plane. The intuition is that each action u describes a
k
of free spaces in the polyomino [18]. motion direction for the robot in stage k.
166
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. (1)
P
1
(2)
P (2)
2 P
1
(4) (1)
P = P
3 0
(1) (2)
P = P
3 0 P(1)
2
(2) (3)
P = P
3 0 (4)
P
1
P(3) P(3) = P(4)
1 3 0
(3)
P
2
(4)
P
2
Fig. 3. [left] Motion of the robot under the sticky (fstk) motion model.
Fig.2. Anexampleenvironmentwithn=4curves.The12distinctcontrol [right]Motionundertheslipping(fslp)motionmodel.
pointsareshown.Dashedsegmentsillustratethecolinearityconstraints.
Astherobotmoves,itcanupdatethissetincorrespondence
Weconsidertwodistinctmodelsforhowtherobot’sactions with the actions it selects. More precisely, we can deﬁne an
× →
change its state. information transition function F :2X U 2X, in which
1) Under the sticky model, the robot moves from position ∪ { }
xk in direction uk as far as possible without leaving E. F(ηk,uk)= xk∈ηk f(xk,uk) . (2)
That is, the robot moves until it reaches the boundary,
In this way, we can deﬁne a sequence of information states,
and then stops at that point. This behaviour might be
realized, for example, either via direct sensing or via staring from η1:
friction between the robot and the environment. We η =F(η ,u ). (3)
k+1 k k
express this motion model as a state transition function
× →
f : E U E, under which x = f (x ,u ). Notice that, under this model, the robot does not have access
stk k+1 stk k k
Details about how to compute f appear in Sec- toanydirectfeedbackfromitssensors.Thus,thepassiveview
stk
tion IV-A. of the localization problem viewed by some as traditional —
2) Under the slipping model, the robot moves in direc- namely, that the localization algorithm should merely process
tion u , possibly sliding along ∂E, until it reaches sensorandactiondata,withoutanycontroloverwhichactions
k
a local maximum of ∂E in that direction. We write therobotexecutes—isquiteunsuitablehere.Indeed,eventhe
× →
f :E U E andx =f (x ,u )forthestate typical ‘active localization’ viewpoint is a poor ﬁt, because
slp k+1 slp k k
transitions that occur under this motion model. Details the lack of direct sensor data in the model means that the
are in Section IV-B. robot cannot adjust its strategy based on its own observations.
As a result, the robot’s localization strategy can be expressed
Figure 3 illustrates these two models, which are intended
simplyasaﬁnitesequenceofactions,underwhichanystarting
to capture two extremal cases for how our robots may be-
have upon coming in contact with the environment. Which point in η1 is driven to the same ﬁnal point. That is, we want
of them is most appropriate in a given setting depends on to sel∈ect an action sequence u1,...,uK such that, for any
the physical characteristics of the robot and its interactions x,x(cid:48) η1,
with the boundary of E. When the difference between f
and f is not relevant, we instead write a generic f fsotkr f(x,u1,...,uk)=f(x(cid:48),u1,...,uk). (4)
slp
whicheverofthetwoisapropos.Wealsoextendthenotationto
Equivalently,weseekanactionsequencethatreducesthesize
sequencesofactions,writingf(x ,u ,u ,...,u )instead
··· ··· k k k+1 K of the information state down to a single point:
of f( f(f(x ,u ),u ) ),u ).
k k k+1 K
Problem: Localization in a curved boundary
C. The active localization problem Input: An environment E described by its 3n distinct
At the start of its execution, the robot does not know its control points, a ﬁnite list η1 of starting loca-
own location. However, we assume that the robot does have tions,andamotionmodelf (eitherfstk orfslp).
access to a ﬁnite list of possible starting locations, which we Output: A| s|equence of actions u1,...,uK, for which
denote η ⊆E. ηK =1.
1
167
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. IV. COMPUTINGACTIONEFFECTS
Before describing how to select an action sequence that
localizes the robot, we ﬁrst consider in this question the x
k+1
passive problem of determining, under the models introduced u
k x
in Section III, what the effects a given action will be. That is, k
iftherobotisatpositionx andexecutesamotionindirection
k
u ,whatlocationx willtherobotreach?Webeginwiththe
stkicking model (Seckt+io1n IV-A) and then extend that approach Fig. 4. Computing fstk. The algorithm computes a collection of candidate
locationsbyintersectingtheboundarycurveswithaline,andthenselectsthe
to the slipping model (Section IV-B). nearesteligiblepointfromamongstthecandidates.
A. Computing action effects under f
stk
Under the sticking model fstk, at stage k, the robot starts uk
at x and moves in direction u as far as possible while
k k
remaining within E. The resulting location is f (x ,u ),
stk k k u
that is, x . Computing this x is, in essence, a form of xk k x
k+1 k+1 k
ray shooting query in E.
We can parameterize the line along which the robot moves Fig.5. Handlingthecasewheres=0todeterminewhetheramovementin
as (cid:96)(s) = x +su and ﬁnd its intersections with a single direction uk would collide immediately (right) with the environment or not
k k (left).
curvec(i) along∂E bysetting(cid:96)(s)=c(i)(t),yieldingavector
equation in the two parameters s and t:
boundary— we will obtain a candidate point at x itself, that
xk+suk =at3+bt2+ct+d, (5) is, with s=0, which must be handled specially. k
in which the vector-valued constant coefﬁcients on the right- Speciﬁcally,whens=0,werelyuponthecounterclockwise
hand side are presentation of ∂E assumed in Section III and test (using
the standard clockwise test from computational geometry)
− −
a= P(i)+3P(i) 3P(i)+P(i) whether the three points (i) x , (ii) x +v where v is the
0 1 2 3 k k
b=3P(i)+6P(i)+3P(i) counterclockwise tangent vector at xk, and (iii) xk +uk are
0 1 2 arranged in clockwise order. If so, then the robot’s motion is
−
c= 3P(i)+3P(i) directly into the boundary, and the robot does not move. If
0 1
d=P(i). those three points are counterclockwise, the robot can move
0 freely away from x , and that candidate is ignored. See
k
Viewing Eq. 5 as a system of two scalar equations, we Figure 5.
eliminate s by solving each of the scalar equations for s and
equating the results. This yields a cubic equation in t, B. Computing action effects under fslp
Next, we turn to the slipping motion model f . As with
At3+Bt2+Ct+D =0, the f , the robot starts at x and moves in directsilopn u until
stk k k
in which the coefﬁcients are reaching the environment boundary. From there, f differs
slp
in that the robot may ‘slide,’ due to extremely low friction
−
A=a x a x between itself and the environment boundary. It continues to
x ky y kx
B =byukx+xkxxky moveuntilit reachesalocalmaximumof ∂E indirection uk.
The robot’s motion within a single stage can thus be
C =c u +x x
y kx− kx ky− − characterized as alternating, perhaps several times, between
D =(ukx xkx)(dy xky uky) jumping motion within the interior of ∂E and sliding motion,
+xky(dx+xkx+ukx). along ∂E. Algorithm 1 summarizes this process. Changes
∈ in the robot’s motion computed by this algorithm can be
Therealsolutionsofthisequationwithintheintervalt [0,1] characterized as jumps, where the robot reaches a point at
providetheintersectionpointsbetweenthegivencurveandthe
which the tangent to the environment boundary is parallel to
line along which the robot is moving.
the motion direction, and extrema, at which the tangent to the
Iterating this process over all n curves gives a set of at environment boundary is orthogonal to the motion direction.
most 3n candidates for xk+1. For each, we can compute the To compute such points for a given boundary curve c(i),
parameter s that determines how far ahead the robot would we need to ﬁnd values of t ∈ [0,1] for which the tangent
have moved to reach that point. In general, we select the
vector c(cid:48)(t) is parallel or antiparallel to u . This occurs when
point with the smallest non-negative s, since negati∈ve values u ·c(cid:48)(i)(t)⊥ =0.Equatingthesetwoimplkicitscalarequations
of s represent backward motion. However, if xk ∂E — gikves a quadratic in t:
an extremely common occurrence after the ﬁrst stage, since
− − −
our robot cannot stop except when it reaches the environment (a u a u )t2+(b u b u )t+(c u c u )=0,
x ky y kx x ky y kx x ky y kx
168
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. Algorithm 1 COMPUTESLIPPINGMOTION(x ,u ,E) Algorithm 2 CHOOSEMOTIONDIRECTIONS(E,η ,f)
← k k ← 1
jumps JUMPPOINTS(u ,E) k 0
← k | |
extrema EXTREMEPOINTS(u ,E) while η >1 do
← ∪ k k←
events jumps extrema (p,q) pair of distinct points in η
← (cid:54) k
while do
x x p=q
curr k ∈ ←
while x / extrema do k k+1
c←urr ⊂
if then
x f (x ,u ) pq E
c←urr stk curr k ← − || − ||
v counterclockwise tangent vector of ∂E at x u (q p)/ q p
curr k
if cw(x ,x +v,x +u⊥) then else
c←urr curr curr k ←
x nearest point to x from events, measured S(p,q) region in E hidden from p, containing q
curr curr ←
in clockwise distance around ∂E. z anchor point of S(p,q)
← − || − ||
else u (z p)/ z p
← k
x nearest point to x from events, measured end if
curr curr ←
in counterclockwise distance around ∂E. η F(η ,u )
k k k
end if end while
end while end while
←
return
x x u ,...,u
k+1 curr 1 k
return
x
k+1
a new pair of distinct possible points and repeats the process.
in which a, b, c, and d are the vector-valued constant coefﬁ- Whenonlyasinglepossiblelocationremains,thelocalization
cients of c(cid:48)(i): plan is complete.
− − How,then,canweselectactionsthatbringpandqtogether?
a= 3P(i)+9P(i) 9P(i)+3P(i) One approach is based on the following idea.
0 1 2 3
b=6P(i)−12P(i)+6P(i) Observation 1 (actions for visible points): If the line seg-
− 0 1 2 ment connecting p to q is contained entirely within E, then
c= 3P(i)+3P(i) − −
0 1 1) f (p,p q)=f (q,p q), and
stk − stk −
d=P(i). 2) f (p,p q)=f (q,p q).
0 slp slp
The real solutions of this equation, for any t on the interval This provides a mechanism for the case in which p and q can
[0,1], provide the jump points for the path of the robot. ‘see’ each other in E: We simply move in a direction parallel
to the line segment between those two points.
Repeating this process for all curves provides a list of all the (cid:54)⊂
possible jump points for the robot. The process to compute In the general case, how⊂ever, it is possible that pq E. In
the extrema nearly identical, but seeks values of t for which suchacase,weletS(p,q) E denotethemaximalconnected
u ·c(cid:48)(i)(t)=0. portionofE notvisibletopbutcontainingq.Thisregionhas
k an ‘anchor point’ z at which its bounding ray is tangent to
Algorithm 1 uses these points to determine how far the
E. See Figure 6. Under f , we can make progress toward
robot slides before its motion stops (in the case of an extreme stk
merging p with q by moving toward this point z:
point) or moves into the interior of E (in the case of a jump − −
Observation2:Letp=f (p,z p)andq(cid:48) =f (q,z p).
point.) This process continues until the robot reaches a local stk⊂ stk
Then either p(cid:48)q(cid:48) or S(p(cid:48),q(cid:48)) S(p,q).
maximum, at which point we have our f (x ,u )=x . −
slp k k k+1 Thus, the robot chooses direction z p. Under f , the
slp
V. LOCALIZATIONPLANNING process is the same, though we cannot make as strong a
guarantee that the S regions will decrease monotonically at
Based on these approaches to passively compute the out-
each step. This overall process repeats until p and q are
comes of a given action, we can now attack the problem of
merged, after which we select a new p and a new q. When
generating,foragivenenvironmentE,asetofpossibleinitial thecandidatepointshaveallbeenmergedwitheachother,the
positions η1, and a choice of motion model f; a sequence of localization plan is complete and the algorithm terminates.
actions u ,...,u that localizes our robot.
1 k
TheoverallapproachappearsasAlgorithm2.Thealgorithm VI. EXPERIMENTALRESULTS
constructs the plan sequentially, maintaining η , selecting u , This section presents the results of our experimental evalu-
k k
and then moving to stage k + 1 by computing η . The ation of the approach. We show some computed examples,
k+1
underlyingideaistoconsiderjustasinglepair(p,q)ofdistinct describe the results of a quantitative comparison against a
possible locations for the robot, and to generate motions that baseline, and show a physical demonstration.
drive those two points from their distinct current locations
A. Simulated examples
to the same ﬁnal location. In our implementation, we select p
andq atrandom.Thelocationsoftheotherpointsareupdated Figure 7 shows the simulated execution of paths computed
alongtheway.Afterpandq aremerged,thealgorithmselects forbothf andf .Eachplanwascomputedbasedonaset
stk slp
169
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. 8
q′ m) 7 RaAnldgo.m2wwiitthhffssttkk
c 6
(
q ce 5
n
p′ uk p dista 34
z n
ea 2
M
1
Fig. 6. Selecting motions that merge p and q. If p cannot see q, it moves 0
towardthetangentpointof∂E thathidesq fromp. 0 20 40 60 80 100 120 140 160
Timeelapsed(s)
7
Alg.2withfslp
m) 6 Randomwithfslp
(c 5
e
nc 4
a
dist 3
an 2
e
M
1
0
0 2 4 6 8 10 12
Timeelapsed(s)
Fig.8. Comparisonoflocalizationprogressasafunctionoftime.[top]Under
fstk [bottom]Underfslp
Fig. 7. Simulated paths generated by our algorithm. Starting locations are
shownwithopencircles;thesingleﬁnallocationisshownwithaﬁlledcircle. UR3  Acrylic boundaries are  2 mm glass 50 mm
[[lreigfth]t]AAseqsueqenuceencoef1o1fa4ctaiocntisongsengeeranteerdatuendduerndfestrkffsolprafsoirmaplemeonrveircoonmmpelnetx. arm inside lighted bucketGcaomPreora  Dbeuaadl lsock 
environment.Seevideoforanimation[21]. boundary
η1 of 50 randomly selected points. From these starting points, Move 0
our algorithm generated plans of length 11 and 4 respectively.
Isolation 
In both cases, from each starting point, executing the same bucket
action sequence, the simulated robots all reached the same
ﬁnal point.
White 
hardboard table
B. Quantitative evaluation Move 5
Fig.9. ArobotarmexecutesaplangeneratedbyAlgorithm2usingahigh-
We evaluated the success of our algorithm quantitatively
by measuring the average distance between the particles after fSreicetivoindesocehntatpriso:/,/ysooluvteud.bues/fiVnghFfcst4k1.T[8r8igIhfto]rtwfuollsnexappsehriomtsenfrto[m21t]h.esequence.
each action was executed. Using the environment in Figure 1,
we selected 25 random starting positions, and executed Al- boundaries are translated above the table, the seed beads stay
gorithm 2, using both f and f . We then simulated those in place until a boundary wall touches them. We then place
stk slp
plans and periodically calculated the mean distance between an inverted plastic bucket over the acrylic tray and attach
theparticles,asameasureoftheprogresstowardlocalization; them. The bucket is ﬁlled with LED lights and a camera is
when the distance reaches 0, the robot is localized. For afﬁxed above the assembly, looking down. The bucket is then
comparisonpurposes,wealsoimplementedasimplealgorithm translatedbyaUR3robotarmalongaprecomputedtrajectory.
that selects motion directions uniformly at random. (There is In this work we used two different walls. The unadorned
some evidence that simple random plans can be surprisingly acrylicwallsreproducetheslipping(f )motionmodel,while
slp
successfulincontextslikethis[19].)Theresults,whichappear attaching a thin strip of Dual Lock (3M Reclosable Fastener)
in Figure 8, show that our approach achieves a meaningful reproduce the sticky (f ) motion model.
stk
improvementintheefﬁciencyoflocalizationcomparedtothis
VII. CONCLUSIONANDFUTUREWORK
baseline.
This paper presented a localization/aggregation technique
C. Physical proofs-of-concept for extremely simple robots within a Be´zier curve boundary.
There are many methods to generate global inputs on a A number of interesting questions remain for future work.
2D set of particles, ranging from gravity-based tilting [8], Chief among them is the question of optimality; rather than
[19], using light to steer kilobots [27], or magnetic ﬁelds on arbitrarily choosing a pair of points to merge, one might
cells[2]orparticles[14].Inthiswork,weuseatabletopmade attemptplansthattakeamoreglobalview,withaneyetoward
of white tile hardboard (often used to make markerboards). minimizing the plan’s execution time. Interesting questions
The boundaries are laser cut from 6 mm thick acrylic and the also remain about motion models situated between the two
particlesare2mmdiameterglassseedbeads.Whentheacrylic extremes considered here.
170
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [17] A. S. Lu¨bbe, C. Alexiou, and C. Bergemann, “Clinical applications of
magneticdrugtargeting,”JournalofSurgicalResearch,vol.95,no.2,
[1] G. Aloupis, J. Cardinal, S. Collette, F. Hurtado, S. Langerman, and
pp.200–206,2001.
J.ORourke,“Drainingapolygon—or—rollingaballoutofapolygon,”
[18] A. V. Mahadev, D. Krupke, J.-M. Reinhardt, S. P. Fekete, and A. T.
Computationalgeometry,vol.47,no.2,pp.316–328,2014.
Becker,“Collectingaswarminagridenvironmentusingshared,global
[2] D.ArbuckleandA.A.Requicha,“Self-assemblyandself-repairofarbi-
inputs,”in2016IEEEInternationalConferenceonAutomationScience
traryshapesbyaswarmofreactiverobots:algorithmsandsimulations,”
andEngineering(CASE). IEEE,2016,pp.1231–1236.
AutonomousRobots,vol.28,no.2,pp.197–211,2010.
[19] P.Mannam,A.V.Volkov,R.Paolini,G.Chirikjian,andM.T.Mason,
[3] A.T.Becker,“Controllingswarmsofrobotswithglobalinputs:Breaking
“Sensorless pose determination using randomized action sequences,”
symmetry,”inMicrobiorobotics. Elsevier,2017,pp.3–20.
Entropy,vol.21,no.2,p.154,2019.
[4] W.Burgard,D.Fox,andS.Thrun,“Activemobilerobotlocalization,”
[20] F.Martinelli,“Arobotlocalizationsystemcombiningrssiandphaseshift
inIJCAI,1997,pp.1346–1352.
inuhf-rﬁdsignals,”IEEETransactionsonControlSystemsTechnology,
[5] X.-Z. Chen, M. Hoop, F. Mushtaq, E. Siringil, C. Hu, B. J. Nelson,
vol.23,no.5,pp.1782–1796,2015.
and S. Pane, “Recent developments in magnetically driven micro-and
[21] R. A. Moan, V. M. Baez, A. T. Becker, and J. M. OKane,
nanorobots,”AppliedMaterialsToday,vol.9,pp.37–48,2017.
“Aggregating simple robots in curved environments,” March 2020.
[6] S. Chowdhury, W. Jing, and D. J. Cappelleri, “Controlling multiple
[Online].Available:https://youtu.be/fVhFc41T88I
microrobots:recentprogressandfuturechallenges,”JournalofMicro-
[22] B. J. Nelson, I. K. Kaliakatsos, and J. J. Abbott, “Microrobots for
BioRobotics,vol.10,no.1-4,pp.1–11,2015.
minimallyinvasivemedicine,”Annualreviewofbiomedicalengineering,
[7] A.CurranandK.J.Kyriakopoulos,“Sensor-basedself-localizationfor
vol.12,pp.55–85,2010.
wheeledmobilerobots,”JournalofRoboticSystems,vol.12,no.3,pp. [23] J. M. O’Kane and S. M. LaValle, “Localization with limited sensing,”
163–176,1995. IEEETransactionsonRobotics,vol.23,no.4,pp.704–716,2007.
[8] M. A. Erdmann and M. T. Mason, “An exploration of sensorless [24] T.Pire,T.Fischer,J.Civera,P.DeCristo´foris,andJ.J.Berlles,“Stereo
manipulation,”IEEEJournalonRoboticsandAutomation,vol.4,no.4, paralleltrackingandmappingforrobotlocalization,”in2015IEEE/RSJ
pp.369–379,1988. International Conference on Intelligent Robots and Systems (IROS).
[9] L. H. Erickson, J. Knuth, J. M. O’Kane, and S. M. LaValle, “Prob- IEEE,2015,pp.1373–1378.
abilistic localization with a blind robot,” in 2008 IEEE International [25] F. Qiu and B. J. Nelson, “Magnetic helical micro-and nanorobots:
ConferenceonRoboticsandAutomation. IEEE,2008,pp.1821–1827. Toward their biomedical applications,” Engineering, vol. 1, no. 1, pp.
[10] D. Fox, W. Burgard, and S. Thrun, “Active markov localization for 021–026,2015.
mobile robots,” Robotics and Autonomous Systems, vol. 25, no. 3-4, [26] S.RezaeiandR.Sengupta,“Kalmanﬁlter-basedintegrationofdgpsand
pp.195–207,1998. vehiclesensorsforlocalization,”IEEETransactionsonControlSystems
[11] ——,“Markovlocalizationformobilerobotsindynamicenvironments,” Technology,vol.15,no.6,pp.1080–1088,2007.
Journalofartiﬁcialintelligenceresearch,vol.11,pp.391–427,1999. [27] M.Rubenstein,C.Ahler,N.Hoff,A.Cabrera,andR.Nagpal,“Kilobot:
[12] P. Goel, S. I. Roumeliotis, and G. S. Sukhatme, “Robust localization A low cost robot with scalable operations designed for collective
using relative and absolute position estimates,” in Proceedings 1999 behaviors,”RoboticsandAutonomousSystems,vol.62,no.7,pp.966–
IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems. 975,2014.
Human and Environment Friendly Robots with High Intelligence and [28] S. Se, D. Lowe, and J. Little, “Local and global localization for
EmotionalQuotients(Cat.No.99CH36289),vol.2. IEEE,1999,pp. mobilerobotsusingvisuallandmarks,”inProceedings2001IEEE/RSJ
1134–1140. InternationalConferenceonIntelligentRobotsandSystems.Expanding
[13] L. Huang, L. Rogowski, M. J. Kim, and A. T. Becker, “Path planning the Societal Role of Robotics in the the Next Millennium (Cat. No.
and aggregation for a microrobot swarm in vascular networks using a 01CH37180),vol.1. IEEE,2001,pp.414–420.
globalinput,”in2017IEEE/RSJInternationalConferenceonIntelligent [29] S.Shahrokhi,H.Zhao,andA.T.Becker,“Reshapingparticleconﬁgura-
RobotsandSystems(IROS). IEEE,2017,pp.414–420. tionsbycollisionswithrigidobjects,”in2019InternationalConference
[14] P. S. S. Kim, A. T. Becker, Y. Ou, A. A. Julius, and M. J. Kim, onRoboticsandAutomation(ICRA). IEEE,2019,pp.4436–4443.
“Imparting magnetic dipole heterogeneity to internalized iron oxide [30] M. Sitti, H. Ceylan, W. Hu, J. Giltinan, M. Turan, S. Yim,
nanoparticlesformicroorganismswarmcontrol,”JournalofNanoparti- and E. D. Diller, “Biomedical applications of untethered mobile
cleResearch,vol.17,no.3,pp.1–15,2015. milli/microrobots.”ProceedingsoftheIEEE,vol.103,no.2,pp.205–
[15] P. Koch, S. May, M. Schmidpeter, M. Ku¨hn, C. Pﬁtzner, C. Merkl, 224,2015.
R.Koch,M.Fees,J.Martin,D.Ammonetal.,“Multi-robotlocalization [31] S. Thrun, D. Fox, W. Burgard, and F. Dellaert, “Robust monte carlo
andmappingbasedonsigneddistancefunctions,”JournalofIntelligent localizationformobilerobots,”Artiﬁcialintelligence,vol.128,no.1-2,
&RoboticSystems,vol.83,no.3-4,pp.409–428,2016. pp.99–141,2001.
[16] A. Ledergerber, M. Hamer, and R. D’Andrea, “A robot self- [32] B.Wang,Y.Zhang,andL.Zhang,“Recentprogressonmicro-andnano-
localization system using one-way ultra-wideband communication,” in robots:Towardsinvivotrackingandlocalization,”Quantitativeimaging
2015 IEEE/RSJ International Conference on Intelligent Robots and inmedicineandsurgery,vol.8,no.5,p.461,2018.
Systems(IROS). IEEE,2015,pp.3131–3137.
171
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 10:23:03 UTC from IEEE Xplore.  Restrictions apply. 