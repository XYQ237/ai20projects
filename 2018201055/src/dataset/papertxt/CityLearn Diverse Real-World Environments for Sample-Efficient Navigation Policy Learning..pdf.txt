2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point
Atrous Convolution for Unorganized 3D Points
Liang Pan1, Chee-Meng Chew2 and Gim Hee Lee3
Abstract—Motivated by the success of encoding multi-scale
contextual information for image analysis, we propose our
PointAtrousGraph (PAG) - a deep permutation-invariant hi-
erarchicalencoder-decoderforefﬁcientlyexploitingmulti-scale
edgefeaturesinpointclouds.OurPAGisconstructedbyseveral
novelmodules,suchasPointAtrousConvolution(PAC),Edge- Fig. 1. Point Atrous Convolution (better view in color). The ﬁgure
preserved Pooling (EP) and Edge-preserved Unpooling (EU). on the left denotes the conventional method in selecting neighboring
{ }
Similarwithatrousconvolution,ourPACcaneffectivelyenlarge points q1,q2,q3,q{4,q5 , and the rig}ht ﬁgure denotes our constructed
receptive ﬁelds of ﬁlters and thus densely learn multi-scale neighborhoodgraph q2,q4,q6,q8,q10 withsamplingrateequalsto2.By
point features. Following the idea of non-overlapping max- addingthesamplingrateparameter,ourPACcanperformtheconvolution
operationoveralargerﬁeldofviewwithoutincreasingcomputationload.
pooling operations, we propose our EP to preserve critical
edge features during subsampling. Correspondingly, our EU
point independently and meanwhile overlooks local geo-
modulesgraduallyrecoverspatialinformationforedgefeatures.
Inaddition,weintroducechainedskipsubsampling/upsampling metric details. PointNet++ [6] adaptively combines multi-
modulesthatdirectlypropagateedgefeaturestotheﬁnalstage. scale local features by its proposed abstraction layer. There
Particularly, our proposed auxiliary loss functions can further are nearly the same encoded local feature vectors if two
improve our performance. Experimental results show that our
selected controid points share the same local regions. These
PAG outperform previous state-of-the-art methods on various
permutation-invariant networks [7], [8] that capture ﬁne
3D semantic perception applications.
geometricstructuresfromlocalneighborhoodsprovidebetter
I. INTRODUCTION point cloud inference results, which is evident that fea-
tures of local neighbors can improve deep learning on 3D
Owingtotheeffectivenessincapturingspatially-localcor-
points.Nonetheless,receptiveﬁeldsoftheirﬁltersarelimited
relations of convolution operations, deep convolution neural
to small local regions by constructing local neighborhood
networks (CNNs) have yielded impressive results for many
graphs. Most recently, PAN [9] introduces a novel Point
image-based tasks. In order to encode multi-scale contextual
Atrous Convolution (PAC) module, which can effectively
information, CNNs probe incoming image features with
enlarge receptive ﬁelds of ﬁlters by introducing a sampling
ﬁlters or pooling operations at multiple rates and multiple
rate to equivalently sparsely sample the neighboring point
effective ﬁelds-of-view [1], such as Atrous Spatial Pyramid
features. PAN can densely exploit multi-scale edge features
Pooling (ASPP) [2] and Pyramid Pooling Module [3], [4].
by using PAC modules with different sampling rates. How-
Bothstrategieseffectivelycapturethecontextualinformation
ever, PAN does not have a hierarchical encoder-decoder
at multiple scales, hence signiﬁcantly improving the capa-
architecture, which becomes inefﬁcient when dealing with
bilities of CNNs. Unorganized point cloud is a simple and
high-dimensional dense point features.
straight-forwardrepresentationof3Dstructures,whichisfre-
In this paper, we propose the PointAtrousGraph (PAG)
quently applied by modern intelligent robotics applications,
- a deep permutation-invariant hierarchical encoder-decoder
such as autonomous driving and human-robot interactions.
to exploit multi-scale local geometric details with novel
However, the unorderedness and irregularity of 3D point
PAC modules for point cloud analysis. To address the
clouds make the conventional convolution operation inappli-
overlapped neighborhood graph problem (elaborated in
cable. Despite novel ﬁltering kernels are recently proposed,
Sec. III), we apply our edge-preserved pooling (EP) opera-
limited studies have been carried out on designing deep
tion to preserve critical edge features during subsampling.
hierarchical encoder-decoder architectures to learn multi-
Therefore, our PAG can exploit and preserve multi-scale
scale point features for 3D semantic perception.
local geometrical details hierarchically. In a similar fashion,
PointNet [5] is a pioneering permutation-invariant net-
our edge-preserved unpooling (EU) operation is applied to
work that directly processes unordered point clouds by
recover the spatial information of sparse high-dimensional
using many symmetric functions. It considers each 3D
point features. Furthermore, we introduce tailored chained
skip subsampling/upsampling modules to directly propagate
1Liang Pan is with Advanced Robotics Centre, National University of
pointfeaturesfromeachhierarchy.Additionally,wepropose
Singaporepan.liang@u.nus.edu
2Chee-Meng Chew is with Department of Mechanical Engineering, novel auxiliary loss functions, maximum mean discrepancy
NationalUniversityofSingaporechewcm@nus.edu.sg (MMD) loss and deeply supervised loss, which further
3GimHeeLeeiswithComputerVisionandRoboticPerception(CVRP)
increases our inference accuracy. Our PAG also requires
Lab, Department of Computer Science, National University of Singapore
dcslgh@nus.edu.sg less training memory consumption and shorter training time
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1113
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. than most existing networks that highly rely on neigh-
borhood graphs in 3D points. Experiments show that our
PAG achieves better performance than previous state-of-the-
art methods in various point cloud applications, including
3D object classiﬁcation, object-part segmentation and 3D
Local details of 
semantic segmentation. 1024 points 512 points Neighboring search neighboring connections
Fig. 2. Constructed local neighborhood graphs in 3D points during
subsamplingprocesses(betterviewincolor).
II. RELATEDWORK
Unorganized Point Cloud Analysis. Due to the un- buildingblock,whichcaneffectivelylearnmulti-scaledense
orderedness of 3D points, a point cloud with N 3D points edge features in 3D points. Furthermore, we propose our
has a total of N! permutations in the data feeding order. edge-preserved pooling (EP) operation, which beneﬁts in
Hence, it is important for a network to maintain invari- constructing deep hierarchical networks by preserving crit-
ance of all possible permutations [5]. The pioneering work ical edge features during subsampling processes. Our EP
PointNet [5] achieves permutation-invariance by applying operation also enlarges the receptive ﬁelds by decreasing
symmetricfunctions.Manyfollowingworks[6],[10],[7],[8] 3D point feature density. In a similar manner, our edge-
propose more complicated symmetric operations to exploit preserved unpooling (EU) operation gradually recovers the
local geometrical details in 3D points. Semantic labeling high-dimensional point feature density by considering 3D
on point cloud is more challenging than classiﬁcation and point spatial locations. We also directly propagate point fea-
object-part segmentation. SPG [11] and SGPN [12] both tures from different hierarchies to the ﬁnal stage by tailored
constructsuperpointgraphstoreﬁnetheirsemanticlabeling chained skip subsampling/upsampling modules. In addition,
results.PAN[9]proposesanovelPACmoduletoeffectively we propose novel auxiliary losses to further increase our
exploitmulti-scalelocaledgefeatures.However,unlikemany inference accuracy.
networks for semantic labeling tasks on images, they [11],
A. Point Atrous Convolution for Dense Point Feature
[12], [13], [9] do not have hierarchical encoder-decoder
architectures, which limits their performance. Two typical methods, ball query and k-nearest neighbors
Hierarchical Encoder-Decoder. Typically, deep hierar- (kNN), are applied to exploit local geometric details in
chical encoder-decoder architectures contain: (1) an en- point clouds. However, the ball query algorithm applied
coder module that progressively reduces the feature res- by PointNet++ [6] always selects the ﬁrst #K points in a
olution, enlarges the receptive ﬁelds of ﬁlters and cap- speciﬁed search ball with a predeﬁned radius, which cannot
tures higher semantic information; (2) a decoder module guaranteethatclosestpointscanbeselected[31].Inorderto
that gradually recovers the spatial information [1]. Deep exploit sufﬁcient local contextual information in 3D points,
conventional networks either construct large neighborhood
hierarchical encoder-decoder architectures are widely and
graphs (large #K) [7], [8] or concatenate multi-scale local
successfully used for many image-based tasks, such as hu-
edge features (large #C ) [32], [6]. Both above strategies,
man pose estimation [14], [15], semantic segmentation [16], f
however, make their networks cumbersome and inefﬁcient.
[17], [18], [19], [20], [21], [22], [23], [24], [25], optical
ﬂow estimation [26], [27], and object detection [28], [29], In contrast, Point Atrous Convolution (PAC) [9] can arbi-
[30]. The encoder-decoder architecture, stacked hourglass trarilyenlargeitsreceptiveﬁeldindensepointfeatureswith-
module, is based on the successive steps of pooling and out increasing its computation volume (small #K and #Cf).
upsampling, which produces impressive results on human Inspired by atrous convolution [33] for image analysis, PAC
pose estimation [14]. Lin et al. [28] introduced the feature modulesintroduceanimportantsamplingrateparameterrto
pyramid network for object detection. As for semantic seg- equivalently sparsely sample the neighboring point features.
mentation tasks, U-Net [16] and DeconvNet [25] follow the A PAC operation can be formulated as:
(cid:48) · ·
symmetricencoder-decoderarchitectures,andtheyreﬁnethe X =g(H (X ,X1r),...,H (X ,Xkr)), (1)
p Θ p q Θ p q ·
segmentation masks by utilizing features in low-level layers. where X is the feature of this centroid point p, Xkr is
p · q
DeepLabv3+[1]takesadvantageofboththeencoder-decoder the feature of the (k r)th nearest neighbor of point p,
(cid:0) (cid:1)
architectureandtheatrousconvolutionmodulestoeffectively r is the sampling rate, k is the number of total searched
·
change the ﬁelds-of-view of ﬁlters to capture multi-scale neighboringpoints,g()denotesamax-poolingfunction,and
· ⊕ − ·
contextual information, which provides new state-of-the-art H () denotes the edge kernel h X (X Xkr) . h
Θ ⊕ θ p p q θ
performance on many semantic segmentation benchmarks. is a shared mlp layer and denotes feature concatenation
operation. An example is also illustrated in Fig. 1.
III. METHODS
B. Non-overlapping Max-pooling
OurPointAtrousGraph(PAG)isfocusedonlearningmulti-
scale edge features by applying a deep hierarchical encoder- Pooling layers, especially non-overlapping max-pooling
decoder architecture. To maintain the permutation-invariant layers, are widely used in CNNs [34], [35], which sum-
property, our PAG is made up of symmetric functions, such marizes the outputs of neighboring groups of neurons in
as shared mlp, max-pooling and feature concatenation. In the same kernel map in image domains [36]. Scherer et
particular, the PAC module is applied as a fundamental al. [37] report that the increment of step size of overlapping
1114
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. Neighboring“Selected”Points using a symmetric hierarchical encoder-decoder architec-
ture [16], [25]. Our edge-preserved unpooling (EU) module
Similar Encoded Features
also considers the point features of centroids and their local
Overlapped Neighborhood Graphs
neighboring point features searched in metric spaces. Unlike
Fig.3. Theoverlappedneighborhoodgraphproblem. PointNet++, our EU module does not need to consider the
pooling windows deteriorates their recognition performance “d-dim coordinates” associated with each point:
(cid:48) ⊕
because maxima in overlapping window regions are merely X =Xe w(X1,...,Xk), (3)
p p q q
duplicatedinthenextlayerandneighboringpixelsaremore where Xe is the corresponding feature propagated from the
p ·
correlated. Cires¸an et al. [38] replace subsampling layers encoder by a skip connection directly, w() is the inverse
with non-overlapping max-pooling layers in the CNNs [39], distance weighted average operation and Xk is feature of
q
which achieves surprisingly rapid learning speed and better the kth nearest neighbor of point p in its previous hierarchy.
performance. Various subsampling methods on 3D point
D. Deep Hierarchical Encoder-Decoder
clouds[40],[6]havebeenproposed.Nonetheless,theyeither
do not summarize local geometrical features, or ignore the Based on our PAC, EP and EU modules, we construct
problem caused by overlapped local neighborhood graphs. the deep hierarchical encoder-decoder architecture PointA-
An example for 3D points subsampling processes is illus- trousGraph (PAG) to learn multi-scale features for 3D point
trated in Fig. 2. The input point feature size is 1,024, and classiﬁcation and segmentation tasks (shown in Fig. 4). The
512pointfeaturesareselectedafterasubsamplingprocess.If same encoder architecture is applied by our classiﬁcation
onlythosefeaturesof“selected”pointsarepropagated,local and segmentation networks, which consists three hierarchies
geometric details will thus be overlooked. Another strategy to gradually reduce the point feature density and meanwhile
is to propagate edge features by considering the features of enlargethereceptiveﬁeldsforlearninghighersemanticpoint
localneighboringpoints(alsoshowninFig.2).Thesearched features. Within each hierarchy, we successively lay out two
neighboring point features often consist of both “selected” PAC layers with increasing sampling rates to gradually ex-
pointfeatures(showninpink)and“discarded”pointfeatures ploitlargerlocalgeometricdetails.Ourdecoderarchitectures
(showninblue)duringsubsampling.Two“selected”centroid aredesigneddifferentlywithrespecttodifferentapplications.
points can often have overlapped neighborhood graphs, and In addition, we also propose different skip connection mod-
even share the same local neighboring points. Hence, if ules,chainedskipsubsamplingandchainedskipupsampling,
we propagate the encoded neighboring point features, two for classiﬁcation and segmentation, respectively.
neighboring “selected” points can have similar or even the Classiﬁcation Network. Our classiﬁcation network (en-
same features. The respective information of each 3D point closed by red dashed lines in Fig. 4) aims to encode a
vanishes, especially when multiple subsampling operations global point feature vector by exploiting multi-scale local
are performed to construct a deep hierarchical network for geometrical details in a point cloud. The main stream is
3D points. We entitle this as the overlapped neighborhood our network encoder, which unravels the multi-scale contex-
graph problem shown in Fig. 3. tual information capturing problem by applying many PAC
modules in a hierarchical fashion. In addition to the main
C. Edge-preserved Pooling & Edge-preserved Unpooling
stream which consecutively propagates features, we also
In view of this, we propose our edge-preserved pooling propose the chained skip subsampling module (enclosed
(EP) module, which effectively captures local geometrical by blue dash-dotted lines in Fig. 4). The chained skip
details while maintaining preserving respective features of subsampling module progressively feeds forward features of
each point. In line with the idea of non-overlapping max- eachhierarchytotheﬁnalstage.Ineachhierarchy,weselect
pooling operations, we encode local edge features by con- the same set of centroid points with the corresponding EP
sidering neighboring point features in the original 1,024 module to construct local neighborhood graphs. However,
points. Due to the absence of regular grids in 3D point we only propagate features of the neighbors in the chained
clouds, we select neighboring point features by constructing skip subsampling operations, which is different from the EP
neighborhood graphs in metric spaces. To preserve both module.Afterconcatenatinghierarchicalpointfeaturesfrom
distinctive individual point features and local geometrical both streams, the global feature is obtained by applying a
edge features, our EP module is designed as: global max-pooling. Thereafter, two fully-connected (FC)
(cid:48) ⊕
X =X g(X1,...,Xk), (2) layers are employed to yield the ﬁnal classiﬁcation results.
p p q q
where X is the feature of selected centroid and Xk is Segmentation Network. A segmentation task can be re-
p q
the point features of its k nearest neighbors. Consequently, gardedasaper-pointclassiﬁcation.Hence,oursegmentation
our EP operation explicitly propagates point features of network (enclosed by golden dashed lines in Fig. 4) densely
each “selected” centroid and also summarizes its local point learns multi-scale edge features for each input 3D point.
features, which is consistent with the idea behind non- Accordingly, we propose a hierarchical decoder to progres-
overlapping max pooling for propagating image features. sively recover the high-dimensional point feature density.
To recover spatial information for image features, low- Our decoder for segmentation has a similar architecture as
level image features from encoder are often applied to our encoder, which also has three hierarchies. Likewise, we
reﬁne the high-level features in decoder, especially when lay out two PAC layers with decreasing sampling rates to
1115
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. PAC + BN + ReLU EP
Segmentation
Coarse
Prediction
MMD Shared MLP Max Pooling
Input Points F+ CD r+o BpoNu +t ReLU EU
Category Prob.  Feature 
(Seg.) Concat.
Chained Skip Upsampling
Classification  Category Prob.
Chained Skip Subsampling (Cls.)
Fig.4. OurPointAtrousGraph(PAG)architecture(betterviewincolor).Ourclassiﬁcationandsegmentationnetworkshavethesamedesignednetwork
encoder architecture. Our classiﬁcation network is enclosed by red dashed lines, and our segmentation network is enclosed by golden dashed lines.
The chained skip subsampling module is applied in our classiﬁcation network, which is enclosed by blue dash-dotted lines. Likewise, our chained skip
upsamplingmoduleisenclosedbypinkdash-dottedlinesinoursegmentationnetwork.
gradually aggregate features for each point. Particularly, we details. However, limited attentions have been received on
apply the regressed global features, which largely increases designing deep hierarchical encoder-decoder architectures
our performance. We also employ the chained skip up- for capturing multi-scale local contexts. In contrast, our
sampling module to consecutively upsample point features PAG-adeephierarchicalencoder-decoder,adaptivelylearns
of each hierarchy (enclosed by pink dash-dotted lines in multi-scale edge features by varying the ﬁeld of view for
Fig. 4). At each stage, we apply the same upsampling ﬁlters in each layer. Motivated by the success of exploiting
strategy with the EU module with the same constructed multi-scale contextual information by operations for image
local neighborhood graphs. Unlike EU module, we do not feature learning [17], [33], [44], [25], [3], such as atrous
concatenatethecentroidfeatures.Finally,weconcatenateall convolution, non-overlapping max-pooling and unpooling,
the hierarchical features for each 3D point to perform pre- we apply novel modules, including PAC, EP and EU, for
point predictions. our multi-scale edge feature learning in unorganized 3D
points. Our PAC module effectively enlarges its receptive
E. Auxiliary Loss Functions
ﬁeld in dense point features without increasing training
We also introduce auxiliary losses, maximum mean dis- parameters. With our EP modules, our PAG is capable of
crepancy (MMD) and deeply supervised losses, which are propagatinghigh-dimensionalfeatureswhilepreservinglocal
mainly applied for segmentation tasks. edge features and respective information of each point. To
MMD criterion [41] that is commonly used in variational recover the density for point features, we apply interpo-
auto-encoder architectures is performed over our embeded lation operations by considering features of those spatial
globalpointfeatures.TheMMDlossquantiﬁesthesimilarity neighboring points. The proposed auxiliary loss functions
between two distributions by comparing all their moments. further increase our network performance. Moreover, our
By applying the kernel trick, the MMD loss is deﬁned as: hierarchical architecture consists of multiple subsampling
(cid:107) (cid:48) (cid:48) operations, which signiﬁcantly decreases its computation
L (q p)=E (cid:48) [k(z,z )]+E (cid:48) [k(z,z )]
mmd q(z),q(z) p(z),p(z)
− (cid:48) amount and thus largely increases the efﬁciency.
2E (cid:48) [k(z,z )], (4)
≥ q(z),p(z)
where L 0, q(z) denotes our embeded feature dis- IV. EXPERIMENTS
mmd
tribution and p(z) denotes a prior Gaussian distribution (we
Our PAG is evaluated on three point cloud analysis tasks,
use N(µ=0,σ =1.0)). L =0 if and only if q =p.
mmd including shape classiﬁcation, object-part segmentation and
Similarwithimage-basedsegmentationnetworks[3],[42],
semantic segmentation. Without additional processes, our
we add a deeply supervised (cross-entropy) loss L at the
ds PAG outperform previous state-of-the-art methods.
ﬁrst stage of our segmentation network decoder. Along with
themasterbranch(cross-entropy)lossL ,auxiliaryloss A. Implementation Details
master
functionsalsopassthroughallpreviouslayers.Consequently,
Our networks are implemented with TensorFlow [45] on
we train our segmentation network by minimizing the fol-
an NVIDIA GTX1080Ti GPU. We report our results with
lowing joint loss function:
respect to different input and training strategies to achieve
Lall =Lmaster+wmmdLmmd+wdsLds, (5) fair comparisons for shape classiﬁcation. For segmentation
where w and w are designed weights to balance tasks, we follow the same training and evaluation setting
mmd ds
corresponding auxiliary losses. in [5]. To improve efﬁciency, we ﬁx #K = 10 for all our
neighborhood graphs. We apply the farthest point sampling
F. Discussion
(FPS) algorithm [6] for subsampling points by considering
Manynetworks[5],[8],[40]thatrespectthepermutation- their metrics (static) or features (dynamic). Our code and
invariant property are focused on designing convolution ker- models are publicly available on the project website1.
nels for unordered 3D points. Previous studies [6], [7], [8],
[43],[10]revealeffectivenessofconsideringlocalgeometric 1https://github.com/paul007pl/PointAtrousGraph
1116
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. TABLEI
SHAPECLASSIFICATIONRESULTSONMODELNET40[46].
Method Input OA Mem. Time
PointNet[5] 1,024pts 89.2 2.4GB 3-6h
(cid:39)
PointNet++[6] 1,024pts 90.7 11.1GB 20h
Wang(41-spec-cp)[47] 1,024pts 91.5 - (cid:39)12h
on MRTNet(kd-tree)[48] 4,000pts 91.7 - -
ati DGCNN[7] 1,024pts 92.2 8.9GB 11.4h
ot
R PAN[9] 1,024pts 92.2 9.2GB 8.7h
xis PAG(ours) 1,024pts 92.2 2.4GB 4.4h
p-a PointNet++[6] 5,000pts+n 91.9 - - Fig. 5. Curve showing our advantage of dealing with non-uniform
U SpiderCNN[8] 1,024pts+n 92.4 11.3GB - distributed point inputs. DP denotes randomly dropout input points, and
With Wang(41-spec-cp)[47] 2,048pts+n 92.1 - (cid:39)20h THRESdenotesadditionalradiithresholds.
PAN[9] 1,024pts+n 92.6 9.2GB 8.8h TABLEII
PAG(ours) 1,024pts+n 92.7 2.6GB 4.5h
ABLATIONSTUDYOFTHECLASSIFICATIONNETWORK.
KCNet[10] 1,024pts 91.0 - -
Atzmonetal.[49] 1,024pts 92.3 - (cid:39)25h K PAC Centroid/Neighbors C(cid:88)SS OA
otation PSoOi-nNtCetN[N4•3][50] 12,,002448ppttss 9920..59 -- (cid:39)-3h 1200 (cid:88)(cid:88)× bbootthh (cid:88) 9921..09
Up-axisR APPAA-CNGN[N(9o]u[3r1s]) 111,,,000222444ppptttsss 999323...611 92..24-GGBB 84..-74hh 11110000 (cid:88)(cid:88)(cid:88) nceeibbngoothrttbohhoidrs (cid:88)(cid:88)(cid:88)× 99992122....2707
o SO-Net[43] 5,000pts+n 93.4 - -
W/ PAN[9] 5,000pts+n 93.4 - - applying two searching radii to bound selected neighboring
PAG(ours) 5,000pts+n 93.8 - -
points in a speciﬁed searching ﬁeld (r , r ). Those
min max
B. Shape Classiﬁcation searching radii denote the distance between a centroid point
anditsneighboringpoint.Inlinewith[6],werandomlydrop
We evaluate the performance of our network for shape
points (DP) to imitate non-uniform and sparse input points.
classiﬁcation on the ModelNet40 dataset [46]. ModelNet40
In our experiments, we observe that applying additional
benchmarkcontains13,834CADmodelsfrom40categories,
radii negatively impact our performance (shown in Fig. 5).
and it is split into a training (9,843 models) and a test set
The reasons can be: 1) our PAG can exploit multi-scale
(2,468 models). Most 3D models from ModelNet40 are pre-
point features to yield robust predictions; 2) it is difﬁcult
aligned to the common up-direction and horizontal-facing
to manually set the predeﬁned searching thresholds, which
direction. To better approximate the scenarios in real world
cannot be self-adaptive to irregularly incomplete 3D points.
applications, the pre-aligned direction can be ignored by
applying random up-axis rotations. For fair comparisons,
C. Object-part Segmentation
we report our classiﬁcation network performance in both
training settings, provided Table I. The column “OA” pro- Object-part segmentation is demonstrated on the
vides the overall classiﬁcation accuracy (percentage). The ShapeNet-part dataset [51], which contains 16,881 shapes
column “Mem.” and “Time” denotes the required training represented as separate point clouds from 16 categories with
memory consumption and time, respectively (batch size = per-point annotation. Following previous work [5], we split
32). According to Table I, our PAG yields the best classi- the dataset into a training (14,034 objects) and a test (2,847
ﬁcation accuracy for all the training settings. Furthermore, objects) set. We apply the mean Intersection over Union
ourPAGrequiressmallermemoryfootprintandshortertime (IoU) metric to evaluate our method on each point. For each
for training than most existing networks. instance, we obtain the mean IoU by averaging IoUs for all
Ablation Study. We report the ablation study results in part types in the corresponding object category. The overall
instance IoU (“pIoU”) is computed by averaging IoUs over
Table II. Without applying PAC modules, the classiﬁcation
all the tested instances. Category-wise IoU is computed as
accuracy dropped due to insufﬁcient contextual information.
the average of all the instances under the corresponding
Unlikepreviousworks[7],[8],settingthenumberofselected
category. Mean category IoU (“mpIoU”) is thus computed
nearest neighbors as 20 does not increase our classiﬁcation
as the mean of all the category-wise IoUs. In Table III,our
accuracy. Furthermore, setting a smaller number of selected
model presents the best overall mean IoU at 86.4%. The
nearest neighbors decreases the training memory require-
qualitative segmentation results are shown in Fig. 6.
ment and also improves the training efﬁciency. Additionally,
Ablation Study. Table IV provides the results for abla-
the proposed chained skip subsampling (CSS) module can
tion study on the object-part segmentation task. The results
further improve the classiﬁcation performance. In our EP
illustrate that the proposed chained skip upsampling (CSU)
operations, if we only propagate “centroid” or “neighbor”
features, our classiﬁcation accuracy will drop signiﬁcantly.
Robustness to Sampling Density Variation. In real
applications, point clouds are often partially captured, thus
becoming irregular and incomplete. Our PAG heavily relies
on kNN, which cannot guarantee a ﬁxed scale for exploited
geometric details, especially for non-uniformly distributed
3D points. To this end, we revise the PAC module by Fig.6. Qualitativeresultsofthepartsegmentationtask.
1117
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. TABLEIII TABLEIV
SEGMENTATIONCOMPARISONSONSHAPENET[51]ANDS3DIS[52]. ABLATIONSTUDYOFTHESEGMENTATIONNETWORK.
Method ShapeNet k-foldS3DIS Area-5S3DIS K PAC Centroid/Neighbors CSU GF Aux.L pIoU
mpIoU pIoU OA mIoU OA mIoU (cid:88) (cid:88)
SRSSPGPeoSgiGNPnCN•teClto••N[u1dN[[11•1]•23][][5530]] 888214--...846 888546--...891 888058--...851 55666025-....5414 8865---..49 455887--...903 112111000000 (cid:88)(cid:88)(cid:88)(cid:88)× nceeibbbbngoooothrttttbohhhhoidrs (cid:88)(cid:88)(cid:88)(cid:88)× (cid:88)(cid:88)(cid:88)(cid:88)(cid:88)× ×××××× 888888555555......377687
PCCN[54] - - - - - 58.3 10 (cid:88) both (cid:88) (cid:88) × 86.1
PointNet[5] 80.4 83.7 78.5 47.6 - 41.1 10 (cid:88) both (cid:88) (cid:88) (cid:88) 86.4
PointNet++[6] 81.9 85.1 - - - -
{ }
SO-Net[43] 81.0 84.9 - - - - many neighboring points for 3 times (e.g. #K= 16,32,128 )
SPLATNET3D [55] 82.0 84.6 - - - - and then concatenate all exploited features together (e.g.
Atzmonet.al[49] 81.8 85.1 - - - -
SpiderCNN[8] 82.4 85.3 - - - - #Cf=64+128+128)ineachhierarchy,whichmakesitcompu-
DGCNN[7] 82.3 85.2 84.1 56.1 - - tationally expensive [6]. In contrast, our PAC module equiv-
PAN[9] 82.6 85.7 85.9 61.4 - - alently sparsely sample the neighboring points in feature
A-CNN[31] 84.0 86.1 87.3 62.9 - -
PAG(ours) 84.0 86.4 88.1 65.9 86.8 59.3 spaces with a sampling rate parameter “r”. In our PAG, we
consecutively lay out PAC modules in series to aggregate
module and the extracted global features are beneﬁcial to multi-scale edge features without increasing the selected
increasing the segmentation accuracy. Our proposed PAC neighboring points (#K) and the point feature size (#C ).
f
module further increases our segmentation accuracy. Setting Hierarchical Encoder-Decoder Architecture. Inspired
the number of selected nearest neighbors as 20 does not bythesuccessofencodingrichcontextualimageinformation
increase our segmentation accuracy, but largely increases at multiple scales for image-based applications, we focus
its training memory consumption. In our EP operations, on capturing multi-scale local geometrical details in 3D
ignoring either centroid point features or neighbor point points by a hierarchical encoder-decoder architecture. Our
features can lead to a drop of its accuracy. By adding global PAG contains: (1) an encoder module that progressively
pointfeatures(GF)andauxiliarylossfunctions(Aux.L),our decreases point feature density, enlarges the ﬁeld of view
segmentation network can yield better results. of ﬁlters and learns higher semantic edge features; (2)
a decoder module that gradually recovers the density for
D. Semantic Segmentation
high-dimensional point features. Deep hierarchical CNNs
We evaluate our model on large-scale 3D semantic seg- commonly use the non-overlapping max-pooling operations,
mentation (see Fig. 7) on the Stanford 3D Indoor Semantic which decrease the image feature resolution while summa-
Dataset (S3DIS) [52]. This dataset contains 3D RGB point rizing local-spatial contextual information. To resolve the
clouds of 271 rooms from 3 different buildings split into 6 overlapped neighborhood graph problem, we propose
areas.Toachievefaircomparison,weapplythesamesetting our EP operation, which concatenates both “centroid” and
of the training strategy with PointNet [5]. We randomly “neighbors” features for hierarchically propagating edge-
sample 4,096 points in each block for training, and all aware features. In our ablation studies, we observe that the
the points are used for testing. The semantic segmentation “neighbors”featuresbeneﬁtingeneratingglobalfeaturesfor
results (k-fold and Area-5) are provided in Table III. Those classiﬁcation tasks. The “centroid” features are beneﬁcial
•
methods [50], [12], [13], [11], [56] (denoted by ) obtain for propagating respective information of each individual
unfair advantages by applying speciﬁc preprocessing and/or point,henceleadingtobettersegmentationresults.Following
postprocessing procedures, such as super point graphs or spatial pyramid pooling operations [57], [58], we can also
recurrent neural networks. Moreover, they do not maintain performourEPoperationsatseveralscalesforfuturestudies.
the important permutation-invariant property, which makes
theirresultsunreliableandsensitivewithrespecttothepoints
feedingorder.Withoutadditionalprocesses,ourpermutation-
invariant PAG provides the best results on the OA (88.1%
and 86.8%) and mIoU (65.9% and 59.3%). Fig.7. Qualitativeresultsonthesemanticsegmentationtask.
V. ANALYSISANDFUTUREDIRECTIONS VI. CONCLUSION
Permutation-Invariance Property. Our proposed mod- We proposed the novel PointAtrousGraph (PAG) archi-
ules are made up of symmetric functions, such as shared tecture to capture multi-scale local geometric details for
mlp, max-pooling and feature concatenation. Consequently, hierarchicalpointfeatureslearning.Manynovelandeffective
our PAG is a permutation-invariant network. modules are proposed and then evaluated in various experi-
Sampling Neighboring Points. Ball query introduced by ments, which provides promising performance. We encour-
PointNet++isanotherstrategytosampleneighboringpoints. age researchers to apply our modules for more complicated
However, PointNet++ only select the ﬁrst #K points found point cloud applications of large-scale 3D scenes.
withintheradius,whichcannotguaranteethatnearestpoints Acknowledgment.Thisworkwaspartiallysupportedbythe
can be selected. Furthermore, PointNet++(MSG) search for Singapore MOE Tier 1 grant R-252-000-A65-114.
1118
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [21] M.AmirulIslam,M.Rochan,N.D.Bruce,andY.Wang,“Gatedfeed-
backreﬁnementnetworkfordenseimagelabeling,”inProceedingsof
[1] L.-C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam, the IEEE Conference on Computer Vision and Pattern Recognition,
“Encoder-decoder with atrous separable convolution for semantic 2017,pp.3751–3759.
imagesegmentation,”inProceedingsoftheEuropeanConferenceon [22] Z. Wojna, V. Ferrari, S. Guadarrama, N. Silberman, L.-C. Chen,
ComputerVision(ECCV),2018,pp.801–818. A.Fathi,andJ.Uijlings,“Thedevilisinthedecoder,”arXivpreprint
arXiv:1707.05847,2017.
[2] L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam, “Rethinking
atrous convolution for semantic image segmentation,” arXiv preprint [23] J.Fu,J.Liu,Y.Wang,J.Zhou,C.Wang,andH.Lu,“Stackeddecon-
arXiv:1706.05587,2017. volutionalnetworkforsemanticsegmentation,”IEEETransactionson
ImageProcessing,2019.
[3] H.Zhao,J.Shi,X.Qi,X.Wang,andJ.Jia,“Pyramidsceneparsing
[24] Z.Zhang,X.Zhang,C.Peng,X.Xue,andJ.Sun,“Exfuse:Enhancing
network,”inProceedingsoftheIEEEconferenceoncomputervision
feature fusion for semantic segmentation,” in Proceedings of the
andpatternrecognition,2017,pp.2881–2890.
European Conference on Computer Vision (ECCV), 2018, pp. 269–
[4] K.He,X.Zhang,S.Ren,andJ.Sun,“Spatialpyramidpoolingindeep
284.
convolutionalnetworksforvisualrecognition,”IEEEtransactionson
[25] H. Noh, S. Hong, and B. Han, “Learning deconvolution network for
pattern analysis and machine intelligence, vol. 37, no. 9, pp. 1904–
semantic segmentation,” in Proceedings of the IEEE international
1916,2015.
conferenceoncomputervision,2015,pp.1520–1528.
[5] C. R. Qi, H. Su, K. Mo, and L. J. Guibas, “Pointnet: Deep learning
[26] A.Dosovitskiy,P.Fischer,E.Ilg,P.Hausser,C.Hazirbas,V.Golkov,
onpointsetsfor3dclassiﬁcationandsegmentation,”Proc.Computer
P. Van Der Smagt, D. Cremers, and T. Brox, “Flownet: Learning
Vision and Pattern Recognition (CVPR), IEEE, vol. 1, no. 2, p. 4,
opticalﬂowwithconvolutionalnetworks,”inProceedingsoftheIEEE
2017.
internationalconferenceoncomputervision,2015,pp.2758–2766.
[6] C. R. Qi, L. Yi, H. Su, and L. J. Guibas, “Pointnet++: Deep hierar-
[27] E.Ilg,N.Mayer,T.Saikia,M.Keuper,A.Dosovitskiy,andT.Brox,
chical feature learning on point sets in a metric space,” in Advances
“Flownet 2.0: Evolution of optical ﬂow estimation with deep net-
inNeuralInformationProcessingSystems,2017,pp.5099–5108.
works,” in Proceedings of the IEEE Conference on Computer Vision
[7] Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M.
andPatternRecognition,2017,pp.2462–2470.
Solomon, “Dynamic graph cnn for learning on point clouds,” arXiv
[28] T.-Y.Lin,P.Dolla´r,R.Girshick,K.He,B.Hariharan,andS.Belongie,
preprintarXiv:1801.07829,2018.
“Featurepyramidnetworksforobjectdetection,”inProceedingsofthe
[8] Y.Xu,T.Fan,M.Xu,L.Zeng,andY.Qiao,“Spidercnn:Deeplearning
IEEEConferenceonComputerVisionandPatternRecognition,2017,
onpointsetswithparameterizedconvolutionalﬁlters,”arXivpreprint
pp.2117–2125.
arXiv:1803.11527,2018.
[29] A. Shrivastava, R. Sukthankar, J. Malik, and A. Gupta, “Beyond
[9] L. Pan, P. Wang, and C. M. Chew, “Pointatrousnet: Point atrous
skip connections: Top-down modulation for object detection,” arXiv
convolutionforpointcloudanalysis,”IEEERoboticsandAutomation
preprintarXiv:1612.06851,2016.
Letters,2019.
[30] C.-Y. Fu, W. Liu, A. Ranga, A. Tyagi, and A. C. Berg, “Dssd: De-
[10] Y. Shen, C. Feng, Y. Yang, and D. Tian, “Mining point cloud local convolutionalsingleshotdetector,”arXivpreprintarXiv:1701.06659,
structuresbykernelcorrelationandgraphpooling,”inProceedingsof 2017.
the IEEE Conference on Computer Vision and Pattern Recognition,
[31] A. Komarichev, Z. Zhong, and J. Hua, “A-cnn: Annularly convolu-
vol.4,2018.
tional neural networks on point clouds,” in Proceedings of the IEEE
[11] L. Landrieu and M. Simonovsky, “Large-scale point cloud se- Conference on Computer Vision and Pattern Recognition, 2019, pp.
mantic segmentation with superpoint graphs,” arXiv preprint 7421–7430.
arXiv:1711.09869,2017. [32] M. Jiang, Y. Wu, and C. Lu, “Pointsift: A sift-like network mod-
[12] W. Wang, R. Yu, Q. Huang, and U. Neumann, “Sgpn: Similarity ule for 3d point cloud semantic segmentation,” arXiv preprint
groupproposalnetworkfor3dpointcloudinstancesegmentation,”in arXiv:1807.00652,2018.
ProceedingsoftheIEEEConferenceonComputerVisionandPattern [33] L.-C.Chen,G.Papandreou,I.Kokkinos,K.Murphy,andA.L.Yuille,
Recognition,2018,pp.2569–2578. “Deeplab:Semanticimagesegmentationwithdeepconvolutionalnets,
[13] Q. Huang, W. Wang, and U. Neumann, “Recurrent slice networks atrous convolution, and fully connected crfs,” IEEE transactions on
for 3d segmentation of point clouds,” in Proceedings of the IEEE pattern analysis and machine intelligence, vol. 40, no. 4, pp. 834–
Conference on Computer Vision and Pattern Recognition, 2018, pp. 848,2018.
2626–2635. [34] K. Simonyan and A. Zisserman, “Very deep convolutional networks
[14] A. Newell, K. Yang, and J. Deng, “Stacked hourglass networks for for large-scale image recognition,” arXiv preprint arXiv:1409.1556,
humanposeestimation,”inEuropeanConferenceonComputerVision. 2014.
Springer,2016,pp.483–499. [35] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage
[15] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, “Coarse- recognition,” in Proceedings of the IEEE conference on computer
to-ﬁne volumetric prediction for single-image 3d human pose,” in visionandpatternrecognition,2016,pp.770–778.
ProceedingsoftheIEEEConferenceonComputerVisionandPattern [36] A.Krizhevsky,I.Sutskever,andG.E.Hinton,“Imagenetclassiﬁcation
Recognition,2017,pp.7025–7034. with deep convolutional neural networks,” in Advances in neural
[16] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional informationprocessingsystems,2012,pp.1097–1105.
networksforbiomedicalimagesegmentation,”inInternationalConfer- [37] D. Scherer, A. Mu¨ller, and S. Behnke, “Evaluation of pooling op-
enceonMedicalimagecomputingandcomputer-assistedintervention. erations in convolutional architectures for object recognition,” in
Springer,2015,pp.234–241. Internationalconferenceonartiﬁcialneuralnetworks. Springer,2010,
[17] V. Badrinarayanan, A. Kendall, and R. Cipolla, “Segnet: A deep pp.92–101.
convolutional encoder-decoder architecture for image segmentation,” [38] D.C.Ciresan,U.Meier,J.Masci,L.M.Gambardella,andJ.Schmid-
IEEE transactions on pattern analysis and machine intelligence, huber,“Flexible,highperformanceconvolutionalneuralnetworksfor
vol.39,no.12,pp.2481–2495,2017. imageclassiﬁcation,”inTwenty-SecondInternationalJointConference
[18] T. Pohlen, A. Hermans, M. Mathias, and B. Leibe, “Full-resolution onArtiﬁcialIntelligence,2011.
residual networks for semantic segmentation in street scenes,” in [39] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner et al., “Gradient-based
ProceedingsoftheIEEEConferenceonComputerVisionandPattern learningappliedtodocumentrecognition,”ProceedingsoftheIEEE,
Recognition,2017,pp.4151–4160. vol.86,no.11,pp.2278–2324,1998.
[19] G. Lin, A. Milan, C. Shen, and I. Reid, “Reﬁnenet: Multi-path [40] F.Groh,P.Wieschollek,andH.Lensch,“Flex-convolution(deeplearn-
reﬁnement networks for high-resolution semantic segmentation,” in ingbeyondgrid-worlds),”arXivpreprintarXiv:1803.07289,2018.
Proceedings of the IEEE conference on computer vision and pattern [41] S. Zhao, J. Song, and S. Ermon, “Infovae: Information maximizing
recognition,2017,pp.1925–1934. variationalautoencoders,”arXivpreprintarXiv:1706.02262,2017.
[20] C.Peng,X.Zhang,G.Yu,G.Luo,andJ.Sun,“Largekernelmatters– [42] H.Zhao,Y.Zhang,S.Liu,J.Shi,C.ChangeLoy,D.Lin,andJ.Jia,
improve semantic segmentation by global convolutional network,” in “Psanet: Point-wise spatial attention network for scene parsing,” in
Proceedings of the IEEE conference on computer vision and pattern ProceedingsoftheEuropeanConferenceonComputerVision(ECCV),
recognition,2017,pp.4353–4361. 2018,pp.267–283.
1119
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. [43] J. Li, B. M. Chen, and G. H. Lee, “So-net: Self-organizing network
forpointcloudanalysis,”inProceedingsoftheIEEEConferenceon
ComputerVisionandPatternRecognition,2018,pp.9397–9406.
[44] J.Long,E.Shelhamer,andT.Darrell,“Fullyconvolutionalnetworks
forsemanticsegmentation,”inProceedingsoftheIEEEconferenceon
computervisionandpatternrecognition,2015,pp.3431–3440.
[45] M.Abadi,P.Barham,J.Chen,Z.Chen,A.Davis,J.Dean,M.Devin,
S. Ghemawat, G. Irving, M. Isard et al., “Tensorﬂow: a system for
large-scalemachinelearning.”inOSDI,vol.16,2016,pp.265–283.
[46] Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao,
“3d shapenets: A deep representation for volumetric shapes,” in
Proceedings of the IEEE conference on computer vision and pattern
recognition,2015,pp.1912–1920.
[47] C.Wang,B.Samari,andK.Siddiqi,“Localspectralgraphconvolution
forpointsetfeaturelearning,”arXivpreprintarXiv:1803.05827,2018.
[48] M.Gadelha,R.Wang,andS.Maji,“Multiresolutiontreenetworksfor
3dpointcloudprocessing,”arXivpreprintarXiv:1807.03520,2018.
[49] M. Atzmon, H. Maron, and Y. Lipman, “Point convolutional neural
networks by extension operators,” arXiv preprint arXiv:1803.10091,
2018.
[50] Y. Li, R. Bu, M. Sun, and B. Chen, “Pointcnn,” arXiv preprint
arXiv:1801.07791,2018.
[51] L.Yi,V.G.Kim,D.Ceylan,I.Shen,M.Yan,H.Su,C.Lu,Q.Huang,
A.Sheffer,L.Guibasetal.,“Ascalableactiveframeworkforregion
annotation in 3d shape collections,” ACM Transactions on Graphics
(TOG),vol.35,no.6,p.210,2016.
[52] I. Armeni, O. Sener, A. R. Zamir, H. Jiang, I. Brilakis, M. Fischer,
andS.Savarese,“3dsemanticparsingoflarge-scaleindoorspaces,”in
ProceedingsoftheIEEEConferenceonComputerVisionandPattern
Recognition,2016,pp.1534–1543.
[53] L.Tchapmi,C.Choy,I.Armeni,J.Gwak,andS.Savarese,“Segcloud:
Semanticsegmentationof3dpointclouds,”in3DVision(3DV),2017
InternationalConferenceon. IEEE,2017,pp.537–547.
[54] S. Wang, S. Suo, W.-C. Ma, A. Pokrovsky, and R. Urtasun, “Deep
parametriccontinuousconvolutionalneuralnetworks,”inProceedings
oftheIEEEConferenceonComputerVisionandPatternRecognition,
2018,pp.2589–2597.
[55] H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang,
and J. Kautz, “Splatnet: Sparse lattice networks for point cloud
processing,” in Proceedings of the IEEE Conference on Computer
VisionandPatternRecognition,2018,pp.2530–2539.
[56] F.Engelmann,T.Kontogianni,A.Hermans,andB.Leibe,“Exploring
spatial context for 3d semantic segmentation of point clouds,” in
ProceedingsoftheIEEEConferenceonComputerVisionandPattern
Recognition,2017,pp.716–724.
[57] K. Grauman and T. Darrell, “Pyramid match kernels: Discriminative
classiﬁcationwithsetsofimagefeatures(version2),”2006.
[58] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features:
Spatial pyramid matching for recognizing natural scene categories,”
in2006IEEEComputerSocietyConferenceonComputerVisionand
PatternRecognition(CVPR’06),vol.2. IEEE,2006,pp.2169–2178.
1120
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 21,2020 at 06:08:17 UTC from IEEE Xplore.  Restrictions apply. 