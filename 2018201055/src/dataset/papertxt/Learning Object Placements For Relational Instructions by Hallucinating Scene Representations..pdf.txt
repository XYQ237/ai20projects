2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous
Environments
Rohan Chandra1, Uttaran Bhattacharya1, Tanmay Randhavane2, Aniket Bera2, and Dinesh Manocha1
1University of Maryland, 2University of North Carolina
Supplementary Material at https://gamma.umd.edu/ad/roadtrack
Abstract—We present a realtime tracking algorithm, Road-
Track, to track heterogeneous road-agents in dense trafﬁc
videos. Our approach is designed for dense trafﬁc scenarios
that consist of different road-agents such as pedestrians, two-
wheelers, cars, buses, etc. sharing the road. We use the
tracking-by-detectionapproachwherewetrackaroad-agentby
matchingtheappearanceorboundingboxregioninthecurrent
framewiththepredictedboundingboxregionpropagatedfrom
thepreviousframe.Roadtrackusesanovelmotionmodelcalled
theSimultaneousCollisionAvoidanceandInteraction(SimCAI)
modeltopredictthemotionofroad-agentsbymodelingcollision
avoidance and interactions between the road-agents for the
next frame. We demonstrate the advantage of RoadTrack on a
datasetofdensetrafﬁcvideosandobserveanaccuracyof75.8% Fig. 1: We highlight the performance of our tracking algorithm,
on this dataset, outperforming prior state-of-the-art tracking RoadTrack, in this urban video. This frame consists of 27 road-
algorithms by at least 5.2%. RoadTrack operates in realtime agents,includingpedestrians,two-wheelscooters,three-wheelrick-
(cid:2)
at approximately 30 fps and is at least 4 faster than prior shaws, cars, and bicycles. RoadTrack can track agents with 75.8%
tracking algorithms on standard tracking datasets. accuracyatapproximately30fpsonanTitanXpGPU.Weobserve
(cid:2)
I. INTRODUCTION average improvement of at least 5:2% in MOTA accuracy and 4
in fps over prior methods.
Tracking of road-agents on a highway or an urban road
the tracking problem in dense and heterogeneous trafﬁc
is an important problem in autonomous driving [1], [2] and
scenarios, we require a motion model that can account
relatedareassuchastrajectoryprediction[3],[4],[5].These
for interactions among heterogeneous agents and the high
road-agents may correspond to large or small cars, buses,
density in which these agents move. We adopt the tracking-
bicycles, rickshaws, pedestrians, moving carts, etc. Different
by-detectionparadigm,whichisatwo-stepprocessofobject
agents have different shapes, move at varying speeds, and
detection and state prediction using the motion model. The
their underlying dynamics constraints govern their trajecto-
ﬁrst step, object detection, is performed to generate vector-
ries. Furthermore, the trafﬁc patterns or behaviors can vary
izedrepresentations,calledfeatures,foreachroad-agentthat
considerably between highway trafﬁc, sparse urban trafﬁc,
facilitate identity association across frames. The second step
and dense urban trafﬁc with a variety of such heterogeneous
is to predict the state (position and velocity) for the next
agents, e.g., in Figure 1. The trafﬁc density can be deﬁned
frame using a motion model.
based on the number of distinct road-agents captured in a
Main Contributions: We present a realtime tracking
single frame of the video or the number of agents per unit
algorithm, called RoadTrack, to track heterogeneous road-
length of the roadway.
agentsindensevideos.RoadTrackusesanewmotionmodel
Given a trafﬁc video, the tracking problem corresponds to
to represent the motion of different road-agents by simul-
computing the consistency in the temporal and spatial iden-
taneously accounting for collision avoidance and pairwise
tityofallagentsinthevideosequence.Recentdevelopments
interactions. We show it is better suited for dense and
in autonomous driving and large-scale deployment of high-
heterogeneoustrafﬁcscenesincomparisontolinearconstant
resolution cameras for surveillance has generated interest in
velocity, non-linear, and learning-based motion models. We
the development of accurate tracking algorithms, especially
name this motion model, SimCAI (“Simultaneous Collision
in dense scenarios with a large number of heterogeneous
Avoidance and Interaction (SimCAI)”).
agents.Thecomplexityoftrackingincreasesindensescenar-
iosasdifferenttypesofroad-agentscomeincloseproximity RoadTrackmakesnoassumptionregardingcameramotion
and interact with each other. Examples of such interactions and camera view. For example, we show our algorithm can
include passengers boarding or deboarding buses, bicyclists track road-agents in heavy trafﬁc captured from both front
riding alongside cars and so on. Such trafﬁc scenarios arise view and top view cameras that can be either stationary or
frequently in densely populated metropolitan cities. moving. We further do not make assumptions for lighting
conditions and can even track road-agents during night-time
Thereisextensivepriorworkontrackingobjectsandroad-
with glare from oncoming trafﬁc (see supplementary video).
agents [6], [7]. But they are mostly designed and used in
scenarios with sparse or lower density of road-agents. Such Main Beneﬁts: The advantages of using RoadTrack are
methods are unable to perform tracking in dense trafﬁc due summarized below:
to occlusions and other challenges. In this paper, we mainly 1) Accuracy: On a dense trafﬁc dataset, RoadTrack is
focus on developing efﬁcient algorithms for dense trafﬁc state-of-the-art with an absolute accuracy of 75.8%.
scenarios with heterogeneous interactions. This is an increase of 5.2% over the next best method.
Recently, techniques based on deep learning are widely This is equivalent to a rank difference of 42 with the
used for object detection and tracking. In order to solve nextbestmethodonthecurrentstate-of-the-arttracking
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1270
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. benchmark dataset [8]. non-linearmotionmodelsthathavebeenusedfortrackingin-
2) Speed: Our method demonstrates realtime performance cludesocialforces[36],LTA[15],andATTR[37].However,
at approximately 30 fps on dense trafﬁc scenes con- these are mainly designed for tracking pedestrians. Social
taining up to 100 agents per frame as well as standard Forces, in particular, holds resemblance to our proposed
trackingdatasets.AllresultswereobtainedonaTITAN motion model, SimCAI, in that it models the attraction
XpGPUwith8coresofCPUat3.6Ghzfrequency.On and repulsion between agents (pedestrians only) through the
(cid:2)
the MOT benchmark, RoadTrack is at least 4 faster concept of potential energy functions. With the recent rise
than SOTA methods, and on the dense trafﬁc dataset, it in popularity of deep learning, recurrent neural networks
is comparable to the fastest SOTA method. such as LSTMs have been used as motion models for
II. RELATEDWORK tracking[38],[39].WecompareSimCAIwithbothlearning-
A. Pedestrian and Vehicle Tracking and non-learning-based motion models in this paper.
There is extensive work on pedestrian tracking [9], [10]. III. ROADTRACK:OVERVIEW
Bruce et al. [11] and Gong et al. [12] predict pedestrians’
In this section, we present the RoadTrack algorithm that
motions by estimating their destinations. Liao et al. [13]
combines Mask R-CNN object segmentation with SimCAI.
compute a Voronoi graph from the environment and predict
Informally, the tracking problem is stated as follows: Given
the pedestrian motion along the edges. Mehran et al. [14]
a video, we want to assign an ID to all road-agents in all
apply the social force model to detect anomalous pedes-
frames. This is formally equivalent to solving the following
trian behaviors from videos. Pellegrini et al. [15] use an
sub-problem at each time-step (or frame): At current time t,
energyfunctiontobuildagoal-directedshort-termcollision-
given the ID labels of all road-agents in the frame, assign
avoidancemotionmodel.Beraetal.[16],[17]usereciprocal
labels for road-agents in the next frame (time t+1).
velocity obstacles and hybrid motion models to improve the
We start by using Mask R-CNN to implicitly perform
accuracy. All these methods are speciﬁcally designed for
pixel-wise segmentation of the road-agents. This generates
tracking pedestrian movement.
a set of segmented boxes [31]. For each detected road-
Vehicle tracking has been studied in computer vision,
agent, h , generated using Mask R-CNN, we extract their
robotics, and intelligent transportation. Some of the earlier j
corresponding features, f , using the deep learning-based
techniques are based on using cameras [18] and laser range feature extraction architechtjure proposed in [31]. We do not
ﬁnders [19]. The authors of [20] model dynamic and geo-
use the provided pre-trained models and instead, ﬁne-tune
metric properties of the tracked vehicles and estimate their
the existing feature extraction network on trafﬁc datasets to
positions using a stereo rig mounted on a mobile platform.
learnmeaningfulfeaturespertainingtotrafﬁc.Wediscussthe
Ess et al. [21] present an approach to detect and track
ﬁne-tuned hyperparameters in the supplementary material.
vehicles in highly dynamic environments. Multiple cameras
Next, we predict the next state (state consists of spatial
have also been used to perform tracking all surrounding
coordinates (p ) and velocities ((cid:23) )) for each road-agent for
vehicles [22], [23]. Moras et al. [24] use an occupancy grid i i
the next time-step using SimCAI. This step is the main
framework to manage different sources of uncertainty for
contribution of this work and is described in detail in
moreefﬁcientvehicletracking;Wojkeetal.[25]useLiDAR
Section IV. This step results in another set of segmented
for moving vehicle detection and tracking in unstructured
boxes for each road-agent at time t+1.
environments. Finally, [26] uses a feature-based approach
Finally, we use these sets of segmented boxes to compute
to track the vehicles under varying lighting conditions.
features using a Convolutional Neural Network [40]. The
Most of these methods focus on vehicle tracking and do
features generated are compared using association algo-
not take into account interactions with other road-agents
rithms [41] to compute the ID of each agent in the next
such as pedestrians, two-wheelers, rickshaws etc. in dense
frame. The features are matched in two ways: the Cosine
urban environments. For an up-to-date review of tracking-
metric and the IoU overlap [42]. The Cosine metric is
by-detection algorithms, we refer the reader to methods
computed using the following optimization problem:
submitted to the MOT benchmark [8].
B. Motion Models for Tracking j 2P 2H
min(l(f ;f )p ;h ): (1)
There is substantial work on tracking multiple objects hj pi hj i j i
H
and use of motion models to improve the accuracy [27], where is the subset of all detected road-agents in the
i
[28], [29], [30], [31], [32]. Kim et al. [28] perform Multiple current frame that are within a circular region around agent
Hypotheses Tracking (MHT) [33] by using an effective p that have not been matched to a predicted agent. The IoU
i
online classiﬁer for efﬁcient branch pruning. The constant overlapmetricisusedinconjunctionwiththecosinemetric.
velocity linear motion model has been used to join frag- This metric builds a cost matrix (cid:6) to measure the amount
mentedpedestriantrackscausedbyocclusion[30].However, of overlap of each predicted bounding box with all nearby
dense trafﬁc often cause road-agents to perform complex detection bounding box candidates. (cid:6)(i;j) stores the IoU
maneuvers to avoid collisions that are often non-linear. overlap of the bounding box of p with that of h and is
i j
Hence, linear motion models do not work well in dense calculated as:
scenes. \
B B 2H
RVO [34] is a non-linear motion model that has been (cid:6)(i;j)= pi [ hj;h :
usedforpedestriantrackingindensecrowdvideos.However, B B j i
pi hj
RVO does not take into account agents interacting with
If we denote the cosine and the IOU overlap metrics by C
one another. An extension to RVO, called AutoRVO [2]
and I, respectively, then the combined cost function value is
includesdynamicconstraintsbetweenroad-agents.However,
obtained through,
AutoRVO is based on CTMAT [35] representations of road-
agents that cannot be translated to front-view scenes. Other Combined Cost=(cid:21) C+(cid:21) I;(cid:21) +(cid:21) =1; (2)
1 2 1 2
1271
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. where (cid:21) ;(cid:21) are constants representing the weights for the trafﬁcaswellastop-view,weusethemodiﬁcationproposed
1 2
individual metric costs. Matching a detection to a predicted by the authors of [31] that allow RVO to model the motion
measurement with maximum overlap thus becomes a max- of road-agents in front-view trafﬁc scenes.
weight matching problem and we solve it efﬁciently using
the Hungarian algorithm [41]. The ID of the road-agent at B. VelocityPredictionbyModelingRoad-AgentInteractions
time t is assigned to that road-agent at time t+1 whose In a trafﬁc scenario, interactions can occur between
appearance is most closely associated to the road-agent at different types of road-agents: vehicle-vehicle, pedestrian-
time t. pedestrian,vehicle-pedestrian,bicycle-pedestrian,etc.Inthis
IV. SIMCAI:SIMULTANEOUSCOLLISIONAVOIDANCE section,wepresentaformulationtomodelsuchinteractions.
ANDINTERACTIONS Our input is an RGB video captured from a camera with
knowncameraparameters.Byusingthecameracenterasthe
One of the major challenges with tracking heterogeneous
origin, we transform pixel coordinates to scene coordinates
road-agents in dense trafﬁc is that road-agents such as
for the computations that follow in this section.
cars, buses, bicycles, road-agents, etc. have different sizes,
1) Intent of Interaction: The idea of using spatial re-
geometric shape, maneuverability, behavior, and dynamics.
gions to characterize agent behavior was proposed in [44].
Thisoftenleadstocomplexinter-agentinteractionsthathave
The authors introduced the notion of “public” and “social”
not been taken into account by prior multi-object trackers.
regions, that are of the form of concentric circles. We show
Furthermore, road-agents in high-density scenarios are in
a quadrant of these regions in Figure 2, where the yellow
close-proximity to one another or are almost colliding. So
area is the social region and the orange area is the public
we need an efﬁcient approach for predicting the next state
region. Based on this work, Satake et al. [45] proposed a
of a road-agent by modeling the collisions and interactions.
model of approach behavior with which a robot can interact
We thus present SimCAI, that takes into account both,
with humans. At the public distance the robot is allowed
(cid:15) Reciprocal collision avoidance [34] with car-like kine-
to approach the human to interact with them, and at the
matic constraints for trajectory prediction and collision
social distance, interaction occurs. In SimCAI, we have set
avoidance.
the public and social distances heuristically.
(cid:15) Heterogeneousroad-agentinteractionbetweenpedestri-
We say that a road-agent, p , intends to interact with
ans, two-wheelers, rickshaws, buses, cars and so on. i
another agent, p , when p is within the social distance of
All the notations used in the paper are provided in Table p for some minkimum timei(cid:28). When two road-agents intend
I of full version of this text [43]. tokinteract, they move towards each other and come in close
proximity.
A. Velocity Prediction by Modeling Collision Avoidance
2) Ability to Interact: Even when two road-agents want
Reciprocal Velocity Obstacles (RVO) [34] extends Veloc-
to interact, their movements could be restricted in dense
ityObstaclesmotionmodelbymodelingcollisionavoidance
trafﬁc. We determine the ability to interact (Figure 2(right))
behavior for multiple engaging agents. RVO can be applied
as follows.
to pedestrians in a crowd and we modify it to work with
Each agent has a personal space, which we deﬁne as a
bounding boxes as our algorithm conforms to the tracking-
circular region (cid:16) of radius (cid:26), centered around p . Given a
by-detection paradigm. k
We represent each agent as, (cid:9)t =[u;v;u_;v_;vpref], where rwoiatdh-tahgeehnotrpizi,onthtaeldsleoﬁpneedofinittshevpwreofrilsdctaonor(cid:18)d.in(cid:18)atiesstyhseteamn.gIlne
u;v;u_;v_;and vpref represent the top left corner of the densetrafﬁc,eachagent,p hasalimitedspaceinwhichthey
bounding box, their velocities, and the preferred velocity of i
cansteer,orturn.Thisspaceisthefeasibleregiondetermined
the agent in the absence of obstacles respectively. vpref is by the ORCA constraints described in the previous section.
computed internally by RVO.
We deﬁne a 2D cone, (cid:13), of angle (cid:30) as the ORCA region in
The computation of the new state, (cid:9)t+1, is expressed as which the agent can steer. (cid:30) is thus the steering angle of the
an optimization problem. For each agent, RVO computes a
agent. We denote the extreme rays of the cone as r and r .
feasible region where it can move without collision. This ?G2 denotesthesmallestperpendiculardistancebetw1eenan2y
region is deﬁned according to the RVO collision avoid- twGo1geometric structures, say, G and G . These parameters
ance constraints (or ORCA constraints [34]). If the ORCA 1 2
are ﬁxed for different agent types and are not learned from
constraints forbid an agent’s preferred velocity, that agent
data.
chooses the velocity closest to its preferred velocity that lies
If p has intended to interact with p , the projected cone
inthefeasibleregion,asgivenbythefollowingoptimization: i k
ofp ,deﬁnedbyextendingr andr ,isdirectedtowardsp
vnew = argminjjv(cid:0)vprefjj (3) Theni, in order for interaction1to take2place, it is sufﬁcient tok
2 check for either one of two conditions to be true:
v=ORCA
poTsihtieonvoelfoacirtyo,adv-naegwe,nti.s then used to calculate the new 1) Ceiothnedritriaoyni(cid:10)nt1e:rsInecte(cid:26)tsrs,etchteinonthoefe(cid:16)ntwiriethcoeinteheirntre1rsoerctrs2(cid:16)()i.f
The difference in shapes, sizes, and aspect ratios of road- 2) Condition (cid:10)2: (cid:16) (cid:13) (if (cid:16) lies in the interior of the
cone, see Figure 2).
agents motivate the need to use appearance-based features.
In order to combine object detection with RVO, we modify For these conditions to hold, we require that the cone does
2 P 6
the state vector, (cid:9)t, to include bounding box information not intersect or contain any pj ;j = i. We now make
by setting the position to the centers of the bounding boxes. these equations more explicit.
Thus, u= u+w and v = v+h, where w;h denote the width We par?ame(cid:21)triz?e r1;r2 by thei(cid:0)r slopes tan(cid:14), where (cid:14) =
andheight,re2spectively,of2thecorrespondingboundingbox. (cid:18) +(cid:30) if r1 r2,else(cid:14) =(cid:18) (cid:30) .Theresultingequation
i i (cid:16) (cid:16)(cid:0) i i(cid:0)
Finally, the original RVO models the motion of agents of r (or r ) is (Y v )=tan(cid:14)(X u ) and the equation
1 (cid:0)2 i(cid:0) i
seen from a top-view. Therefore, to account for front-view of (cid:16) is (X u )2+(Y v )2 =(cid:26)2. Solving both equations
k k
1272
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. Fig. 3: Qualitative analysis of RoadTrack on the TRAF dataset at
night time consisting of cars, 2-wheelers, 3-wheelers, and trucks.
(cid:24)
Framesarechosenwithagapof2seconds( 60frames).Forvisual
clarity,eachroad-agentisassociatedwithauniqueIDnumber.The
ID is displayed in orange. Note the consistencies in the ID, for
example, the 3-wheeler (1), car (2), and 2-wheeler (3).
Fig.2:Inneryellowcircledenotesthesocialdistanc(cid:21)eandtheouter Let n represent the number of total road-agents in a video,
oIVra-nBg.1e,apreaindteenndostetsotihneterpaucbtliwcitrhegpio.n.ThAetntiumsiengtIV-B(cid:28).2an(ldefut)s,inpg then we have n = nc + ni, where nc;ni correspond to
determineis its ability to interact withk p . We observe that (cid:13) (greyi the number of agents that are avoidaing collisions and are
k
cone) of p contains (cid:16) of p (green circle around p ). Thus p interacting, respectively.
i k k i
can interact with pk. Using IV-B.3 (right), pi and pk align their Increasing n would increase the number of road-agents
preferred velocities toward each other. whose motion is modeled through collision avoidance or
heterogeneousinteractionformulations.Linearmodelsdonot
simultaneously, we obtain an(cid:21)equation (cid:10)1. Intersection oc- account for either formulation. Standard RVO only accounts
cursifthediscriminantof(cid:10)1 0.Thisprovidesuswiththe forcollisionavoidance.SimCAImodelsboth.Therefore,we
ﬁrst condition necessary for the occurrence of an interaction
rationalize that,
between p and p .
i k
Next, we observe that if (cid:16) lies in the interior of (cid:13), then MOTAlinear(cid:20)MOTARVO(cid:25)MOTASimCAI
pbyk ltiheesfoonllothweinogppeoqsuiatetiosind:es of r1 and r2 which is modeled =)MMOOTTAAcliliinneeaarr(cid:20)(cid:20)MMOOTTAAcRiRVVOO(cid:20)(cid:20)MMOOTTAAcSiSiimmCCAAII
(cid:17) (cid:20) We validate the analysis presented here in Section V-D.
(cid:10) r (p ):r (p ) 0 (4)
2 1 k 2 k Runtime Analysis: At approximately 30 fps, we achieve
(cid:2)
Solving Equation 4 further provides us with the second a minimum speed-up of approximately 4 , and upto ap-
(cid:2)
condition for the occurrence of an interaction between p proximately 30 , over state-of-the-art methods on the MOT
(cid:2) (cid:2) (cid:2) 7(cid:0)! i
and p , where (cid:10) ;(cid:10) :R2 R2 R R R. dataset (Table II). The selection of state-of-the-art methods
k 1 2
3) Interaction: Ifeither(cid:10) or(cid:10) istrue,thenroad-agents is done in Section V-B. The state-of-the-art use RNNs to
1 2 (cid:21)
p ;p willmovetowardseachothertointeractattimet (cid:28). model the motion of road-agents [38], [39], while we use
i k
When this happens, we assume that p and p align their the modiﬁed RVO formulation. We exploit the geometrical
i k
currentvelocitiestowardseachother.Thus,vnew =vpref.The formulation of SimCAI to state and prove the following
time taken for the two road-agents to be meet or converge theorem:
jj (cid:0) jj
with each other is given by t = jjpi(cid:0)pkjj2. If two road- Theorem IV.1. Given P =fpij1(cid:20)i(cid:20)ng, that represents
agents are overlapping (based on thveivaluveks2of (cid:10)1 and (cid:10)2), ashsaepteo,fsinzer,oaandd-aaggeenntst-tiynpae,trifasfﬁtactescen2efthsattatmioanyarays,scuomlleisaionny
we model them as a new agent with radius 2(cid:15). avoiding, interacting g, 8i 2 n, thpein SimCAI can track the
Our approach can be extended to model multiple inter- O
n road-agents in (n +!n ), where ! <<n .
actions. Currently, we restrict an interaction to take place c i i
between 2 road-agents. Therefore, in the case of multiple Proof. RVOisbasedonlinearprogrammingandcanperform
Q(cid:18)P O
possibleinteractionswithanagent,p ,weformaset , tracking with a proven runtime complexity of (n) [34].
Q k
where is the set of all road-agents p , that are intending Now, if we assume that agents always assume one of the
!
to interact with p . We determine the road-agent that will followingstates:stationary,avoidingcollision,orinteracting,
k
interactwithpk astheroad-agentthatminimizesthedistance then we have n = nc + ni, where nc;ni correspond to
between p and p after a ﬁxed time-step, (cid:1)t. Thus, p = the number of agents in collision avoidance states and
kk ! (cid:0) k 2Q !
argmin (p +v (cid:1)t) p ;p . road-agents that are interacting states, respectively. We ignore stationary road-
notinterwactin!gavoi!deachothkeran!dcontinuemovingtowards agents. Following the formulation in Section IV-B, for each
their destination. interacting road-agent, SimCAI predicts a new velocity by
solving a linear optimization problem over ! road-agents.
O
C. Analysis Thus, the runtime complexity of SimCAI is (n +!n ),
c i(cid:4)
We analyze the accuracy and runtime performance of where ! <<ni.
SimCAI in trafﬁc scenarios with increasing density and Our high fps is a consequence of our linear runtime
heterogeneity. complexity and we validate our theoretical claims in Sec-
Accuracy Analysis: We analytically show the advantage tionV.Wefurtherhypothesizethatpriordeeplearning-based
of SimCAI over other motion models such as Social Forces methods [38], [39] are less optimal in terms of runtime due
[36], RVO [34], [46], and constaPnt velocity [40P]. to the intensive computation requirements by deep neural
We denote the mutliple object tracking accuracy, MOTA networks [47], [48]. For example, ResNet [49] needs more
ofasystemusingaparticularmotionmodelasMOTAmodel than25MBforstoringthecomputedmodelinmemory,and
anddeﬁneitasMOTAmodel = MOTA + MOTA morethan4billionﬂoatpointoperations(FLOPs)toprocess
c c i i (cid:2)
where c and i denote an agent whose motion is being mod- a single image of size 224 224 [47].
eled using collision avoidance and interaction, and MOTA Wewouldliketoclarifythatbyrealtimeperformance,we
c
andMOTA denotetheirindividualaccuracies,respectively. refer to the realtime computation of the tracking algorithm
i
1273
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. only. We do not consider the computation time of Mask R- the tracking algorithm only. We do not consider the
CNN. This is standard practice by tracking-by-detection al- computation time of Mask R-CNN. This is conven-
gorithms[39]thatonlycontributetothetrackingcomponent, tionally accepted by tracking-by-detection methods that
similar to this work. We therefore compare with realtime optimize only the tracking component. We therefore
tracking algorithms. compare with algorithms that also compute tracking in
realtime.
V. EXPERIMENTS The methods that satisfy these criteria are listed in Ta-
A. Datasets blesIIandIII.ForevaluationontheTRAFdataset,however,
one additional criterion is required: the availability of open-
We highlight the performance of RoadTrack through ex-
sourced code. There are only two methods (Table I) that
tensive experiments on different trafﬁc datasets.
(Dense) TRAF Dataset: We use the TRAF trafﬁc satisfy all of the above criteria.
We point out that in selecting methods to compare with
dataset [3] that consists of a set of 60 video sequences that
for each dataset according to the above criteria, all tables
contain dense trafﬁc with highly heterogeneous agents with
need not have the same selection of methods. For example,
front and top-down viewpoints, stationary and moving cam-
the methods in Tables II,III do not have open-sourced code.
eramotions,andduringbothdayandnight.Thesevideosare
ofhighwayandurbantrafﬁcinhighpopulationcountrieslike
C. Evaluation Metrics
China and India. Most importantly, ground truth annotations
Weusestandardtrackingmetricsdeﬁnedin[52].Wecom-
consisting of 2-D bounding box coordinates and agent types
pare the overall accuracy (MOTA) which is computed using
areprovidedwiththedataset.Thekeyaspectsofthisdataset (cid:0)
are the high density and the heterogeneity. the formula: MOTA = 1 (FN+FP+IDS) where FN, FP, IDS,
GT
(Sparse) MOT & KITTI-16 Datasets: There are now and GT correspond to the number of false negatives, false
several popular open-source tracking benchmarks available positives,ID switches, andgroundtruth agents,respectively.
on which researchers can test and compare the performance Additionally, we report the number of mostly tracked (MT)
of tracking algorithms. The current state-of-the-art bench- and mostly lost (ML) agents as well as the precision of the
mark is the MOT benchmark [8], which contains a mix of detector (MOTP), as per their provided deﬁnitions in [52].
pedestriansandtrafﬁcsequences.However,theMOTbench- In accordance with the strict annotation protocol adopted by
markisageneraltrackingbenchmarkdataset.Therefore,we theMOTbenchmark,wedonotcountstationaryagentssuch
additionally conduct experiments exclusively on the KITTI- as parked vehicles in our formulation. Detected objects such
16trafﬁcsequence[50].ItshouldbenotedthattheKITTI-16 as trafﬁc signals are thus considered false positives.
sequence is sparse, consisting of mostly cars, and does not
contain road-agent interactions. Dataset Tracker FPS" MT(%)" ML(%)# IDS# FN# MOTP(%)" MOTA(%)"
MOTDT 37.9 0 98.2 15(<0.1%) 18,764(33.0%) 63.3 67.0
TRAF1 MDP 9.3 0 98.2 21(<0.1%) 18,667(32.8%) 60.1 67.1
B. Evaluation Methods RoadTrack 43.9 0 95.6 163(0.3%) 17,953(31.6%) 58.8 68.1
MOTDT 41.6 0 98.8 17(<0.1%) 18,201(32.7%) 60.3 67.3
TRAF2 MDP 20.9 0 100.0 7(<0.1%) 18,105(32.5%) 59.6 67.5
Due to the open-source nature of the MOT benchmark, RoadTrack 12.3 0 92.3 55(0.1%) 17,202(30.9%) 60.8 69.0
MOTDT 50.7 3.3 67.1 64(<0.1%) 34,883(27.0%) 69.6 72.9
there are a large number of methods available in the MOT TRAF3 RoaMdDTrPack 5316..86 320.2 14000..00 620((<0.00.%1%)) 1493,,502517((1353..13%%)) 6790..21 6864..78
benchmark (80 and 87 on 2D MOT15 and MOT16, respec- TRAF4 MMOTDDPT 396..06 11..22 7867..32 11623(<(00..11%%)) 5549,,804997((2391..03%%)) 6656..32 7680..97
RoadTrack 40.6 6.0 54.6 266(0.1%) 47,444(25.1%) 65.1 74.7
tively). To demonstrate the superiority of RoadTrack, it is MOTDT 36.0 0.7 75.9 221(0.2%) 33,774(28.9%) 63.2 70.9
TRAF5 MDP 22.5 0 98.4 6(<0.1%) 38,091(32.6%) 64.9 67.3
therefore sufﬁcient to select state-of-the-art methods from RoadTrack 41.4 1.5 55.7 299(0.3%) 24,860(21.3%) 63.1 78.4
MOTDT 33.0 0 87.5 161(0.1%) 58,212(29.4%) 63.3 70.5
all the methods, and compare RoadTrack against this set TRAF6 MDP 4.3 0 99.3 0(0.0%) 65,687(33.2%) 68.6 66.8
RoadTrack 14.6 0.7 67.8 283(0.1%) 52,017(26.3%) 62.8 73.6
of methods. We deﬁne a state-of-the-art method as one that MOTDT 34.7 0.9 83.6 601(0.1%) 218,683(29.3%) 65.5 70.6
Summary MDP 10.1 0.2 97.0 50(<0.1%) 242,704(32.6%) 65.3 67.4
satisﬁes all of the following criteria simultaneously: RoadTrack 31.6 7.0 66.9 1128(0.2%) 178,997(24.0%) 65.7 75.8
1) Higher Average Rank: The MOT benchmark assigns TABLEI:EvaluationontheTRAFdatasetwithMOTDT[53]and
MDP [54]. MOTDT is currently the best online tracker on the
an “average rank” to each method. The average rank
MOT benchmark with open-sourced code. Bold is best. Arrows
([51],page390)ofatrackingalgorithmiscomputedby (";#) indicate the direction of better performance. Observation:
averaging over all the metrics. This metric effectively RoadTrackimprovestheaccuracy(MOTA)overthestate-of-the-art
rankstheoverallperformanceofatrackingalgorithmby by 5.2% and precision (MOTP) by 0.2%.
taking all the metrics into account simultaneously. We
select competitor methods that have a higher (better)
D. Analysis of Results & Discussion
average rank than ours.
2) Published Work: Many of the tracking methods sub- On Dense Datasets: We provide results on the TRAF
mitted on the MOT benchmark are anonymous. We dataset using RoadTrack and demonstrate a state-of-the-
therefore select methods that are published in peer- art average MOTA of 75.8% (Table I). The aim of this
reviewed conferences and journals. experiment is to highlight the advantage of our overall
3) Online Tracking: RoadTrack performs tracking using tracking algorithm in dense and heterogeneous trafﬁc. We
only the information from the previous frame and compare RoadTrack with methods (selected according to
assumes no knowledge of future frames, thus making criteria established in Section V-B) on the dense TRAF
it an online tracking method. Therefore, we compare dataset in Table I. MOTDT [53] and MDP [54] are the only
RoadTrack with top-performing online methods for fair state-of-the-artmethodswithavailableopen-sourcecode.All
comparison. methods are evaluated using a common set of detections
4) Realtime Performance: RoadTrack has realtime perfor- obtained using Mask R-CNN. Compared to these methods,
mance and performs tracking at up to approximately we improve upon MOTA by 5.2% on absolute. This is
30 fps (see Tables II,III). Note that by realtime per- roughly equivalent to a rank difference of 46 on the MOT
formance, we refer to the realtime computation of benchmark.
1274
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. Tracker FPS" MT(%)" ML(%)# IDS# FN# MOTP(%)" MOTA(%)" attributed to a high number of detections that are incorrectly
APHWDPLp[55] 6.7 17.6 11.8 18 831 72.6 40.7 classiﬁedasfalsepositives.Forinstance,road-agentsthatare
TI-16 RAHAMybRIrRid11D55Ap[Tu3b8[]5[63]9] 514...496 1051..0.98 111717...686 111808 787001694 777012...976 544016...423 too distant to be manually labeled are not annotated in the
KIT AM[57] 0.5 5.9 17.6 19 805 70.5 40.6 ground truth sequence. We observed this to be true for the
RoadTrack 28.9 29.4 11.7 15 668 71.3 12.2
methods we compared with as well. Therefore, we exclude
TABLE II: Evaluation on the KITTI-16 dataset from the MOT
FP from the calculation of MOTA for all methods in the
benchmark with online methods that have an average rank higher
thanours.RoadTrackisatleastapproximately4(cid:2)fasterthanprior interest of fair evaluation. (cid:2)
methods. While we do not outperform on the MOTA metric, we We note, however, that RoadTrack is least 4 faster on
still achieve the highest MT, ML, FN, and MOTP. We analyze"o#ur the KITTI-16 and 2D MOT15 datasets at approximately
MOTA performance in Section V-D. Bold is best. Arrows ( ; ) 30 fps (Tables II,III). To explain the speed-up, we refer
indicate the direction of better performance. The values for all
to theorem IV.1 and the runtime analysis presented in Sec-
methodscorrespondtotheKITTI-16sequencespeciﬁcally,andnot (cid:2) (cid:2)
the entire 2D MOT15 dataset. tion IV-C. We specially point to the 15 and 5 speed-up
over learning-based tracking methods, [38], [39] in Table II
Tracker FPS" MT(%)" ML(%)# IDS# FN# MOTP(%)" MOTA(%)" which we attribute the linear time computation of SimCAI
OT15 AHAMyMbIrR[i5d17D5]A[T38[]56] 140...965 111511...844 244623...824 1330452886 233914,,,318944708 777120...765 333754...603 as opposed to the intensive computation required by deep
M APHWDPLp[55] 6.7 8.7 37.4 586 33,203 72.6 38.5 learning models.
2D RoadTrack 28.9 18.6 32.7 429 27,499 75.6 20.0 Ablation Experiments: We highlight the advantages of
EAMTTpub[58] 11.8 7.9 49.1 965 102,452 75.1 38.8
RAR16pub[39] 0.9 13.2 41.9 648 91,173 74.8 45.9 SimCAI through ablation experiments in Table IV. The aim
MOT16 SMARTMoOAaTIdMRDT1rT[63a8c[[5k]537]] 210108....2068 11124450....6023 33448631....1366 477772793242 99781285,,,,184415137631 77774554....9858 44447760....6209 ocofmthpeasreeewxiptehrtihmeefnotlsloiswtiongisvoalraitaetitohnesboefnReﬁoatdoTfrSaicmkCinAwI.hWiche
we replace our novel motion model SimCAI with standard
TABLEIII:EvaluationonthefullMOTbenchmark.ThefullMOT
dataset is sparse and is not a trafﬁc-based dataset. RoadTrack is andstate-of-the-artmotionmodels,whilekeepingtherestof
(cid:2)
at least approximately 4 faster than previous methods. While the system untouched:
we do not outperform on the MOTA metric, we still achieve the
(cid:15) Constant Linear Velocity (Const Lin Vel). We re-
highest MT, ML (MOT16), FN, and MOTP(MOT15). We analyze
ourMOTAperformanceinSectionV-D.Boldisbest.Arrows(";#) place SimCAI with a constant velocity linear motion
indicate the direction of better performance. model [40].
(cid:15) SocialForces(SF).WereplaceSimCAIwiththeSocial
MotionModel FPS" MT(%)" ML(%)# IDS# FN# MOTP(%)" MOTA(%)" Forces motion model [36].
Const.Vel 30 0.0 100 11 247,738(33.3&) 66.3 66.7 (cid:15) Reciprocal Velocity Obstacles (RVO) [34]. We replace
SF 30 0.1 98.6 147 246,528(33.1%) 63.8 66.3
RVO 30 0.0 100 38 247,675(33.2%) 63.8 66.9 SimCAI with the RVO motion model.
SimCAI 30 7.0 66.9 1128 178,997(24.0%) 65.7 75.8
TABLE IV: Ablation experiments to show the advantage of Sim- WecompareSimCAIwithothermotionmodels(Constant
CAI.WereplaceSimCAIwithaconstantvelocity(ConstLinVel) linearvelocity,SocialForces,andRVO)onthedenseTRAF
[40], Social Forces (SF) [36], and RVO motion model (RVO)[34]. dataset.Theseexperimentswereperformedbyonlyreplacing
The rest of the method is identical to the original method. All SimCAI with other motion models, keeping the rest of the
variations operate at similar fps of approximately 30 fps. Bold is
" # systemunchanged.WeobservethatSimCAIoutperformsthe
best. Arrows ( ; ) indicate the direction of better performance.
motion models by at least 8.9% on absolute on MOTA. All
thevariationsusedintheablationexperimentsoperatedatthe
MOTDT is currently the fastest method (according to the
same fps of approximately 30 fps. Additionally, we exper-
selectioncriteriaofSectionV-B)ontheMOT16benchmark.
imentally verify the analysis of Section IV-C by observing
Ourapproachoperatesatrealtimespeedsuptoapproximately (cid:20) (cid:20)
30 fps and is comparable with MOTDT (Table I). Our that MOTAlinear MOTARVO MOTASimCAI. Once
realtime performance results from the runtime analysis from again, we point to our high IDS in Table IV, compared to
Section IV-C and theorem IV.1. the IDS of other motion models. As mentioned previously,
this is due to the near-failure of other motion models (near
Note that we observe an abnormally high number of
100% ML) to track road agents in dense trafﬁc. Not being
identity switches compared to other methods; however, this
abletotrackaroad-agentexcludesthemasaIDScandidate.
is because prior methods mostly fail to maintain an agent’s
track for more than 20% of their total visible time (near VI. LIMITATIONSANDFUTUREWORK
100% ML). Not being able to track road-agents for most There are many avenues of future work for our presented
of the time excludes those agents as possible candidates work. Currently, many parameters in our algorithm such as
for IDS, thereby resulting in lower IDS for prior methods. the radii for the social and public regions, steering angles,
Interestingly, the low IDS score for prior methods also andconeangles,areheuristicallychosenforoptimumperfor-
contributes to their reasonably high MOTA score, despite mance. It would be more efﬁcient to learn these parameters
near-failure to track agents in dense trafﬁc. instead, using data driven and machine learning techniques.
On Standard Benchmarks: In the interest of com- Furthermore, the results from tracking road-agents can be
pleteness and thorough evaluation, we also evaluate Road- directly used to further research in related areas such as
Track on sparser tracking datasets and present results on trajectory prediction. With the increased popularity of deep-
both trafﬁc-only datasets (KITTI-16) in Table II as well learningandimprovedtrackingmethods,deeplearningtech-
as datasets containing only pedestrians (MOT) in Table III. niques can be employed for predicting the future motion of
RoadTrack’s main advantage is SimCAI, which is based on road-agents in dense and heterogeneous trafﬁc.
modelingcollisionavoidanceandinteractions.Intheabsence
of one or both, we do not expect it demonstrate superior VII. ACKNOWLEDGEMENTS
performanceoverpriormethodsonthesparseKITTI-16and This work was supported in part by ARO Grants
MOT datasets. While not conclusive, we believe our low W911NF1910069andW911NF1910315,SemiconductorRe-
MOTA score on the 2D MOT15 and KITTI-16 may also be search Corporation (SRC), and Intel.
1275
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [23] Michael Darms, Paul Rybski, and Chris Urmson. Classiﬁcation and
tracking of dynamic objects with multiple sensors for autonomous
[1] Alex Teichman and Sebastian Thrun. Practical object recognition in driving in urban environments. In Intelligent Vehicles Symposium,
autonomousdrivingandbeyond. InAdvancedRoboticsanditsSocial 2008IEEE,pages1197–1202.IEEE,2008.
Impacts,pages35–38.IEEE,2011. [24] JulienMoras,Ve´roniqueCherfaoui,andPhilippeBonnifait.Credibilist
[2] Yuexin Ma, Dinesh Manocha, and Wenping Wang. Autorvo: Local occupancy grids for vehicle perception in dynamic environments. In
navigation with dynamic constraints in dense heterogeneous trafﬁc. RoboticsandAutomation(ICRA),2011IEEEInternationalConference
arXivpreprintarXiv:1804.02915,2018. on,pages84–89.IEEE,2011.
[3] Rohan Chandra, Uttaran Bhattacharya, Aniket Bera, and Dinesh [25] Nicolai Wojke and Marcel Ha¨selich. Moving vehicle detection
Manocha. Traphic:Trajectorypredictionindenseandheterogeneous and tracking in unstructured environments. In IEEE International
trafﬁc using weighted interactions. In The IEEE Conference on Conference on Robotics and Automation (ICRA), pages 3082–3087.
ComputerVisionandPatternRecognition(CVPR),June2019. IEEE,2012.
[4] RohanChandra,UttaranBhattacharya,ChristianRoncal,AniketBera, [26] Benjamin Coifman, David Beymer, Philip McLauchlan, and Jitendra
andDineshManocha. Robusttp:End-to-endtrajectorypredictionfor Malik. A real-time computer vision system for vehicle tracking
heterogeneous road-agents in dense trafﬁc with noisy sensor inputs. and trafﬁc surveillance. Transportation Research Part C: Emerging
arXivpreprintarXiv:1907.08752,2019. Technologies,6(4):271–288,1998.
[5] Rohan Chandra, Tianrui Guan, Srujan Panuganti, Trisha Mittal, Ut- [27] Matthias Luber, Johannes A Stork, Gian Diego Tipaldi, and Kai O
taran Bhattacharya, Aniket Bera, and Dinesh Manocha. Forecasting Arras. People tracking with human motion predictions from social
trajectory and behavior of road-agents using spectral clustering in forces. In 2010 IEEE International Conference on Robotics and
graph-lstms. arXivpreprintarXiv:1912.01118,2019. Automation,pages464–469.IEEE,2010.
[6] SayananSivaramanandMohanManubhaiTrivedi.Integratedlaneand [28] Chanho Kim, Fuxin Li, Arridhana Ciptadi, and James M Rehg.
vehicle detection, localization, and tracking: A synergistic approach. Multiple hypothesis tracking revisited. In Proceedings of the IEEE
IEEETransactionsonIntelligentTransportationSystems,14(2):906– International Conference on Computer Vision, pages 4696–4704,
917,2013. 2015.
[7] RicardoGuerrero-Go´mez-Olmedo,RobertoJLo´pez-Sastre,Saturnino [29] JiahuiChen,HaoSheng,YangZhang,andZhangXiong. Enhancing
Maldonado-Basco´n,andAntonioFerna´ndez-Caballero. Vehicletrack- detection model for multiple hypothesis tracking. In Conf. on Com-
ing by simultaneous detection and viewpoint estimation. In In- puter Vision and Pattern Recognition Workshops, pages 2143–2152,
ternational Work-Conference on the Interplay Between Natural and 2017.
ArtiﬁcialComputation,pages306–316.Springer,2013. [30] Hao Sheng, Li Hao, Jiahui Chen, Yang Zhang, and Wei Ke. Robust
[8] Anton Milan, Laura Leal-Taixe´, Ian Reid, Stefan Roth, and Konrad local effective matching model for multi-target tracking. In Paciﬁc
Schindler. Mot16: A benchmark for multi-object tracking. arXiv RimConferenceonMultimedia,pages233–243.Springer,2017.
preprintarXiv:1603.00831,2016. [31] Rohan Chandra, Uttaran Bhattacharya, Aniket Bera, and Dinesh
[9] Jinshi Cui, Hongbin Zha, Huijing Zhao, and Ryosuke Shibasaki. Manocha.Densepeds:Pedestriantrackingindensecrowdsusingfront-
Tracking multiple people using laser and vision. In Proc. of the rvoandsparsefeatures. arXivpreprintarXiv:1906.10313,2019.
IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems [32] AniketBera,NicoGaloppo,DillonSharlet,AdamLake,andDinesh
(IROS),pages2116–2121.IEEE,2005. Manocha. Adapt:real-time adaptivepedestriantracking forcrowded
[10] LouisKratzandKoNishino. Trackingpedestriansusinglocalspatio- scenes. InRoboticsandAutomation(ICRA),2014IEEEInternational
temporal motion patterns in extremely crowded scenes. Pattern Conferenceon,pages1801–1808.IEEE,2014.
Analysis and Machine Intelligence, IEEE Transactions on, (99):11, [33] DonaldReidetal. Analgorithmfortrackingmultipletargets. IEEE
2011. transactionsonAutomaticControl,24(6):843–854,1979.
[11] Allison Bruce and Geoffrey Gordon. Better motion prediction for [34] Jur Van Den Berg, Stephen J Guy, Ming Lin, and Dinesh Manocha.
people-tracking. InProc.oftheInternationalConferenceonRobotics Reciprocal n-body collision avoidance. In Robotics research, pages
andAutomation(ICRA),2004. 3–19.Springer,2011.
[12] Haifeng Gong, Jack Sim, Maxim Likhachev, and Jianbo Shi. Multi- [35] Yuexin Ma, Dinesh Manocha, and Wenping Wang. Efﬁcient recip-
hypothesis motion planning for visual object tracking. In 2011 rocal collision avoidance between heterogeneous agents using ctmat.
InternationalConferenceonComputerVision,pages619–626.IEEE, In International Conference on Autonomous Agents and Multiagent
2011. Systems,2018.
[13] Lin Liao, Dieter Fox, Jeffrey Hightower, Henry Kautz, and Dirk [36] Dirk Helbing and Peter Molnar. Social force model for pedestrian
Schulz. Voronoitracking:Locationestimationusingsparseandnoisy dynamics. PhysicalreviewE,51(5):4282,1995.
sensor data. In Proc. of the IEEE/RSJ International Conference on [37] KotaYamaguchi,AlexanderCBerg,LuisEOrtiz,andTamaraLBerg.
IntelligentRobotsandSystems(IROS),2003. Whoareyouwithandwhereareyougoing? InComputerVisionand
[14] RaminMehran,AlexisOyama,andMubarakShah. Abnormalcrowd PatternRecognition(CVPR),2011IEEEConferenceon,pages1345–
behavior detection using social force model. In Proc. of the IEEE 1352.IEEE,2011.
ConferenceonComputerVisionandPatternRecognition,CVPR,pages [38] Amir Sadeghian, Alexandre Alahi, and Silvio Savarese. Tracking
935–942,2009. the untrackable: Learning to track multiple cues with long-term
[15] StefanoPellegrini,AndreasEss,KonradSchindler,andLucVanGool. dependencies. In Proceedings of the IEEE International Conference
You’ll never walk alone: Modeling social behavior for multi-target onComputerVision,pages300–311,2017.
tracking. In IEEE International Conference on Computer Vision [39] KuanFang,YuXiang,XiaochengLi,andSilvioSavarese. Recurrent
(ICCV),2009. autoregressivenetworksforonlinemulti-objecttracking.In2018IEEE
[16] AniketBeraandDineshManocha. REACH:Realtimecrowdtracking WinterConferenceonApplicationsofComputerVision(WACV),pages
using a hybrid motion model. Proc. of the International Conference 466–475.IEEE,2018.
onRoboticsandAutomation(ICRA),2015. [40] NicolaiWojke,AlexBewley,andDietrichPaulus. SimpleOnlineand
[17] AniketBera,SujeongKim,TanmayRandhavane,SrihariPratapa,and Realtime Tracking with a Deep Association Metric. arXiv preprint
Dinesh Manocha. Glmp-realtime pedestrian path prediction using arXiv:1703.07402,March2017.
global and local movement patterns. In 2016 IEEE International [41] HaroldWKuhn.Thehungarianmethodfortheassignmentproblem.In
Conference on Robotics and Automation (ICRA), pages 5528–5535. 50YearsofIntegerProgramming1958-2008,pages29–47.Springer,
IEEE,2016. 2010.
[18] FrankDellaertandChuckThorpe. Robustcartrackingusingkalman [42] Michael Levandowsky and David Winter. Distance between sets.
ﬁltering and bayesian templates. In Conference on intelligent trans- Nature,234(5323):34,1971.
portationsystems,volume1,1997. [43] Rohan Chandra, Uttaran Bhattacharya, Tanmay Randhavane, Aniket
[19] Daniel Streller, K Furstenberg, and Klaus Dietmayer. Vehicle and Bera,andDineshManocha.Roadtrack:Trackingroadagentsindense
object models for robust tracking in trafﬁc scenes using laser range and heterogeneous environments. arXiv preprint arXiv:1906.10712,
images.InIntelligentTransportationSystems,2002.Proceedings.The 2019.
IEEE5thInternationalConferenceon,pages118–123.IEEE,2002. [44] EdwardTwitchellHall. Thehiddendimension,volume609. Garden
[20] AnnaPetrovskayaandSebastianThrun.Modelbasedvehicledetection City,NY:Doubleday,1966.
andtrackingforautonomousurbandriving.AutonomousRobots,26(2- [45] SatoruSatake,TakayukiKanda,DylanFGlas,MichitaImai,Hiroshi
3):123–139,2009. Ishiguro,andNorihiroHagita. Howtoapproachhumans?:strategies
[21] Andreas Ess, Konrad Schindler, Bastian Leibe, and Luc Van Gool. for social robots to initiate interaction. In Proceedings of the 4th
Objectdetectionandtrackingforautonomousnavigationindynamic ACM/IEEE international conference on Human robot interaction,
environments. The International Journal of Robotics Research, pages109–116.ACM,2009.
29(14):1707–1725,2010. [46] AniketBeraandDineshManocha.Realtimemultilevelcrowdtracking
[22] AkshayRangeshandMohanMTrivedi.Noblindspots:Full-surround using reciprocal velocity obstacles. In Pattern Recognition (ICPR),
multi-objecttrackingforautonomousvehiclesusingcameras&lidars. 2014 22nd International Conference on, pages 4164–4169. IEEE,
arXivpreprintarXiv:1802.08755,2018. 2014.
1276
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. [47] Qing Zhang, Mengru Zhang, Mengdi Wang, Wanchen Sui, Chen
Meng,JunYang,WeidanKong,XiaoyuanCui,andWeiLin.Efﬁcient
deep learning inference based on model compression. In The IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)
Workshops,June2018.
[48] Meiqi Wang, Zhisheng Wang, Jinming Lu, Jun Lin, and Zhongfeng
Wang. E-lstm:Anefﬁcienthardwarearchitectureforlongshort-term
memory. IEEEJournalonEmergingandSelectedTopicsinCircuits
andSystems,2019.
[49] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
residual learning for image recognition. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 770–
778,2016.
[50] AndreasGeiger,PhilipLenz,andRaquelUrtasun. Arewereadyfor
autonomousdriving?thekittivisionbenchmarksuite. InConference
onComputerVisionandPatternRecognition(CVPR),2012.
[51] Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair
Weiss, editors. Computer Vision - ECCV 2018 - 15th European
Conference, Munich, Germany, September 8-14, 2018, Proceedings,
PartI,volume11205ofLectureNotesinComputerScience.Springer,
2018.
[52] Arnold WM Smeulders, Dung M Chu, Rita Cucchiara, Simone
Calderara, Afshin Dehghan, and Mubarak Shah. Visual tracking:
An experimental survey. IEEE Transactions on Pattern Analysis &
MachineIntelligence,(1):1,2013.
[53] Chen Long, Ai Haizhou, Zhuang Zijie, and Shang Chong. Real-
timemultiplepeopletrackingwithdeeplylearnedcandidateselection
and person re-identiﬁcation. In IEEE International Conference on
MultimediaandExpo(ICME),2018.
[54] Yu Xiang, Alexandre Alahi, and Silvio Savarese. Learning to track:
Online multi-object tracking by decision making. In Proceedings of
the IEEE international conference on computer vision, pages 4705–
4713,2015.
[55] Long Chen, Haizhou Ai, Chong Shang, Zijie Zhuang, and Bo Bai.
Online multi-object tracking with convolutional neural networks. In
Image Processing (ICIP), 2017 IEEE International Conference on,
pages645–649.IEEE,2017.
[56] Min Yang, Yuwei Wu, and Yunde Jia. A hybrid data association
framework for robust online multi-object tracking. arXiv preprint
arXiv:1703.10764,2017.
[57] Qi Chu, Wanli Ouyang, Hongsheng Li, Xiaogang Wang, Bin Liu,
andNenghaiYu. Onlinemulti-objecttrackingusingcnn-basedsingle
object tracker with spatial-temporal attention mechanism. In IEEE
International Conference on Computer Vision (ICCV), pages 4846–
4855,2017.
[58] RicardoSanchez-Matilla,FabioPoiesi,andAndreaCavallaro. Online
multi-target tracking with strong and weak detections. In European
ConferenceonComputerVision,pages84–99.Springer,2016.
1277
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 12:24:11 UTC from IEEE Xplore.  Restrictions apply. 