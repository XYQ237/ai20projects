2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Ground Texture Based Localization Using Compact Binary Descriptors
Jan Fabian Schmid1,2, Stephan F. Simon1, Rudolf Mester2,3
Abstract—Ground texture based localization is a promising
approach to achieve high-accuracy positioning of vehicles. We
present a self-contained method that can be used for global
localizationaswellasforsubsequentlocallocalizationupdates,
i.e. it allows a robot to localize without any knowledge of
its current whereabouts, but it can also take advantage of a
prior pose estimate to reduce computation time signiﬁcantly.
Our method is based on a novel matching strategy, which
we call identity matching, that is based on compact binary
feature descriptors. Identity matching treats pairs of features Fig. 1: Examples of the ground texture image database of
as matches only if their descriptors are identical. While other Zhangetal.[1]:ﬁneasphalt,coarseasphalt,carpet,concrete,
methods for global localization are faster to compute, our
tiles, and wood.
methodreacheshigherlocalizationsuccessrates,andcanswitch
to local localization after the initial localization.
I. INTRODUCTION to the conﬁdence in a prior pose estimate, while increasing
thelocalizationsuccessratecomparedtoglobalmethodsthat
High-accuracy localization capabilities are a precondition
donottakeadvantageofsuchaprior.Furthermore,thispaper
to enable fully autonomous agents for tasks like freight and
contributes the ﬁrst quantitative evaluation of ground texture
passenger transport. A promising approach to this task is
based localization approaches. We compare our approach to
ground texture based visual localization using a downward-
Micro-GPS[1],aglobalmethod,Ranger[5],alocalmethod,
facing camera. In contrast to approaches with a forward-
and StreetMap [6], which can be used for both tasks.
facing camera, it does not suffer from occlusion of the
surrounding, works in dynamic environments without static II. PROBLEMSTATEMENT
landmarks, avoids privacy issues, and can be made indepen-
Consider an agent such as an autonomous robot with
dent of external lighting conditions. Using ground texture
restricted operation area, e.g. a warehouse robot, equipped
allows to build infrastructure-free solutions that provide
with a downward-facing camera. To be able to take on tasks
reliable centimeter precise localization on the most relevant
and navigate in the area, the robot needs a map and needs
ground coverings like asphalt, concrete, and carpet [1].
to be able to localize within that map.
Previous approaches require an initial localization estima-
During the mapping phase, the agent explores the envi-
tion from an external source [2], [3], [4], [5], making them
ronment. The agent gathers observations in form of ground
unsuitable for a self-contained localization system, or they
images,andestimatestheircorrespondingposesintheworld.
areslowtocomputeforincrementallocalizationupdates[1],
Weassumethattheseposeestimatesareoptimizedforglobal
[6], which limits the achievable localization accuracy. For
consistency.Theposeestimatescanbedescribedasstandard
example, if a warehouse robot with a typical velocity of
Euclidean transformations of rotation and translation in two
10km/hhasalocalizationlatencyof200ms,therobotmoves
dimensionsifweassumetohaveaverticallyorientedpinhole
morethan0.5mduringalocalizationupdate.Thepathtaken
camera with constant distance to a ﬂat ground.
during the localization update can only be approximated,
which also requires additional computational effort. Problem1(Mapping). Givenasetofobservationsoftheen-
We present an adaptation to the approach of Zhang et vironmentinformofgroundimagesI (thereferenceimages)
al. [1] that performs fast localization updates as it is able to and corresponding pose estimates T, process the images
focus on a restricted area of the map according to a prior to extract relevant information using an image processing
pose estimate. Our method employs compact LATCH [7] function f . Subsequently, construct a map M that stores
m
descriptors with less than two bytes per descriptor. Also, we theextractedinformationefﬁcientlyusingamappingfunction
introduceidentityfeaturematching,whereonlyidenticalde- m and the pose estimates T:
scriptorsareconsideredasmatches,anduseitassubstitution
M =m(f (I),T). (1)
ofapproximatenearestneighborsearch.Thesechangesallow m
ustoscalethecomputationaleffortoflocalizationaccording Onceamapisavailable,itcanbeusedforlocalization.For
this purpose, the agent searches the map for visual features
1RobertBoschGmbH,Hildesheim,Germany that correspond to the features it is currently observing.
SchmidJanFabian@gmail.com
It can be differentiated between global/initial localization
2VSILab,CSDept.,GoetheUniversity,FrankfurtamMain,Germany
3NorwegianOpenAILab,CSDept.,NTNUTrondheim,Norway without an estimation of the current pose (p=∅) and local
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1315
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. localization with available pose estimation prior (p (cid:54)= ∅). A purpose, a voting map is created, which is a grid with a size
localization algorithm might treat the cases p=∅ and p(cid:54)=∅ that corresponds to that of the mapped environment. Then,
separately or it has a common approach to both cases. each retrieved ANN votes for the grid cell containing the
camera position that would explain the occurrence of the
Problem 2 (Localization). Given a map M, an observation
proposed correspondence. Finally, only the correspondences
of the environment in form of a query image i, an image
voting for the grid cell that obtained the most votes are used
processing function f , and a localization prior p, estimate
l to estimate the camera pose with a RANSAC procedure.
the pose t of the image using a pose estimation function g:
Chenetal.developedStreetMap[6],whichisabletomake
t =g(f (i),M,p). (2) use of a localization prior, but does not require one. While
est l
there is also a version speciﬁcally for tiled ground textures,
The estimated agent pose test is considered correct if we only consider the feature-based variant. If no prior is
it is closer to the actual pose t than a threshold distance available, they use bag of words (BoW) image retrieval [9]
dt and if the absolute angle between the two Euclidean to ﬁnd similar reference images to the query image. For this
transformations is smaller than an orientation threshold ot. purpose, BoW representations of the images are computed
usingtheSURF[10]featuredescriptorsextractedfromthem.
III. RELATEDWORK
After retrieval of the most similar reference images, their
Weconsidermap-basedlocalizationapproachesforrobots features are matched to the features of the query image.
equipped with a downward-facing camera. These are meth- For each feature of the query image, they search for its
ods that allow to perform absolute localization within a nearestneighborfromthereferenceimagesandsubsequently
conﬁnedarea.Methodsforincrementallocalization,thatesti- ﬁlter these matches with the ratio test constraint [11],
matethevehicleposerelativetoapreviouspose,accumulate which requires that the most similar reference descriptor is
drift and therefore need to be accompanied by an error signiﬁcantly closer to the query descriptor than the second
correction mechanism, e.g. an absolute localization method. most similar one. The Euclidean transform of the camera
Examination of these methods is out of our scope. pose is ﬁnally estimated using RANSAC.
Globalmethodsdonotrequirealocalizationprior[1],[6],
B. Local localization approaches
while local methods do [2], [3], [4], [5], and therefore have
to be initialized in another way, e.g. using GPS. Kelly et al. [2], [12] developed a photometric localization
Inordertolocalize,itisnecessarytoﬁndcorrespondences approach using normalized cross correlation for template
between the mapped reference images and the current view matchingtoﬁndcorrespondingimagepatchesbetweenquery
oftheautonomousagent.Thiscanbedonewithphotometric andreferenceimages.Theyconstructagroundmapofstatis-
approaches [2], that compare images based on a function of ticallynormalizedpixelintensityvalues.Duringlocalization,
image intensity values, e.g. normalized cross correlation, or the output of a Kalman ﬁlter is used as a localization prior.
with feature-based approaches, that propose well-matching Peaksofatexturescorefunction,whichdependsonthelocal
features as correspondences [1], [3], [4], [5], [6]. These fea- intensity gradient of the pixels, are used to deﬁne up to 16
tures are representations of characteristic image regions [8]. imagepatchesfortemplatematching.Thedifferencebetween
The position of a feature in the image is speciﬁed by its predicted and observed positions of these image patches is
keypoint. Additionally, size and orientation might further combined into a pose update.
specifythefeature.Thefeaturedescriptordescribesthelocal The localization pipeline of Fang et al. [3], [13] relies on
environment of a keypoint. For keypoints it is important the iterative closest point (ICP) algorithm to align reference
that they are repeatable, i.e. the same keypoints for the images during mapping and to register query images for
same physical locations are found for varying conditions of localization. The point clouds needed for this purpose are
recording like camera position and illumination. Descriptors built using extracted corner and edge features. For the ﬁnal
should take similar values for corresponding keypoints, and pose estimation the results of a robust ICP variant are fused
distinctively different values for non-corresponding ones. with odometry information in an extended Kalman ﬁlter.
Nagai and Watanabe [4], [14] propose a method that
A. Global localization approaches
avoids the need for a globally consistent map. Instead, they
Micro-GPS is a localization pipeline proposed by Zhang construct a sparse spatial map of images. Whenever the
et al. [1]. They rely on SIFT for feature extraction, and autonomous system approaches a reference image stored
construct an efﬁcient approximate nearest neighbor (ANN) in the map, correspondences between query and reference
search structure for feature matching, exploiting the fact imageareusedtocorrectforthedriftthataccumulatedsince
that the scale of corresponding features remains essentially thelastabsolutelocalizationstep.Imagetransformationsare
constantforimagesofadownward-facingcamerawithstable estimated through minimization of the reprojection error,
height. Per reference image 50 randomly sampled features which is measured as cross-correlation of intensity values.
areinsertedintothesearchstructure.Duringlocalization,all Kozak and Alban [5] developed Ranger, a method that
query image features are used for feature matching. Each enableslocalizationathighvehiclespeedsofupto120km/h.
feature from the query image is paired with its ANN. A Ranger extracts ORB [15] feature descriptors at Cen-
voting procedure is employed for outlier rejection. For this SurE [16] keypoints. Based on the current prior, the closest
1316
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. reference image is selected. Then, correspondences are gen- (850). A higher number of bits increases the inlier-to-
erated through nearest neighbor matching of features from outlierratio,butdecreasestheabsolutenumberofinliers.To
this reference image and the query image. A cross check compensateforthis,wewouldhavetoextractmorefeatures,
is performed to reject incorrect matches. This means that in increasing computation cost and memory consumption.
orderforthereferenceimagefeatureF andthequeryimage Our matching strategy proposes only those pairs of de-
r
feature F to be considered a match, among all reference scriptors as matches that have identical values. Identity
q
featuresF needstobethenearestneighborofF andamong matchingcanbeimplementedefﬁcientlyastablelookup,i.e.
r q
allqueryfeaturesF needstobethenearestneighborofF . row i of the table contains references to descriptors whose
q r
If afterwards at least 25 correspondences remain, these are decimalrepresentationoftheirbinarystringisequaltoi.For
used to estimate the camera transformation with RANSAC. feature matching of binary descriptors with a dimensionality
Otherwise, the procedure is repeated with the next closest ofn(n=15inourcase),atableoflength2n iscreatedand
reference image (or localization is aborted due to timeout). ﬁlled with pointers to the reference features. Then, to ﬁnd
As mentioned, StreetMap is able to make use of a prior matches for a feature, it is sufﬁcient to retrieve the pointers
as well [6]. Instead of selecting reference images based on of the table row that corresponds to the feature descriptor.
BoW similarity, the images with shortest spatial distance to In contrast to the ANN search index employed by Zhang
the prior are taken into consideration. et al., it is not necessary to compute one search structure
for the entire map, but feature matching can be performed
IV. METHOD on an image to image basis. Accordingly, during mapping,
we create a descriptor table for each reference image. If a
WeadaptMicro-GPS,thelocalizationpipelineofZhanget localization prior is available, only the tables of the closest
al. [1]. Micro-GPS achieves reliable high-precision localiza- reference images are considered for feature matching. For
tiononmostoftheevaluatedgroundtextures,butitrequires global localization without prior, all tables are considered.
morethanhundredmillisecondsforeachlocalizationrequest, The use of identity matching with compact binary de-
even on a fast computer with hardware acceleration. scriptors leads to a large number of incorrectly proposed
Weidentifytheconstructionofaglobalapproximatenear- matches (outliers). E.g. for global localization, typically
estneighbor(ANN)searchstructureforfeaturematching,as less than 0.015% of matches can be considered correct
a major drawback of Micro-GPS. It allows to perform efﬁ- correspondences (inliers). This is why we employ the voting
cient feature matching between query and reference images; procedure of Micro-GPS [1] for outlier rejection. Here, the
however, the structure represents a ﬁxed set of reference outlier matches distribute their votes for the current camera
imagesandneedstoberecomputedwheneveranotherimage positionequallyonthevotingmap,whiletheinliervotesare
isaddedtothemap.Updatingareferenceimagewithamore concentratedinanarrowregion(seeFigure2).Subsequently,
recent recording requires recomputation as well. Also, using the matches that voted for the map cell with most votes are
this matching technique means that correspondences are al- used for a RANSAC-based estimation of the camera pose.
wayssearchedglobally.Themethodcannotusealocalization
prior to reduce the number of considered reference images. V. EVALUATION
We tackle these drawbacks, using identity matching in For evaluation, we use the ground texture image database
conjunction with compact binary descriptors. of Zhang et al. [1]. It contains datasets of six texture types
For feature extraction, we determine keypoints and their (see Figure 1), recorded with a Point Grey camera. The
orientationsusingSIFT[11],andcomputefeaturedescriptors 8-bit gray scale images have a resolution of 1288 by 964
with LATCH [7]. The SIFT feature detector locates regions pixels, covering an area of about 0.2m×0.15m. For each
of interest as local extrema on a Gaussian scale-space texture type, Zhang et al. provide a set of reference images
pyramid. LATCH computes binary descriptors for keypoints for mapping, consisting of about 2000 to 4000 partially
through the comparison of image patch triplets. An anchor overlapping recordings. Furthermore, the database provides
patch p , is extracted at the position of the keypoint and sequences of ground images that were recorded on paths
a
is then compared to two surrounding image patches p ,p . independent to the paths taken for mapping, which we use
1 2
Each bit value of the LATCH descriptor is evaluated by one to evaluate localization performance.
triplet, each of which speciﬁes a unique placement of p Prior to the evaluation, we ﬁnd the best suited parameters
1
and p . A triplet is evaluated to 1 if p is more similar to of the examined methods, if not speciﬁed by the respective
2 a
p than to p and to 0 otherwise. We take advantage of authors, on a training set of 100 query images per ground
1 2
the original LATCH triplet arrangements, which have been texture type. Subsequently, a separate set of 500 images per
optimized by the authors. The order of the employed triplets texture type is used to evaluate our experimental setups.
isaranking basedonhow manytimesatriplethas thesame The employed hardware consists of a E3-1270 Intel Xeon
value for corresponding keypoints and different values for CPU at 3.8GHz, and a Quadro P2000 Nvidia graphics card
non-corresponding ones. Furthermore, strongly correlating (used to compute SIFT features in Micro-GPS).
triplets were removed. In our case, we use only the ﬁrst We separately evaluate localization methods for initial
15 triplets as compact binary descriptors, which results in localization without available prior and for subsequent local
the highest success rate for our number of extracted features localization with available prior. Our main performance
1317
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. metric isthe poseestimation successrate, i.e.the proportion perform identity matching with all reference images. The
of localization queries for which the estimated pose t is retrievedmatchesareusedtocastvotesforthecorresponding
est
closer to the actual pose t than d with an absolute angle camerapositionsonavotingmap.Thecellsizeofthevoting
t
difference of less than o . We adopt the thresholds of Zhang mapgridissetto75×75pixels(12×12mm).Weselectthe
t
et al. [1] of d =30pixels (4.8mm) and o =1.5degrees. matches that voted for the voting map cell with most votes
t t
and perform RANSAC based pose estimation with them.
A. Evaluation of global localization
B. Micro-GPS
Besides our method, we evaluate Micro-GPS [1], for
whichthecodeisprovidedbytheauthors,andStreetMap[6], Image processing: Zhang et al. [1] use SiftGPU1 to
which is re-implemented according to the paper. extract SIFT features. As for all other evaluated localization
methods, features are extracted from full-scale images. The
B. Evaluation of local localization authors employ principal component analysis (PCA) dimen-
For our examination of localization performance with sionalityreductiontoreducethesizeoftheSIFTdescriptors.
available localization prior, we evaluate our method, In our case, the PCA basis for that purpose is created using
StreetMap, and Ranger [5], which we re-implemented ac- the entire set of reference images of the currently evaluated
cording to the system description of the authors. texture type. We use 16-dimensional descriptors, which the
Here,weevaluateposeestimationsuccessratesforvarying authorsfoundtoperformbetterthan8-dimensionalones[1].
accuracies of the localization prior. The prior is created by Mapping: Of each reference image 50 16-dimensional
taking the ground truth camera position of the query image SIFT features are randomly sampled. The authors assume
and by shifting it into a randomly sampled direction. that corresponding features will have similar scale. There-
All of the evaluated local methods use the prior only to fore, they use the scale information to divide the set of
select a subset of closest reference images to the current reference features into 10 groups. For each group, they
pose estimate. In our experiments, we choose the number of constructanANNsearchindexwiththeFLANNlibrary[19].
considered images in respect to the available prior accuracy, Localization:Foreach16-dimensionalSIFTfeatureofthe
basedonempiricevaluationofthenumberofclosestimages query image, its ANN reference feature is retrieved, using
to the prior position that is necessary to ensure that the the search index corresponding to the feature’s scale. Each
closest images to the actual camera position are included. of the obtained matches casts a vote for the camera position
onavotingmapwithacellsizeof50×50pixels(8×8mm).
VI. IMPLEMENTATION Afterwards, the matches that voted for the voting map cell
In the following, we present implementation details of with most votes are used for RANSAC pose estimation.
the evaluated localization methods. We describe the image
C. StreetMap (without prior)
processing, mapping, and localization functions. For all of
Image processing: We extract SURF features using
the evaluated methods, feature extraction is the same for
OpenCV [17], using 4 pyramid octaves with 3 layers each,
reference and query images (f is similar to f ).
m l and a Hessian threshold of 20. Per image the 1000 features
A. Our method with largest response values are kept for further processing.
Image processing: We employ the SIFT implementation Mapping: For each image, a BoW representation is com-
putedbasedontheretrievedSURFfeatures,usingtheFBOW
of the OpenCV 4.0 library [17] to extract keypoints. The
library2. The vocabulary for that purpose was computed
numberoflayersperpyramidoctaveissetto11,thecontrast
beforehand, using default parameters of the library and the
threshold to 0.005, the edge threshold to 13, and the sigma
of the employed Gaussian ﬁlter is set to 8.5. Only the 850 extracted SURF features of 1000 images per texture type.
Localization:Thenumberofconsideredreferenceimages
keypoints with largest response values are kept. Then, we
extract for each keypoint the ﬁrst 15 bit of the OpenCV is reduced by 80%, by selecting the most similar ones to the
queryimagebasedontheirBoWrepresentations.Thisvalue
LATCH descriptor. In order to deal with varying image
is a trade-off between localization performance and com-
orientations, we use the LATCH variant that rotates the
putation time. For matching, we ﬁnd for each query image
consideredimagepatchaccordingtothekeypointorientation.
featurethemostsimilarreferencefeaturefromtheremaining
The half-size of the evaluated patches is set to 8, and the
reference images, using the L2 norm and the OpenCV brute
sigma of the employed Gaussian smoothing is set to 2.2.
Mapping:Foreachreferenceimage,theidentitymatching forcefeaturedescriptormatcher.Aratiotestwithathreshold
table is built. These tables are sparsely populated, which is of 0.9 is employed for outlier rejection. Poses are estimated
in a RANSAC fashion, using the obtained feature matches.
why we implement them as dictionaries that map descriptor
values to lists of indexes from features with that descriptor D. StreetMap (with prior)
value. To use available priors, a k-dimensional tree (k-d
Image processing: OpenCV [17] SURF features are ex-
tree) is constructed from the pose estimates of the reference
tracted from an image pyramid with 5 octaves with 4 layers
images, using the nanoﬂann library [18].
Localization: If a localization prior is available, only 1https://github.com/pitzer/SiftGPU
the closest reference images are considered. Otherwise, we 2https://github.com/rmsalinas/fbow
1318
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. each. The Hessian threshold for keypoint rejection is set to
20,andonlythe768featureswithlargestresponsesarekept.
Mapping:Ak-dtree[18]isbuiltfromthereferenceimage
positions.
Localization: The procedure is the same as for global
localization,buttheconsideredreferenceimagesareselected
based on closeness to the prior, using the k-d tree. Fig. 2: Cutout of a voting map from a successful global lo-
calization attempt. Brightness indicates the voting numbers.
E. Ranger
Matchesvote forthepositionof theupperleft imagecorner.
Imageprocessing:KozakandAlban[5]useCenSurE[16] The true positions of the other 3 corners are depicted in red.
keypoints, which are not robust to the image orientation.
For street vehicles, robustness to orientation is not required
because typically the vehicle orientation is the same during are most similar to each other, resulting in lower keypoint
mapping and localization. In our evaluation, however, image repeatability.Infact,usingpairsofsyntheticallytransformed
orientations during mapping and localization are indepen- images,weﬁndthatwoodisthemostchallengingtexturefor
dent of each other. Therefore, we exchange CenSurE with keypoint detectors to retrieve corresponding keypoints [21].
AKAZE [20] keypoints, which among the OpenCV [17] A voting map is illustrated in Figure 2. For better visu-
keypoint detectors achieved the best results for our Ranger alization, we doubled the voting cell size. One cell, which
implementation. The best parameters we found for AKAZE is corresponding to the actual camera position, received the
are a response threshold of 0.00001, and a single image most votes, while outlier votes are randomly distributed.
pyramid octave with two layers. Up to 1250 keypoints with For local localization, results are presented in Figure 4.
largest response values are kept per image. For feature de- As explained previously, we empirically determined suitable
scription,weemploytherotationinvariantBRIEFdescriptor numbersofreferenceimagesthataretakenintoconsideration
of OpenCV with its full size of 64 bytes. foracertainprioraccuracy.Thecorrespondingﬁxednumbers
Mapping:Ak-dtree[18]isbuiltfromthereferenceimage canbefoundinTableI,theyarechosenratherconservatively
positions. to avoid a situation in which localization with the available
Localization: Features of query image and the closest set of reference images is not possible.
reference image are matched using the OpenCV brute force On both asphalt types, carpet, concrete, and tiles, all
feature descriptor matcher with Hamming norm. For outlier three evaluated methods are almost always able to localize
rejection, a cross check is performed. The remaining feature correctly. Again, wood (Figure 4(f)) presents itself as the
matches are used for RANSAC based pose estimation. If most challenging ground texture type. With decreasing prior
the estimated pose is supported by at least 25 matches, it is accuracy, localization success rates of StreetMap and our
usedasﬁnaloutputofthemethod.Otherwise,theprocedure method decline. Again, this can be explained with a low
of matching and pose estimation is repeated with the next number of inlier matches for wood, which leads to a less
closest reference image, and so on. If the condition is not signiﬁcant inlier voting peak than there is for other textures.
met by any of the considered reference images, we use the For increasing numbers of considered reference images, the
pose estimation that had the most inliers. number of outlier votes increases, and it becomes more
likelythatvariationsinthedistributionofoutliervotescause
VII. RESULTS
higher voting peaks than the inliers. Similarly, the inlier-to-
Pose estimation success rates for our experimental setup outlierratioofStreetMapdecreaseswithincreasingnumbers
forgloballocalizationarepresentedinFigure3.Weobserve of reference images, while Ranger considers one reference
that both types of asphalt, carpet, and tiles are particularly imageafter theotherandis thereforerobustto thisproblem.
well suited for ground texture based localization, as all On wood, our approach is outperformed by both
three evaluated methods reach almost perfect success rates. StreetMap and Ranger. However, they become slow for
The situation is different for concrete and wood. While our larger errors of the prior, due to the use of nearest neighbor
method is still able to localize correctly in 97.0% of the test matching, computing distances between all possible pairings
cases on concrete texture, the original Micro-GPS reaches ofqueryfeaturedescriptorsandreferencefeaturedescriptors.
only 88.4% success rate and StreetMap 82.0%. For wooden Figure 5 presents the required computation time of feature
texture, our method is again the best performing method, matchingforthethreeevaluatedlocalizationmethodsonthe
butonlyachievesasuccessrateof66.6%,whileMicro-GPS carpettestset.Usingapriorwithanexpectederrorof0.35m,
and StreetMap have 51.4% and 39.0%, respectively. Further ittakes0.19stomatchfeaturesforStreetMapand0.26sfor
analysisshowsthatlowersuccessratescanbeexplainedwith Ranger, while our method takes only 0.01s. If the expected
lowernumbersofinliersamongthematchedfeatures.During prior error is 1.5m, feature matching for StreetMap takes
localization, our method identiﬁes on average more than 40 1.87s and 2.72s for Ranger, but only 0.11s for our method.
inliersforasphalt,carpetandtiles,butonly31.5forconcrete TableI presentsforour methodandMicro-GPS thelocal-
and 9.7 for wood texture images. One explanation for this izationtime,withouttherequiredtimeforfeatureextraction.
is, that among the evaluated textures the wooden images Thecomputationaleffortforfeatureextractioniscomparable
1319
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. 1.0 Ours 1.00 1.00
Micro-GPS
0.8 StreetMap rate0.75 rate0.75
uccessrate00..46 Success00..2550 OSRtaurnersegteMrap Success00..2550 OSRtaurnersegteMrap
S 0.00 0.00
0.2 0 250 500 750 1000 1250 1500 0 250 500 750 1000 1250 1500
Errorofthelocalizationprior(mm) Errorofthelocalizationprior(mm)
0.0 Asphalt(coarse)Asphalt(ﬁne) Carpet Concrete Tiles Wood (a) Asphalt (coarse) (b) Asphalt (ﬁne)
Fig. 3: Pose estimation success rates for global localization. 1.00 1.00
TthAeBcLarEpeIt:dLaotcaaselitzadteipoenntdiemnet o(wnitthheouatcfceuartaucryeoefxttrhaectpiorino)r.on Successrate000...257505 OSturersetMap Successrate000...257505 OSturersetMap
Ranger Ranger
Errorofthelocali- Numberofconsidered Computationtime(ms) 0.00 0 250 500 750 1000 1250 1500 0.00 0 250 500 750 1000 1250 1500
zationprior(mm) referenceimages Ours Micro-GPS Errorofthelocalizationprior(mm) Errorofthelocalizationprior(mm)
0 5 1.60 (c) Carpet (d) Concrete
50 10 2.42 1.00 1.00
100 20 3.85
235705050000 12550500000 1378563.1...2782547 Successrate000...257505 OSturersetMap Successrate000...257505 OSturersetMap
Ranger Ranger
1000 750 108.48 0.00 0.00
1500 1000 143.65 0 250 500 750 1000 1250 1500 0 250 500 750 1000 1250 1500
Errorofthelocalizationprior(mm) Errorofthelocalizationprior(mm)
Noprior 2014 286.47 145.55
(e) Tiles (f) Wood
Fig. 4: Pose estimation success rates for local localization.
for both methods, as it is dominated by the use of SIFT.
Using SiftGPU, feature extraction takes us about 40ms. 101
The computational effort of our matching method grows (s)
g
linearlywiththenumberofconsideredreferenceimages;for hin 100
large numbers, it is slower than ANN matching approaches. matc
Athcacnoorduirngmlye,thModic.rHo-oGwPeSvepr,erinfoprmrasctgicloebgallolboaclalloizcaatliioznatifoansteisr orfeature1100−−21 OSturersetMap
f
typicallyperformedonlyonce.Afterwards,thepreviouspose me Ranger
estimationcanbeusedaspriorforthenextlocalizationstep. Ti10−3 0 250 500 750 1000 1250 1500
Errorofthelocalizationprior(mm)
Withincreasingaccuracyoftheavailableprior,lessreference
images have to be considered, reducing the localization Fig. 5: Required computation for feature matching on the
time of our method. If the prior is reliably more accurate carpet dataset for varying prior accuracies.
than 1.5m, our method will be faster than Micro-GPS. At
the same time, as seen in Figure 4, the chance of correct
localization increases when using a prior. with our strategy, allowed us to reach higher localization
The memory consumption of our method is about three success rates than the state-of-the-art methods for global
and a half times as large as that of Micro-GPS. We roughly localization.Furthermore,ourmethodallowstoadd,remove,
estimate the memory requirements as follows. Per reference andupdatemappedreferenceimagesonlinewithouttheneed
image, Micro-GPS stores 50 keypoints (with position, scale, of map recomputation. Also, with our matching strategy the
and orientation) and 50 16-dimensional ﬂoating point de- method is able to take advantage of prior pose estimates to
scriptors, resulting in (50·4·32+50·16·32) bit =32000 perform local localization updates. Apart from wooden ﬂoor
bit. Our method stores per reference image 850 keypoints texture, our method performs similarly well as state-of-the-
(with position and orientation), and a dictionary with 850 art local localization methods, while being faster to com-
pairs of 15-bit descriptor values and integer feature indexes, pute, especially for inaccurate prior pose estimates. Lower
resulting in (850·3·32+850·(15+16)) bit =107950 bit. computational cost can lead to higher effective localization
accuracy, as the time between image recoding and available
VIII. CONCLUSION
poseestimationisshorter,anditenablesmorefrequentpose
We examined methods for ground texture based absolute updates or savings on the required computational power.
localizationwithandwithoutavailablelocalizationprior.We In future research, we want to examine possible alter-
proposeidentitymatching,afeaturematchingstrategybased natives to the use of SIFT keypoints, which make hard-
on compact binary feature descriptors, which simpliﬁes fea- wareaccelerationnecessarytoreachreasonablecomputation
ture matching to a single table lookup. Substituting Micro- times, and we want to evaluate modiﬁcations to improve the
GPS’s [1] use of a global search index for feature matching localization capability on wooden texture.
1320
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [11] D. G. Lowe, “Distinctive image features from scale-invariant key-
points,” International Journal of Computer Vision (IJCV), vol. 60,
[1] L.Zhang,A.Finkelstein,andS.Rusinkiewicz,“High-precisionlocal- no.2,pp.91–110,Nov2004.
ization using ground texture,” in IEEE International Conference on [12] A. Kelly, “Mobile robot localization from large-scale appearance
RoboticsandAutomation(ICRA),May2019. mosaics,” The International Journal of Robotics Research, vol. 19,
[2] A.Kelly,B.Nagy,D.Stager,andR.Unnikrishnan,“Fieldandservice no.11,pp.1104–1125,2000.
applications - an infrastructure-free automated guided vehicle based [13] H. Fang, M. Yang, and R. Yang, “Ground texture matching based
on computer vision - an effort to make an industrial robot vehicle global localization for intelligent vehicles in urban environment,” in
thatcanoperatewithoutsupportinginfrastructure,”IEEERoboticsand IEEEIntelligentVehiclesSymposium(IV),June2007,pp.105–110.
AutomationMagazine(RAM),vol.14,no.3,pp.24–34,Sept2007. [14] I.Nagai,“Mobilerobotwithﬂoortrackingdeviceforlocalizationand
[3] H. Fang, M. Yang, R. Yang, and C. Wang, “Ground-texture-based control,” Journal of Mechatronics and Robotics (JMR), vol. 19, pp.
localizationforintelligentvehicles,”IEEETransactionsonIntelligent 34–41,2007.
TransportationSystems(ITS),vol.10,no.3,pp.463–468,Sept2009. [15] E.Rublee,V.Rabaud,K.Konolige,andG.Bradski,“ORB:Anefﬁ-
[4] I.NagaiandK.Watanabe,“Pathtrackingbyamobilerobotequipped cientalternativetoSIFTorSURF,”inIEEEInternationalConference
with only a downward facing camera,” in IEEE/RSJ International onComputerVision(ICCV),Nov2011,pp.2564–2571.
ConferenceonIntelligentRobotsandSystems(IROS),Sept2015,pp. [16] M.Agrawal,K.Konolige,andM.R.Blas,“CenSurE:Centersurround
6053–6058. extremasforrealtimefeaturedetectionandmatching,”inIEEEEuro-
[5] K. C. Kozak and M. Alban, “Ranger: A ground-facing camera- pean Conference on Computer Vision (ECCV). Berlin, Heidelberg:
basedlocalizationsystemforgroundvehicles,”inIEEE/IONPosition, SpringerBerlinHeidelberg,2008,pp.102–115.
LocationandNavigationSymposium(PLANS),April2016,pp.170– [17] G. Bradski, “The OpenCV library,” Dr. Dobb’s Journal of Software
178. Tools,2000.
[6] X.Chen,A.S.Vempati,andP.Beardsley,“StreetMap-mappingand [18] J. L. Blanco and P. K. Rai, “nanoﬂann: a C++ header-only fork of
localization on ground planes using a downward facing camera,” in FLANN, a library for nearest neighbor (NN) with KD-trees,” https:
IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems //github.com/jlblancoc/nanoﬂann,2014.
(IROS),Oct2018,pp.1672–1679. [19] M.MujaandD.G.Lowe,“Fastapproximatenearestneighborswith
[7] G. Levi and T. Hassner, “LATCH: Learned arrangements of three automatic algorithm conﬁguration,” in International Conference on
patchcodes,”inIEEEWinterConferenceonApplicationsofComputer ComputerVisionTheoryandApplication(VISSAPP). INSTICCPress,
Vision(WACV),2016,pp.1–9. 2009,pp.331–340.
[8] W.K.Pratt,Digitalimageprocessing:PIKSScientiﬁcinside. Wiley- [20] P.F.Alcantarilla,J.Nuevo,andA.Bartoli,“Fastexplicitdiffusionfor
interscienceHoboken,NewJersey,2007,vol.4. acceleratedfeaturesinnonlinearscalespaces,”inProceedingsofthe
[9] D.Galvez-Lo´pezandJ.D.Tardos,“Bagsofbinarywordsforfastplace BritishMachineVisionConference(BMVC),2013.
recognition in image sequences,” IEEE Transactions on Robotics, [21] J.F.Schmid,S.F.Simon,andR.Mester,“Featuresforgroundtexture
vol.28,no.5,pp.1188–1197,Oct2012. basedlocalization-asurvey,”inProceedingsoftheBritishMachine
[10] H. Bay, T. Tuytelaars, and L. Van Gool, “SURF: Speeded up robust VisionConference(BMVC),2019.
features,”inIEEEEuropeanConferenceonComputerVision(ECCV).
Berlin,Heidelberg:SpringerBerlinHeidelberg,2006,pp.404–417.
1321
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 05:57:54 UTC from IEEE Xplore.  Restrictions apply. 