2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Robust Sound Source Localization considering Similarity of
Back-Propagation Signals
Inkyu An1, Byeongho Jo2, Youngsun Kwon1, Jung-woo Choi2, and Sung-eui Yoon1
http://sgvr.kaist.ac.kr/~ikan/papers/SSL-BPS/
Abstract—We present a novel, robust sound source local- [Separation signal 2]
ization algorithm considering back-propagation signals. Sound Acoustic ray 
propagation paths are estimated by generating direct and Back-propagation  path:    
reﬂection acoustic rays based on ray tracing in a backward signal 2
manner. We then compute the back-propagation signals by Microphone 
designing and using the impulse response of the backward array
sound propagation based on the acoustic ray paths. For iden- Ground
tifyingthe3Dsourceposition,weuseawell-establishedMonte truth
Estimated 
Carlolocalizationmethod.Candidatesforasourcepositionare position
determined by identifying convergence regions of acoustic ray
Acoustic ray 
paths.Thosecandidatesarevalidatedbymeasuringsimilarities
Back-propagation  path:    
between back-propagation signals, under the assumption that
signal 1
the back-propagation signals of different acoustic ray paths
[Separation signal 1]
shouldbesimilarneartheground-truthsoundsourceposition.
Thanks to considering similarities of back-propagation signals,
our approach can localize a source position with an averaged Fig. 1. Our approach generates direct and indirect acoustic ray paths
errorof0.55minaroomof7mby7mareawith3mheightin andlocalizesthesoundsourcewhileconsideringback-propagationsignals
testedenvironments.Wealsoplaceadditional67dBand77dB ongeneratedacousticraypaths.Theback-propagationsignalsarevirtually
computedsignalsthatcouldbeheardatparticularlocationsandcomputed
white noise at the background, to test the robustness of our
byusingimpulseresponses.Whentwoback-propagationsignalsofacoustic
approach. Overall, we observe a 7 % to 100 % improvement
raypathsarehighlycorrelated,wetreatthemtobeoriginatedfromthesame
in accuracy over the state-of-the-art method.
source.
I. INTRODUCTION
cal microphone arrays. Rafaely [7] presented a theoretical
Asrobotsbecomemorewidelyavailable,itisgettingmore
framework of spherical harmonic array processing, and the
imperative for a robot to understand environments for safe
delay-and-sum beamformer is extended to process on the
and accurate operations. There have been many kinds of
spherical harmonics domain. Many advanced beamform-
research efforts to perceive the environments by acquiring
ing techniques [8], [9], [10] were proposed by using the
and using data from hardware sensors. One of the main
minimum variance distortionless response (MVDR) power
research topics for understanding the environments focuses
spectraonthesphericalharmonicsdomain.Lietal.[11]pre-
on identifying locations of a robot itself and other objects
sentedaMUSIC(MultipleSignalClassiﬁcation)basedDOA
in environments from collected data by vision cameras and
estimation algorithm, which uses orthogonality between a
depth sensors. Departing from these approaches, an acoustic
noise-only subspace and a signal-plus-noise subspace on the
data measured by acoustic sensors has recently attracted
spherical harmonics domain.
attention as an important clue for localizing various objects.
Unfortunately, these methods were designed for detecting
The problem identifying the location of a sound source
DOA, not the 3D location of a sound source in an arbitrary
from collected acoustic data is widely known as the sound
environment. Especially, when a sound source is occluded
source localization (SSL). There has been a signiﬁcant
by an obstacle, most prior approaches cannot specify the
amount of efforts to localize a sound source by estimating
location of the source generating the sound signal.
direction of arrival (DOA) of sound waves. There have been
To address this issue, recent techniques were proposed to
fundamental methods for estimating DOA based on time
ﬁnd a 3D source location even if the sound source is in the
difference of arrival (TDOA) of a microphone array [1],
non-line-of-sight state [12], [13]. These techniques estimate
[2], [3], and the beamforming algorithms are widely used
sound propagation paths from the source to microphones as
to enhance desired signals at the speciﬁc directions from the
acoustic rays, generated by the ray tracing technique, and
sound source [4], [5], [6].
identify the 3D source location by using generated acoustic
Thanks to the advantage of the spherical conﬁguration,
rays. However, the accuracy of these methods decreases
many DOA estimation methods focus on using the spheri-
in environments with background noise and imperfect re-
1I. An, 1Y. Kwon, and 1S. Yoon (Corresponding author) are construction of the 3D environments. This low accuracy is
with the School of Computing, KAIST, Daejeon, South Korea; caused mainly because several errors, like background noise
3B. Jo and 3J. Choi is with the School of Electrical Engi-
{ andimperfect3Dreconstruction,areaccumulatedalongeach
neering, KAIST; inkyu.an, byeongho, youngsun.kwon,
}
jwoo @kaist.ac.kr, sungeui@kaist.edu acoustic ray for estimating the source location.
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1574
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. Main Contributions. To robustly identify the sound source apply the spherical Fourier transform (SFT) to the array
location, we present a novel, sound source localization signal x [7], which yields the spherical harmonic (SH)
algorithm using back-propagation signals (Fig. 1). Using a coefﬁcients x deﬁned over different orders ν and degrees
νµ
beamformingalgorithm,weﬁrstcomputeDOAofthesound µ of spherical harmonics. For the SH coefﬁcients measured
(cid:48) (cid:48)
wave and separation signals corresponding to those speciﬁc up to the order ν =ν , there are (ν +1)2 coefﬁcients in
DOAs(Sec.II-A).Wethenestimatesoundpropagationpaths total. Since the SFT is a linear operation, we also have the
by generating acoustic ray paths in the reverse direction following relation:
to DOAs of the sound (Sec. II-B), and compute the back-
propagationsignalsusingtheimpulseresponseoftheacous- xνµ =pνµ+nνµ, (2)
ticraypathfromtheseparationsignal(Sec.II-C).Intuitively Our objective is to identify DOAs and extract the sound
speaking, back-propagation signals are virtually computed signal coming from each DOA. The beamformer does this
signalsthatcouldbeheardataparticularlocationonacoustic by multiplying a beamformer weight vector wνµ(Ω) deﬁned
paths from the measured signals at the microphone array. for a speciﬁc pair of zenith and azimuth angle Ω=(θ,φ)
Finally, we use the Monte Carlo localization algorithm to the measured signal x . The output of the beamformer
νµ
estimating a location of the sound as a converging region S, therefore, can be written as the inner product of wνµ(Ω)
of computed acoustic ray paths. In particular, we utilize the and x :
νµ
computed back-propagation signals of different acoustic ray S(Ω)=wνµ(Ω)Hxνµ, (3)
paths for robust estimation of the sound location, under the
·
intuitive assumption that acoustic paths coming from the where ()H is the Hermitian transpose. Among many beam-
same sound source should have similar back-propagation formers, we adopt the EB-MVDR that is known to provide
signals at the estimated location (Sec. II-D). a good spatial resolution and signal separation performance.
With the EB-MVDR beamformer, DOAs are estimated from
II. SOUNDSOURCELOCALIZATIONUSING the beamforming power deﬁned as:
BACK-PROPAGATEDSIGNALS
1
locOaluirzawtioonrk(iSsSLbu)il[t1u3p].onInraay rteraaclinegn-vbiarosendmesnotunidnvsoolvuirncge βMV(Ω)= vνµ(Ω)HR−xν1µxνµvνµ(Ω), (4)
moving sound sources, obstacles, or noise, acoustic rays whereR isthecovariancematrixofwhichelementsare
xνµxνµ
generated naively by the prior ray tracing based SSL may cross-spectraldensitiesofmeasuredsignalsxνµ,andvνµ(Ω)
converge to a position other than the actual location of the denotes a steering vector given by the wave propagation
sound source. model. In this work, we use the plane wave model to deﬁne
To solve this problem, we aim to generate and utilize thesteeringvectorv .Fig.2showsthebeamformingpower
νµ
back-propagation signals to a candidate 3D location along calculatedforeverydirectionΩ;alldirectionscorrespondto
eachacousticray.Thisback-propagationsignalsatalocation 10242 grids on the unit sphere that is based on the recursive
can be computed by simulating the reverse process of sound subdivision of an icosahedron [14].
propagation, i.e., by reversely performing ray tracing. Local maxima of the beamforming power can represent
the direct and indirect DOAs of the propagation paths. That
A. Beamforming
is
··· { }
To generate acoustic rays, we estimate DOAs of the [d1,d2, ,dN]=Fmax βMV(Ω) , (5)
sound waves at the spherical microphone array using a
EB-MVDR(Eigenbeam-minimumvariancedistortionlessre- where dn =(cosφnsinθn,sinφnsinθn,cosθn) denotes a di-
sponse)beamformer[8],[9],[10].Notethatourinputsignals rectional vector of the n-th local maximum of the beam-
are measured by almost uniformly sampled microphones forming power among N different local maxima in a frame,
{·}
on a rigid sphere (32 channel microphone positions), but and Fmax is a function for ﬁnding local maxima of the
each microphone signal is, in fact, a mixture of signals beamenergyfunction.Inpractice,weidentifytop-fourlocal
fromdifferentdirections.Wethereforeaimtoextractsignals maxima on average in our tested experiments.
from different DOAs, and for this purpose, the EB-MVDR We then extract sound signals, called the separated signal
beamformer is utilized. Sn, coming from a speciﬁc direction Ωn with the directional
The array signal, x=[x1(k),···,xQ(k)]T, measured by vector dn. The beamformer weight wνµ(Ωn) of the EB-
Q microphones of the spherical array consists of sound MVDR beamformer is given by:
···
pnr=ess[nu1re(ks)i,g·n··a,lsnQp(k=)]T[p:1(k), ,pQ(k)]T and noise signals, wνµ(Ωn)= vνµ(vΩνnµ)(HΩRn)−xνH1µRxν−xµν1vµxννµµ(Ωn), (6)
x=p+n, (1) (cid:0) (cid:1)
which minimizes the total beamforming power while sat-
where k = 2πf/c is the wavenumber determined by the isfying the distortionless-response constraint to the looking
frequency f and speed of sound c. Note that the measured direction Ωn wνµ(Ωn)Hvνµ(Ωn)=1 . This beamformer
sound signal p is the consequence of sound propagation and weight is used in Eq. 3 for computing four separated signals
reﬂections through a direct or indirect propagation path. We S .
n
1575
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. Normalized beamforming power               (dB) Max 
(0dB)
180
: Back-propagation
160
signal
140
120 Triangle 1
Zenith (degree)1860000 Triangle d
40
20 : Separation 
0 0Direct5i0on 1 100 A15z0imuth (d2e0g0ree) 250 300 350(-2M0 idnB ) signal Origin of 
Pressure(Pa) Pressure(Pa)DiPressurere(Pa)ctDioinr e2ScTteiimpoena ( rm3ailtliisoTecinmo nesd (i)mginlliaselcsondT)ime (millisecond) FpRriogp.isa3gg.aetnieoArnantseiegdxnataoml.tphTleehedoipfrregicmetinaoernyravatiecntcohgtuoesar tnmidcairccatohryo,uartspn0tihi,scoothfrnaeteyh reaeprvnare-tathrhsyeRacndoirauensctdtiicoitrnsayobfpactahkthe-
n n
n-thincomingsound.Whentheacousticrayr0hitsanobstaclerepresented
n
Fig.2. Abeamformingpoweriscomputedbyabeamformingalgorithm, by Triangle 1, its reﬂection acoustic ray rn1 is generated according to the
where the horizontal axis is the azimuth angle and the vertical axis is the specularreﬂectionbasedonthenormalvectorn1 ofTriangle1.Theback-
zenithangleoftheunitsphere.Localmaximaofthebeamformingpowerare propagationsignalPn iscomputedbyusingtheimpulseresponseofRn at
treated most signiﬁcant directions of arrival (DOAs) of sound. The sound aspeciﬁcpoint,Πn,onthepathfromtheseparatedsignalSn.
signalimpingingfromeachDOAisextractedbyapplyingtheEB-MVDR
beamformertothesignalsmeasuredbymicrophones. (Rn,Sn) for the reverse direction vector dn of the n-th
incoming sound. We want to compute the back-propagation
The separated signals are then back-propagated to the
signalP fromtheseparatedsignalS bydesigningandusing
directions d by reconstructing acoustic rays to the true n n
n an impulse response of backward sound propagation based
source positions.
on the acoustic ray path R . The impulse response describes
n
B. Acoustic ray tracing the reaction of any linear system as a function of time-
independent variables; the input is the separated signal and
We explain how to generate acoustic rays from estimated
directions [d1,d2,···,dN] that are the reverse directions of the output is the back-propagation signal in our approach.
In this work, we utilize the impulse response for the
incoming sounds. We want to estimate propagated paths
backward propagation to improve the accuracy of the sound
(e.g.,directandreﬂectionpaths)ofthesoundfromitssource
sourcelocalization.Inforwardsoundpropagations[16],[17],
location to the microphone array location using the acoustic
[18], [19], the impulse response of an acoustic ray path
rays. We generate such acoustic rays considering direct and
is described by sound attenuations according to the travel
reﬂection paths based on the RA-SSL algorithm [13].
distance of a ray path and reﬂection. For example, the
Unlike the prior work of RA-SSL, we use a mesh rep-
travel distance attenuation represents the decrease of sound
resentation of the surroundings captured from sensors. We
pressure inversely proportional to the travel distance of the
construct the mesh that is robust to minor noise, and use
ray path, because the sound is propagated according to the
it for acoustic interactions between the surroundings and
sphericalwavein3Denvironments;similarforthereﬂection
generated acoustic rays. Starting from the point cloud
attenuation.
collected by the depth sensor, i.e., Velodyne VLP-16, we
Ontheotherhand,forthebackwardpropagationproblem,
apply the voxelization in order to reduce the sensor noise,
the attenuation of travel distance and reﬂection becomes an
and then reconstruct the environment in the form of a mesh
ampliﬁcation of the sound pressure. Suppose that we aim
mapfromthevoxelizedpointcloudusingthePoissonsurface
to compute the back-propagation signal from the starting
reconstruction algorithm [15].
point to a speciﬁc point, Π (Fig. 3), on an acoustic ray
For the n-th acoustic ray path, denoted by R , its primary n
n
acoustic ray, r0, is created into the n-th direction vector path using the backward impulse response, where there is
n
dn, as shown in Fig. 3. If the acoustic ray collides with the n-th tuple (Rn,Sn) a··n·d the−acoustic ray path Rn consists
an obstacle, its secondary, reﬂection ray is generated by of D acoustic rays [rn0, ,rnD≤1];≤rn0 is−a primary ray and rnd
assumingthespecularreﬂection,andisdenotedbyr1,where is the d-th reﬂection ray (1 d D 1). In the frequency
the superscript represents the order of the acoustic rnay path; domain, the backward impulse response, HnΠn, is described
referto[13]forthedetailedprocessonraygeneration.When by ampliﬁcations becau(cid:18)se of(cid:19)the travel distance l and the
− reﬂection until the d-th order reﬂection ray rd:
Rn is propagated until a (D 1)-th order, it indicates that n
tRhne=ac[ron0u,srtn1ic,··r·ay,rnDp−at1h].Rn consists of D acoustic rays: i.e., HnΠn[k]=exp ikcl ·AT[l]·AR[Rn,d,k], (7)
C. Back-propagation signals
where the term inside the exponential function is for shift-
We introduce how to compute back-propagation signals ing the back-propagation signal to the time delay of the
···
based on the generated acoust·i·c· ray paths [R1,R2, ,RN] sound propagation at the speciﬁc point Πn and i is the
and separated signals [S1,S2, ,SN]; there is a tuple of imaginary unit. AT is a coefﬁcient of the travel distance
1576
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. differentiation of our approach over the prior technique is
thatourmethodimprovesthelocalizationaccuracybasedon
a novel module for computing weights of particles based on
our back-propagation signals.
Supposetherearei-thparticles,xi,representinghypothet-
j
ical locations of the sound source at a j frame. We compute
how close the particle is to acoustic ray paths. For this, we
deﬁne a speciﬁc point Πi, which is decided to be the point
n
satisfying the shortest distance between xi and any point
j || − ||
on the n-th acoustic ray path; i.e., Πin=argminπd xij πid ,
i
Fig. 4. Examples of determining the point of the acoustic ray path whereπid istheperpendicularfootonthed-thorderacoustic
for computing the back-propagation signal. For the particle of x2, the rayfromthexi position(Fig.4).Wethencomputeourback-
j j
perpendicularfootsπ2d onalld-thorderacousticraysofthen-thacoustic propagation signal according to Eq. 7 at the shortest point
raypatharecomputed.Wethendecidetherepresentativeperpendicularfoot
Πi on the n-th acoustic ray path from the particle xi.
Π2n satisfyingtheshortestdistancefromx2j toRn. n j
Πi
From the back-propagation signal Pn n[k] in the frequency
ampliﬁcation, and is deﬁned by a function of the travel Πi
domain, we compute the back-propagation signal pnn[t] in
distance l: AT[l]=4π(1+l). Also, AR is a coefﬁcient of the time domain signal. We then calculate a particle weight,
the reﬂection ampliﬁcation, and i(cid:20)s deﬁn(cid:21)ed by considering wi, representing the probability of being a convergence
j
specular reﬂections until the d-th order reﬂection ray:
region of the sound source, based on two factors: a distance
AR[Rn,d,k]=δ∏=d1 Γδ1[k] , (8) wnh-oetwhigahscitm,ouwilsdatri,crbereaptywreepseeannthtipnaΠnngind[hta]owasnimdawiolaatrhyietytrhsweigepniagarhltsitc,glweivsi,esninfadrocicomautsittnhigce
where Γ denotes the reﬂectivity (reﬂection coefﬁcient) of
δ − ray paths:
the triangle hit by the (δ 1)-th order ray; the reﬂection
ccooeeffﬁﬁcciieenntt visalauefsunrecptioorntedofbwya[v2e0n].umber k and we refer to wij=P(Oj|xij)= n1 ∑Nj [wd(xij,Rn)·ws(xij,Rn)], (10)
The back-propagation signal PnΠn at the speciﬁc point Πn where N is the numbcenr=1of acoustic ray paths at the j
ontheacousticraypathR isﬁnallycomputedbytheproduct j
osifgnthael Sbnacinkwthaerdfriemqupeunlsceyn rdeosmpoaninse: HnΠn and the separated f[Rra1m,·e·,·O,RjNijs],tahnedonbcseirsvaatinoonrmcoanlitzaiinngincgo[nPs1Πtai1n,t·.··,PNΠjiNj] and
PnΠn[k]=Sn[k]·HnΠn[k]. (9) cliTdehaenddiissttaanncceebweetwigehetnwthdeipsarctiacllceullaotceadtiobnyxiusainndgththeepoEiun-t
j
D. Estimating a source position Πi:
n || − |||
Our estimation process of localizing the sound source is wd(xij,Rn)=G( xij Πin 0,σw), (11)
based on the Monte Carlo (MC) localization method. The
where G is the Gaussian distribution function with the zero
MC sound source localization identifying the convergence
mean and a standard deviation σ . w is maximized when
region of acoustic ray paths was suggested in the prior work w d
theparticlexi isontheperpendicularfootΠi.Thesimilarity
(RA-SSL)[13];theconvergenceregionmeanstheareawhere j n
acoustic ray paths gather. weight ws(xij,Rn) measures the similarity between the back-
Πi
However, the accuracy of MC localization can decrease propagation sig(cid:40)nal p n from the n-th acoustic ray path and
n
in real environments. When there are background noises of ones of other acoustic ray paths:
sound or complex scene conﬁgurations causing uncertainty − − ·
of the reconstructed environment, they can trigger to gen- 1 ∑Nj L (1 αL)lcc(n,m), if acc(n,m)>ath (12)
erate many arbitrary or incoherent acoustic ray paths. By nsm=1,m(cid:54)=n 0, otherwise,
considering back-propagation signals, we aim to identify
where n is the normalizing constant, L is the length of the
those arbitrary and incoherent acoustic ray paths and cull s ·
away acoustic ray paths with different back-propagation back-propagation sign−al, acc() is ·the peak coefﬁcient in a
normalized range of 1 to 1, lcc() is the peak coefﬁcient
signalsindicatingthattheyarefromdifferentsoundsources.
delay, α denotes a parameter for adjusting the similarity
Intuitively speaking, if there are two acoustic ray paths ·
caused by the same source, their back-propagation signals weight, and ath d·enotes the· threshold value of acc(). Both
variables of acc() and lcc() are computed by applying the
should be similar near the location of their sound source. In
cross-correlation operation between n-th and m-th signals:
other words, when back-propagation signals of two acoustic
raypathsaredifferentatalocation,thelocationisunlikelyto acc(n,m)=max{(pΠnin(cid:63)pΠmim)[τ]},
(13)
beTahceanMdiCdatleocfaolrizaatcioonnvecrognisnigstsregoifonthorefethpeasrotsu:ndsasmopulricneg., lcc(n,m)=argmaxτ{(pΠnin(cid:63)pΠmim)[τ]},
computing a weight of particles, and resampling. The main where (cid:63) is the cross-correlation operator.
1577
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. Microphone
array
Sound  Trajectory
Back-propagation signal Back-propagation signal source Goal
e e
Pressur (Pa) Pressur (Pa) Starting point White noise
Time (millisecond) Time (millisecond)
Cross-correlation operation
(a)Theenvironmentwithouttheobstacle.
nt Microphone
e
oeffici Invisible area Obstacle Goal array
C 0 Delay (  )
Sound 
Fig. 5. An example of computing the peak coefﬁcient a and the peak
cc source
coefﬁcient delay lcc by using the cross-correlation operation. Given two Trajectory
back-propagation signals, pΠnin and pΠmim at Πin and Πim, respectively, we Starting  White noise
performthecross-correlationoperationbetweentwosignals.Themaximum
point
coefﬁcientbecomesthepeakcoefﬁcienta andthetimedelayfromthetime
cc
origin,0,tothetimerealizingthemaximumcoefﬁcientbecomesthepeak (b)Theenvironmentwiththeobstacle.
coefﬁcientdelayl .
cc
Fig.6. Thetestenvironmentsw/andw/oanobstaclethatcanmakethe
· soundsourcenon-line-of-sightone.Weusetheclappingsoundinthesound
As shown in Fig. 5, acc() represents how much both source.Weputanadditionalnoise(67dBand77dBwhitenoises)asthe
back-propagation signals are correlated, and l shows the distractorinthethebackofthetestenvironments.
cc
timedifferenceofoccurrencebetweenbothback-propagation
signals. As both back-propagation singles are from the same forcomputingthedistanceweightis0.5thatisdeterminedby
sound source, ideally acc and lcc become one and zero, theconsiderationofthesizeoftheindoorenvironment(about
respectively. one-tenth of the room width 7m), and the threshold value
GettingbacktoEq.12,wetreatthattwoback-propagation a for checking the correlation between back-propagation
th
signalsaresimilar,whentheirpeakcoefﬁcientisbiggerthan signals is 0.15.
the threshold, i.e., acc>ath. In this case, we assign a higher We use 1024 samples for the separation signal, where
weight according to the relative time delay of the length of the sampling frequency is 12 kHz; 1024 audio samples
− − ·
the signal, (L (1 α)lcc) that becomes a value in a range of (85 ms) are a sufﬁcient length for covering direct and ﬁrst-
L
α to1;i.e.,wegivethehighestweightwhentwosignalsare bounce reﬂection signals as indicated in [21]. We set our
matched without any delay, under the assumption that those algorithm to estimate the source position every 256 ms in
two signals are originated from the same sound source. If ordertorespondappropriatelytothemovementofthesource.
there is no back-propagation signal satisfying the condition, Speciﬁcally, beamforming and generating acoustic rays take
acc>ath,thesignalsimilarityweig−ht−ws·hasaconstantvalue 50ms and 0.54ms respectively on average, which are less
α that is the smallest value of (L (1 α)lcc). than the audio length (85ms), and estimating the source
L
position based on the particle ﬁlter takes 200 ms on an
III. RESULTSANDDISCUSSION average that is less than the iteration period 256 ms.
The yellow disk in Fig. 1 represents a 95% conﬁdence
A. Benchmarks
area for the sound source location estimated by our method.
We also compare distance errors of our approach to the Different experiments were conducted in two scenes: the
prior work (RA-SSL) that does not use the similarity of movingsoundwithoutandwithanobstacle.Inbothenviron-
back-propagationsignals,todemonstratetheeffectivenessof ments (Fig. 6a and Fig. 6b), a robot equipped with an omni-
considering the back-propagation signals. directional speaker moved along the red trajectory, and the
The hardware platform consists of Eigenmike, the 32- 32-channelmicrophonearrayrecordedtheaudiosignals,and
channel microphone array of the mh acoustics, and the i7 these data are used for various tests with the ground truth
CPUcomputer.AsmentionedinSec.II-B,weuseVelodyne informationonthesoundsourcelocations.InFig.6b,weput
VLP-16 and build a mesh map as the reconstruction of anobstaclemadebypaperboxes,tocausetherobotinvisible
tested indoor environments. The reﬂection coefﬁcients are along the robot’s trajectory for the microphone array; at the
appropriately assigned to the triangles by referring to the invisible area, the sound source becomes the non-line-of-
reported values in [20]. sight (NLOS) source.
We report values of parameters used for our algorithm: α Handling the NLOS source was reported a quite difﬁcult
for controlling the inﬂuence of each weight is 0.5, the stan- problem in prior methods [13], because direct sound propa-
dard deviation σ of the Gaussian distribution function used gationpathsareblockedbytheobstacleandwehavetorely
w
1578
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. TABLEI 4 : Reflection-Aware SSL (77dB noise)
THEAVERAGEDISTANCEERRORSW/DIFFERENTNOISELEVELS. : Our approach  (77dB noise)
m)3
NUMBERSINTHEPARENTHESESSHOWTHEIMPROVEMENT. or (
Anmovingsource w/owhite 67dBwhite 77dBwhite err2
w/oanobstacle noise noise noise e 
c
SNR 20.64dB 15.74dB 9.35dB an
Ourapproach 0.57m(7%) 0.58m(18%) 0.56m(38%) Dist1
RA-SSL 0.61m 0.69m 0.78m
0
Anmovingsource w/o 67dB 77dB 0 50 100 150 200 250
w/anobstacle whitenoise whitenoise whitenoise Time (second)
SNR 20.83dB 17.33dB 9.65dB
(a)Accuracyofmovingsoundw/otheobstaclecontaininga77dB
Ourapproach 0.51m(64%) 0.54m(75%) 0.53m(100%)
whitenoise(Fig.6a).
RA-SSL 0.84m 0.95m 1.08m
3
m)
on indirect sound paths that are incoherent and sensitive to or (2
err
noise.Furthermore,thenumberofindirectacousticraypaths ce 1
n
pacacsusirnagcyneoafrththeelogcroaluinzadtitornuthalgisoruitshumallytensdmsaltlo, danetdertihourasteth.e Dista0
0 50 100 150 200 250
Additionally, these scenes are not free from noise (e.g., Time (second)
various noise from outside the room and moving sound of (b)Accuracyofmovingsoundw/theobstaclecontaininga77dB
whitenoise(Fig.6b).
the tested sound source), naturally occurring in a typical
environment where the signal-to-noise ratios (SNRs) of both Fig. 7. The distance errors between the ground truth and the estimated
source positions. In this scene, there is the additional 77 dB white noise,
scenes containing the moving sound without and with an
ontopofnaturaloccurringnoise.
obstacle are 20.64 dB and 20.83 dB. To further test the
robustness of the proposed method, we expose these scenes
and 0.5364 m, respectively. Especially, where the sound
additional white noise, whose average sound pressure levels
source is in the NLOS state from 90 to 180 seconds, the
are67dBand77dB.Thesenoisescancausetotriggermany
accuracy of RA-SSL decreases drastically, because blocking
incoherent acoustic ray paths, hindering them to converge in
the direct sound propagation paths makes the convergence
a single location.
of acoustic rays weak near the ground truth. On the other
B. A moving sound source hand, even in this challenging case, we get a stable result,
100% improvement compared to RA-SSL, by considering
We ﬁrst show how our approach has the advantage com-
the similarity between back-propagation signals of indirect
pared to the prior method in a simple scene with a moving
acoustic paths.
sound. In Table I, the accuracy of RA-SSL in the moving
As we have stronger white noise (Table I), SNRs in the
source scene gradually deteriorates, as the power of noises
moving source scene w/ the obstacle decrease, which are
increase,wheretheSNRscontaining67dBand77dBnoises
20.83 dB, 17.33 dB, and 9.65 dB, and the accuracy of RA-
are 15.74 dB and 9.35 dB, respectively. On the other hand,
SSL then dramatically deteriorates. However, the accuracy
theaccuracyofourworkisratherrobustwithdifferentpower
of our approach is stable even with different noise energy,
of noise. This shows that our method is robust even in noisy
demonstratingtherobustnessandusefulnessofourapproach.
environments, thanks to considering the back-propagation
signals on estimated source locations; the similarity weight
improvestherobustnessofthesourcelocalizationalgorithm. IV. LIMITATIONSANDFUTUREDIRECTIONS
To show the positive effect of back-propagation signals on
While we have demonstrated beneﬁts of our approach, it
the 3D sound source localization, we append a description
has several limitations and opens up many interesting future
on coherence among back-propagation signals compared to
directions.Whenthewhitenoiseislargerthan87dB(sound
separation signals on the video submission.
level like a truck noise [22]), we found that our approach
Fig. 7a shows the distance errors of RA-SSL and our
did not work properly because of the relatively weak energy
approach, where there is 77 dB white noise. The average
of the sound source (77.34 dB). Other sound propagation
distance errors are 0.7839 m for RA-SSL and 0.5678 m for
phenomena such as scattering and diffraction that are fre-
our approach; the accuracy of the sound source localization
quentlyobservedatlowfrequenciesarenothandledyet.The
is improved about 38% based on our approach.
acoustic material properties such as reﬂection coefﬁcients of
trianglesofobjectsarenotautomaticallyassigned,andrecent
C. A moving sound around an obstacle
deep learning approaches showing promising results can be
We now show results with the more challenging environ- employed to solve this problem [20].
mentincludinganobstaclebetweenthesourcetrajectoryand
the microphone array (Fig. 6b). Fig. 7b shows graphs of the ACKNOWLEDGMENT
distance errors of RA-SSL and our approach with the 77 dB This research was supported by the SW StartLab program
white noise; SNR in this scene is 9.65 dB. The average (IITP-2015-0-00199), NRF grant funded by MSIT (No.
distance errors of RA-SSL and our approach are 1.083 m 2019R1A2C3002833), and MOTIE (No.10067202).
1579
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [21] Jingdong Chen and Jacob Benesty, “A time-domain widely linear
mvdr ﬁlter for binaural noise reduction”, in Applications of Signal
[1] C. Knapp and G. Carter, “The generalized correlation method for ProcessingtoAudioandAcoustics(WASPAA),2011IEEEWorkshop
estimation of time delay”, IEEE Trans. Acoust., Speech, Signal on.IEEE,2011,pp.105–108.
Process.,vol.24,no.4,pp.320–327. [22] Yang-HannKimandJung-WooChoi,Soundvisualizationandmanip-
[2] J-M Valin, Franc¸ois Michaud, Jean Rouat, and Dominic Le´tourneau, ulation, JohnWiley&Sons,2013.
“Robustsoundsourcelocalizationusingamicrophonearrayonamo-
bilerobot”, inProceedings2003IEEE/RSJInternationalConference
onIntelligentRobotsandSystems(IROS2003)(Cat.No.03CH37453).
IEEE,2003,vol.2,pp.1228–1233.
[3] Charles Blandin, Alexey Ozerov, and Emmanuel Vincent, “Multi-
sourcetdoaestimationinreverberantaudiousingangularspectraand
clustering”, SignalProcessing,vol.92,no.8,pp.1950–1960,2012.
[4] J-M Valin, Franc¸ois Michaud, Brahim Hadjou, and Jean Rouat,
“Localization of simultaneous moving sound sources for mobile
robot using a frequency-domain steered beamformer approach”, in
IEEE International Conference on Robotics and Automation, 2004.
Proceedings.ICRA’04.2004.IEEE,2004,vol.1,pp.1033–1038.
[5] J.-M. Valin, F. Michaud, and J. Rouat, “Robust localization and
tracking of simultaneous moving sound sources using beamforming
andparticleﬁltering”, Robot.Auton.Syst.,vol.55,no.3.
[6] Cha Zhang, Dinei Floreˆncio, Demba E Ba, and Zhengyou Zhang,
“Maximum likelihood sound source localization and beamforming
for directional microphone arrays in distributed meetings”, IEEE
TransactionsonMultimedia,vol.10,no.3,pp.538–548,2008.
[7] Boaz Rafaely, Fundamentals of spherical array processing, vol. 8,
Springer,2015.
[8] HaohaiSun,EdwinMabande,KonradKowalczyk,andWalterKeller-
mann, “Jointdoaandtdoaestimationfor3dlocalizationofreﬂective
surfacesusingeigenbeammvdrandsphericalmicrophonearrays”, in
2011IEEEInternationalConferenceonAcoustics,SpeechandSignal
Processing(ICASSP).IEEE,2011,pp.113–116.
[9] DanielPJarrett,Emanue¨lAPHabets,andPatrickANaylor,“Spherical
harmonicdomainnoisereductionusinganmvdrbeamformeranddoa-
basedsecond-orderstatisticsestimation”, in2013IEEEInternational
ConferenceonAcoustics,SpeechandSignalProcessing.IEEE,2013,
pp.654–658.
[10] Shefeng Yan, Haohai Sun, U Peter Svensson, Xiaochuan Ma, and
Jens M Hovem, “Optimal modal beamforming for spherical micro-
phone arrays”, IEEE Transactions on Audio, Speech, and Language
Processing,vol.19,no.2,pp.361–371,2011.
[11] XuanLi,ShefengYan,XiaochuanMa,andChaohuanHou,“Spherical
harmonicsmusicversusconventionalmusic”, AppliedAcoustics,vol.
72,no.9,pp.646–652,2011.
[12] I. An, D. Lee, J. Choi, D. Manocha, and S. Yoon, “Diffraction-
aware sound localization for a non-line-of-sight source”, in 2019
International Conference on Robotics and Automation (ICRA), May
2019,pp.4061–4067.
[13] I. An, M. Son, D. Manocha, and S. Yoon, “Reﬂection-aware sound
source localization”, in 2018 IEEE International Conference on
RoboticsandAutomation(ICRA),May2018,pp.66–73.
[14] F. Gyorgy, “Rendering and managing spherical data with sphere
quadtrees”, in Proceedings of the First IEEE Conference on Visu-
alization:Visualization‘90,Oct1990,pp.176–186.
[15] Michael Kazhdan, Matthew Bolitho, and Hugues Hoppe, “Poisson
surface reconstruction”, in Proceedings of the fourth Eurographics
symposiumonGeometryprocessing,2006,vol.7.
[16] ChunxiaoCao,ZhongRen,CarlSchissler,DineshManocha,andKun
Zhou, “Interactivesoundpropagationwithbidirectionalpathtracing”,
ACMTransactionsonGraphics(TOG),vol.35,no.6,pp.180,2016.
[17] DingzeyuLi,TimothyRLanglois,andChangxiZheng,“Scene-aware
audio for 360 videos”, ACM Transactions on Graphics (TOG), vol.
37,no.4,pp.111,2018.
[18] HengchinYeh,RavishMehra,ZhiminRen,LakulishAntani,Dinesh
Manocha, and Ming Lin, “Wave-ray coupling for interactive sound
propagationinlargecomplexscenes”,ACMTransactionsonGraphics
(TOG),vol.32,no.6,pp.165,2013.
[19] Carl Schissler, Ravish Mehra, and Dinesh Manocha, “High-order
diffraction and diffuse reﬂections for interactive sound propagation
in large environments”, ACM Transactions on Graphics (TOG), vol.
33,no.4,pp.39,2014.
[20] Carl Schissler, Christian Loftin, and Dinesh Manocha, “Acoustic
classiﬁcationandoptimizationformulti-modalrenderingofreal-world
scenes”, IEEE transactions on visualization and computer graphics,
vol.24,no.3,pp.1246–1259,2018.
1580
Authorized licensed use limited to: La Trobe University. Downloaded on September 21,2020 at 13:03:46 UTC from IEEE Xplore.  Restrictions apply. 