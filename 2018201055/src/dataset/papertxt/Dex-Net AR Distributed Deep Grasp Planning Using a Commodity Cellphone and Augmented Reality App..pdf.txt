2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Semantic Linking Maps for Active Visual Object Search
∗ ∗
Zhen Zeng Adrian Ro¨fer† Odest Chadwicke Jenkins
Abstract—We aim for mobile robots to function in a variety
of common human environments. Such robots need to be
able to reason about the locations of previously unseen target
objects.Landmarkobjectscanhelpthisreasoningbynarrowing
down the search space signiﬁcantly. More speciﬁcally, we can
exploit background knowledge about common spatial relations
between landmark and target objects. For example, seeing a
table and knowing that cups can often be found on tables aids
the discovery of a cup. Such correlations can be expressed as
distributions over possible pairing relationships of objects. In
this paper, we propose an active visual object search strategy
methodthroughourintroductionoftheSemanticLinkingMaps
(SLiM)model.SLiMsimultaneouslymaintainsthebeliefovera
target object’s location as well as landmark objects’ locations,
whileaccountingforprobabilisticinter-objectspatialrelations.
BasedonSLiM,wedescribeahybridsearchstrategythatselects
thenextbestviewposeforsearchingforthetargetobjectbased
on the maintained belief. We demonstrate the efﬁciency of our
SLiM-based search strategy through comparative experiments
in simulated environments. We further demonstrate the real-
world applicability of SLiM-based search in scenarios with a Fig. 1: Robot tasked to ﬁnd a coffee machine.
Fetch mobile manipulation robot.
I. INTRODUCTION graph. The marginal belief on inter-object spatial relations
inferred from the factor graph is used in SLiM to account
Being able to efﬁciently search for objects in an environ-
for probabilistic spatial relations between objects.
ment is crucial for service robots to autonomously perform
tasks [9], [27], [7]. When asked where a target object can
Using the maintained belief over target and landmark
be found, humans are able to give hypothetical locations
objects’ locations from SLiM, we propose a hybrid strategy
expressed by spatial relations with respect to other objects.
for active object search. We select the next best view pose,
For example, a cup can be found “on a table” or “near a
which guides the robot to explore promising regions that
sink”. Table and sink are considered landmark objects that
may contain the target and/or landmark objects. Previous
areinformativeforsearchingforthetargetobjectcup.Robots
works[30],[6],[25],[2]haveshownthebeneﬁtofpurpose-
shouldbeabletoreasonsimilarlyaboutobjectslocations,as
fully looking for landmark objects (Indirect Search) before
shown in Figure 1.
directly looking for the target object (Direct Search). The
Previous works [10], [13], [26] assume landmark objects
proposed hybrid search strategy draws insights from both
are static, in that they mostly remain where they were
indirect and direct search. We demonstrate the efﬁciency of
last observed. This assumption can be invalid for dynamic
the proposed hybrid search strategy in our experiments.
landmarkobjectsthatchangetheirlocationovertime,suchas
chairs, food carts and toolboxes. Temporal assumptions can
mislead the search process if the prior on the landmarks’ In this paper, we describe the Semantic Linking Maps
locations is too strong. Further, there also exists uncertainty model as a Conditional Random Field (CRF). Our descrip-
in the spatial relations between landmark objects and the tion of SLiM as a CRF allows us to simultaneously maintain
target object, and between landmark objects themselves. For the belief over target and landmark object locations with
example, a cup can be “in” or “next to” a sink. probabilistic modeling over inter-object spatial relations. We
Considering the problem of dynamic landmarks, we pro- also describe a hybrid search strategy based on SLiM that
pose the Semantic Linking Maps (SLiM) model to account draws upon ideas from both indirect and direct search
for uncertainty in the locations of landmark objects during representations. This SLiM-based search makes use of the
object search. Building on Lorbach et al. [18], we model maintainedbeliefoverobjects’locationsbyselectingthenext
inter-object spatial relations probabilistically via a factor best view pose based on the current belief. In our experi-
ments, we show that the proposed object search approach
∗
Z.Zeng,O.C.JenkinsarewiththeDepartmentofElectricalEngineering is more robust to noisy priors on landmark locations by
andComputerScience,RoboticsInstitute,UniversityofMichigan,USA
†A. Ro¨fer is with the Department of Computer Science, University of simultaneouslymaintainingbeliefoverthelocationsoftarget
Bremen,Germany and landmark objects.
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1984
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. II. RELATEDWORK III. PROBLEMSTATEMENT
{ | ··· }
Let O = oi i = 1, ,N be the set of objects of
Existing works have studied object search with differ- interest, including landmark objects and the target ob-
ent assumptions on prior knowledge of the environment. ject for search. Given observations z0:T and robot poses
Some assume priors on landmark objects’ locations in the x0:T, we a|im to maintain the belief over object loca-
environment, and utilize the spatial relations between the tions P(OT x0:T,z0:T), while accounting for th∈e probabilistic
target object and landmark objects to prioritize regions to spatial relations Rij between objects oi,oj O. For thi∈s
search. Kollar et al. [10] utilize object-object co-occurrences w{ork, we consider the set of spatial relations}to be Rij
extracted from image tags on Flickr.com to infer target In, On, Contain, Support, Proximity, Disjoint . For exam-
object locations. Kunze et al. [13] expanded the generic ple, the relation Rij =In indicates that object oi is inside
notion of co-occurrences to more restrictive spatial relations object oj. The probabilistic spatial relations betweenBobject
(e.g. “in front of”, “left of”), which provide more conﬁned oi,oj isrepresentedbythebeliefoverRi|j,denotedas (Rij).
regionstosearch,thusimprovingthesearchefﬁciency.Toris Based on the maintained belief P(OT x0:T,z0:T), the robot
et al. [26] proposed to learn a temporal model on inter- searches for the target object by selecting the next best view
object spatial relations to facilitate search. These methods pose ranked by an utility functionU:τ(cid:55)→R. τ speciﬁes the
assumethelandmarkobjectstobestatic,however,webelieve 6 DOF of camera view pose. The utility function U trades
accountingfortheuncertaintyinlandmarkobjects’locations off between navigation cost and the probability of search
is important for object search. success.Uponauserrequesttoﬁndatargetobject,therobot
iterates between the belief update of objects’ locations and
Existingworkshavealsoexploredknownpriorsonspatial
view pose selection, until the target object is found or the
relations between landmark and target objects. Given exact
maximum search time is reached.
spatial relations between landmark and target objects, Sjo¨o¨
et al. [25] used an indirect object search strategy [30], [6], IV. SEMANTICLINKINGMAPS
wheretherobotﬁrstsearchesforlandmarkobjects,andthen
For Semantic Linking Maps (SLiM), we consider inter-
searchesforatargetobjectinregionssatisfyinggivenspatial
objectspatialrelations,whilemaintainingthebeliefovertar-
relations.Ontheotherhand,givenaprobabilisticdistribution
getandlandmarkobjects’locations.Buildingonourprevious
over the spatial relations between objects, Aydemir et al. [2]
work [33], we probabilistically formalize the object location
formulate the object search problem as a Markov Decision
estimation problem via a Conditional Random Field (CRF).
Process. In our work, we learn the probabilistic inter-object
Themodelisnowextendedtoaccountforprobabilisticinter-
spatial relations by building on ideas of Lorbach et al. [18],
object spatial relations, as shown in Figure 2.
where inter-object relations are being probabilistically mod-
The posterior probability of object locations O history is
eled via a factor graph.
|
There are also works that do not assume prior knowledge p(O0:T x0:T,z0:T)=
owfitthheveisnuvailroantmteenntito.nRemseeacrhcahneirssmhsav[2e3e]x,p[l2o4re],d[o1b9j]e,ctsusceharcahs Z1∏T ∏N φp(oti,oti−1)φm(oti,xt,zt)∏φc,B(Rij)(oti,otj) (1)
t=0i=1 i,j
saliency detection. Similar to [10], [13], other research [17],
where Z is a normalization constant. Robot pose x and
[4], [8] utilizes object-object co-occurrences to guide the t
observation z are known. We assume that the robot stays
search for a target object. Positive and negative detections t
localized given a metric map of the environment.
of landmark objects will result in an updated belief over
the target object. We expand object-object co-occurrences φp(oti,oti−1) is the prediction potential that models the
movement of an object over time. We assume objects to
to ﬁner-grained spatial relations between objects, i.e., “in”,
remainstaticormovewithtemporalcoherence(variesacross
“on”, “proximity”, “disjoint”, which specify more conﬁned
object classes) during the search, i.e.
regions for object search.
Other literature [29], [12], [28] has also explored object- φp(oti,oti−1)=e−(oti−oti−1)TΣ−1(oti−oti−1)
place relations to facilitate object search. Wang et al. [29]
buildabeliefroadmapbasedonobject-placeco-occurrences φm(oti,xt,zt) is the measurement po{ten|tial tha·t··acc}ounts
for efﬁcient path planning during object search. Kunze for the observation model, and zt = zti i = 1, ,N are
(potentially noisy) detections for each object oi at time t.
et al. [12] bootstraps commonsense knowledge on object- (cid:54)
Because zi and oj areindependent if j = i, we simplify
place co-occurrences from the Open Mind Indoor Common t
Sense (OMICS) dataset. Samadi learned similar knowledge φm(oti,xt,zt) to φm(oti,xt,zti) s.t.,
∈
bwAtoyyoidrnakefcmetariivlrtseholeeytttaayqklpu.eees[r1oyo]finbtmghjeeactdtrh-eoepolumaWsceeonroelcxfdot-pdWoloaciccodeure,-rpraeWlsanctechebeesc(roWoin-botWooctcWueaxcr)rcp.eolnoOucrnueetssr. φm(oti,xt,zti)=PPPFTTNPN,,, iiifff ooπttii(∈o/ti)EE∈ttii baznutidt zztiti==0/0/ (2)
an environment during search. Manipulation-based object PFP, otherwise
search, as in [32], [31], [14], is not within the scope of this whereeachPstandsfortheprobabilityoffalsenegative,true
paper. negative, true positive, and false positive detection. Ei is the
t
1985
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. Algorithm 1: Inference of objects locations in SLiM.
Input: Observation z, Robot pose x,
t t
Particle set for each object:
oi− ={(cid:104)oi(−k),αi−(k)(cid:105)|k=1,···,M},i∈1:N
t 1 t 1 t 1
1 Resample M particles oi(−k) from oi− with probability
t 1 t 1
proportional to importance weights αi−(k) ;
··· t 1
2 for i=1, ,n do
···
3 for k=1, ,M do
4 Sample oti(k)∼φp(oti,oti(−k1)) ;
5 Assign weight
{ }
F{zigt}.2s:eCnsRoFr-boabsseedrvSaLtiioMnsm;oUdnekl:n(oaw)Kn:noOwtn=: {xott1,root2b,·o·t·p,oostNe}s., αti(k)∝φm(oti(k),xt,zt)j∈∏Γ(i)φc,B(Rij)(oti(k),otj−1) ;
(ethbae)cihrPsloapbtaejteicantlotrpaeatliiaortnioo:ni,asotBjti(imsRiepj)at.r,amtheetesrpizaetidalbryelathtieonbselbieeftwoeveenr 6 ∑w∑MheBr(eRφijc,=B(Rri)jα)(toj−(til1()kφ)c,,or(tj−o1ti,)o=tj,Rij=r)
r l=1
end
7
effective observation region for oi given robot pose at time end
8
t. Note, Ei is larger for larger objects, which can be reliably
t
detected from longer distance compared to small objects. π
is the camera projection matrix, and π(oi)∈zi denotes that C representative and divergent particles from the original M
t t
the projected object lies in the detected bounding box in zi. particles (C<M).
t
We model the spatial relations between objects with con-
B. Probabilistic Inter-Object Spatial Relations
twexotrkpobtyenptiaarlaφmct,Ber(eRriji)z.inHgeriet,wwiethexthteendbeφliceffroBm(Roiuj)rporveevriothues To get the belief over int∈er-object spatial relations B(Rij)
inter-object spatial relation between oi,oj, for each object pair oi,oj O, we use a factor graph by
φc,B(Rij)=∑B(Rij=r)φc,r(oti,otj,Rij=r) (3) bgueniledrianlgizeon[18p]rebcyedreinlagxinwgorthkebayssuLmoprbtiaocnhoentkanlow[1n8s]p.aWtiael
r
relations between landmark objects.
where r can take any value in the set of possible relations {V F E}
{ } ThefactorgraphG: , , consistsofvariablevertices
InF,oOrnr,∈C{oInnt,aOinn,,SCupopnotaritn,,PSrouxpipmoirtty},,Dφics,rjo(ointi,to.tj,Rij=r) is Ved=ges{REijw|∀hi(cid:54)=icjhoci,oonjn∈ecOtf}a,cftaocrtovrervtiecretiscewsitFh=va{riFaCbSl,eFvLeCr}ticaensd.
equal to 1 if objects oti,otj satisfy the spatial relation given Speciﬁcally, FCS :Rij (cid:55)→R is a unary factor that considers
the width, length and height of the object, otherwise 0. For
commonsenseknowledgeonspatialrelationbetweenobjects,
r=Proximity, φc,r(oti,otj,Rij =Proxim∼ityN) corresponds to a
Gaussian distribution that models otj (oti,Σij) and Σij FCS(Rij)=Frequency(Rij)
is determined by the size of objects oi,oj. The larger the
Similar to [18], we extract commonsense knowledge on R
size of oi,oj, the larger the variance in Σij. For r=Disjoint, ij
− fromonlineimagesearchengine(e.g.Flickr)bycountingthe
φc,r(oti,otj,Rij=Disjoint)=1 (cid:54) ∑ φc,r(oti,otj,Rij=r). frequency of certain spatial relation between objects oi,oj.
r=Disjoint
A. Inference For example, the frequency of Rcup,table =On is computed
as the number of search results of a query “cup on the
We propose a particle ﬁltering inference method for
table” divided by the number of search results of a query
maintaining the belief over object locations, as shown in
“on the table”. These extracted frequencies can be noisy.
Algorithm 1. Examples of the belief update over time are
For example, the frequency of “laptop on kitchen” is larger
available in Figure 3. Instead of estimating the posterior of
than 0, but it is not a valid expression because it refers to a
|
thecompletehistoryofobjectlocations p(O0:T x0:T,z0:T),we laptop being on top of the room geometry of a kitchen. We
recursively estimate the posterior probability of each object
oi ∈O, similarly to [33], [15]. manually encode the(cid:55)→FC{S(Rij}) for invalid expressions to 0.
t t FLC:(Rij,Rik,Rjk) 0,1 (cid:40)isatripletfactorthatconsiders
Todealwithparticledecay,wereinvigoratetheparticlesof logical consistency between a triplet of objects oi,oj,ok,
eachoi bysamplinginknownroomareas,aswellasaround
B ∈
o1t−heBr(oRbijje=ctsDoisjjobianste)d>o0n.2.(ARcirj)o.ssInoustrepex5p,erjimeΓn(tsi), wonelyusief FLC(Rij,Rik,Rjk)= 10,, iofthceornwsiissete.nt.
100 particles for each object. The inference algorithm does
not assume single object instance for each object class. The For example, if oi is in oj, and oj is in ok, then oi
O
inferencealgorithmhasacomplexityof (nKM2),whereK should be in ok to satisfy logical consistency, i.e., FLC(Rij=
istheaveragecardinalityofΓ(i).FurOtherworkscanbedone In,Rik =In,Rjk =In)=1. Previous work [18] assumes the
to decrease the complexity down to (nKMC) by sampling spatial relations between landmark objects to be known,
1986
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. Fig.3:ExamplesofbeliefupdatesinSLiM.givenobservations.Upper:Evolutionofparticlesoffridge,sink,coffeemachine
over time. Lower: RGB observation (with object detection) over time. (Best viewed in color).
and only relations R connecting target object o is not necessarily looking at x . Thus, we formulate a view
target,j target n
and landmark object o to be unknown. Their pairwise pose optimization problem under constraints as below,
j
fFtiaLocCnto:re(mReptnalfrogoyertcs,ji,naRgttarrligonegat,irkcy)a(cid:55)→lfacc{oto0nr,s1iFs}t.enIcncyocniossnidtarearsibtn,ignoauarylrlffpouornmscstuiibloalne- argτmn in 1−vn·(cid:107)xxnn−−ccnn(cid:107) s.t xn∈Eτn, c(τn)>0 (5)
LC
combinations of (Rij,Rik,Rjk) and evaluating their logical where vn is the view direction given τn, Eτn denotes the
consistency. effective observation region of the target object at camera
By applying Belief Propagation [11] on the factor graph pose τn, and c:τ (cid:55)→R is a function that computes a signed
formulated as above, we can get the marginal belief over distanceofaconﬁgurationτ tothecollisiongeometryofthe
B
inter-objectrelations (Rij)betweenallobjectpairs.Weuse environment.
the libDAI [20] library for inference. An example of the
B. View Pose Selection
probabilistic inter-object spatial relations inferred from the
factor graph is as shown in Figure 5, and it is used in our Weproposetwodifferentutilityfunctionstoranktheview
experiments. pose candidates:
1) Direct Search utility: U encourages the robot to
DS
V. SEARCHSTRATEGY explore promising areas that could contain the target object
while accounting for navigation cost,
Based on the belief over the object locations, we actively
search for the target object, by generating promising view 1
pGoivseesnatnhde spealretcictlethseetbe(cid:104)sott(ko),nαet(kra)(cid:105)nkoefdthbey taarugteitlitoybjfeucntctoioans. whereω isthUeDwSe(iτgkh)t=ofωthne+Gαauarscstiaann(cσodmnapvo)nent(asin(4(6)))
being maintained in IV, we ﬁt Gaussian Mixture Models n
that τ is generated from, and d is the navigation distance
(GMMs) through Expectation Maximization to the particles k nav
from the current robot location to view pose τ . Parameter
by auto selecting the number of clusters [5], k
α trades off between the probability of ﬁnding the target
(cid:104)ot(k),αt(k)(cid:105)∼(cid:104)N(xn,Σn),ωn(cid:105) (4) oqbujieccktlyanthdethaercntaanv(iσgadtnioavn)cpolsatt.eaPuasra.meter σ determines how
A. View Pose Generation With U , the object search id direct because we are di-
DS
N rectlyconsideringpromisingareasrepresentedbytheGMMs
For each Gaussian component {(xn,Σn), we}generate a for the target object.
setofcameraviewposecandidates τni =(cin,ψni) ,wherecn 2) Hybrid Search utility: U encourages the robot to
and ψ denote the translation and the rotation of the camera HS
n
explore promising areas that could contain the target object
respectively.
and/or any landmark object, while accounting for navigation
Initially, we sample the location of the camera c evenly
n
cost
from a circle with a ﬁxed radius around the center xn of the 1
Gψa.usNsioatne,ctohmatpothneesnet,iannitdiaallsysigsnamapdleedfauvlitewvalpuoesetso croatnatipount UHS(τk)= ωn+αarctan(σdnav) (7)
n +β max CoOccur(o,oj)ωjIj
the robot in collision with the environment, and the camera n n
j,n
1987
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. Fig. 5: Marginal belief on inter-object spatial relations, as
well as object-room relations, inferred from the factor graph
as explained in Sec. IV-B. CM: coffee machine, CT: coffee
table
room types and considered landmark objects are annotated
Fig. 4: Simulation experiments setup in Gazebo: an
in Figure 4, along with the placements of target objects.
apartment-like environment with four rooms. There are 6
The marginal belief R inferred from the factor graph as
landmarkobjectsand3targetobjects:coffeemachine,laptop, ij
explained in IV-B is depicted in Figure 5.
cup. Each target object has two equally possible locations.
We set up an object detector in simulation that returns a
detection of an object, if the object is in view, not fully
wheretheadditionaltermcomparedtoU actstoencourage
DS occluded, and within the effective observation range. For
the robot to also explore areas that could contain landmark
large objects (e.g. sofa, bed, fridge), mid-sized objects (e.g.
object oj which co-occurs with the target object o with
desk, table, sink), and small objects (e.g. cup, laptop, coffee
probability CoOccur(o,oj). Speciﬁcally, CoOccur(o,oj) =
−B machine), we assume an effective observation range of 5m,
(1 (Rtarget,j=Disjoint)), and ωnj is the weight of the n- 4m, 2.5m respectively.
th Gaussian component of GMMs ﬁtted to the belief over
We benchmark following methods:
the location of the landmark object oj. And Ij is 1 if the
n
n-thGaussianofobjectoj iswithintheeffectiveobservation • UDS: Uninformed direct search (Eq.6). The robot does
region at camera pose τ , otherwise 0. not account for the spatial relations between the target
k
U is inspired by the indirect object search strategy and landmark objects (omitting Eq. 3 in SLiM). This
HS
baseline represents a naive approach for object search.
as studied in [6], [30]. Previous studies demonstrated that
• IDS-Known-Static: Informed direct search (Eq.6) with
purposefully looking for an intermediate landmark object
a known prior on landmark object locations. The robot
helps quickly narrow down the search region for the target
assumesthatlandmarkobjectsarestaticatthelocations
object if the landmark object often co-occurs with the target
provided by the prior. This method resembles previous
object, thus improving the search efﬁciency.
With U , the object search can be considered hybrid works [10], [13], [26].
HS • IDS-Known-Dynamic: Informed direct search (Eq.6)
because we are considering promising areas represented by
with a known prior on landmark object locations. This
GMMs for both the target object (as in direct search) and
is similar to IDS-Known-Static except that the robot
landmark objects that co-occur with the target object (as in
does not assume the landmark objects to remain at the
indirect search).
∗ locations expressed in the prior.
Inourexperiments,weuseaA basedplannertocompute
• IDS-Unknown: Informed direct search (Eq.6) without
dnav.Weempiricallysetα=0.1,β =0.4,andσ=0.5such
prior on landmark object locations. The particles for
that arctan(σdnav) plateaus as dnav goes beyond 3m.
landmarkobjectsareinitializeduniformlyacrosstheen-
VI. EXPERIMENTS vironment.Thismethodresemblespreviousworks[17],
[3].
We perform object search tasks in both simulation and
• IHS-Unknown: Informed hybrid search (Eq.7) without
real-world environments with a Fetch robot. In the sim-
prior on landmark object locations.
ulation experiments, we quantitatively benchmark various
methods, including methods that resemble previous works All methods except for UDS are using the full SLiM
andourproposedmethod.Inthereal-worldexperiments,we model. We assume that an occupancy-grid map of the en-
demonstrate qualitatively that the proposed method scales to vironment is given. We also assume that the room types are
real-world applications. In both simulation and real-world accurately recognized across the environment. IDS-Known-
∗
experiments, the robot accelerates to at most 1m/s and turns methods are provided with a noisy prior on landmark
at most at 1.7rad/s. object locations which differ from the actual locations, to
1) Simulation Experiments: The simulation experiments emulate the common cases where perfect knowledge about
are performed in an apartment-like environment (10mx11m) landmark locations is not available. For all methods, the
setup in the Gazebo simulator, as shown in Figure 4. The particlesforthetargetobjectareinitializeduniformlyacross
1988
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. Fig. 6: Examples of search paths generated by each method while searching for cup. Methods from left to right: UDS,
IDS-Known-Static, IDS-Known-Dynamic, IDS-Unknown, IHS-Unknown. (Best viewed in color).
Target Object Metrics UDS IDS known, static IDS known, dynamic IDS unknown IHS unknown
Views 7.83 6.17 4.67 6.33 3.67
Search Time (s) 107 76 60 75 50
Coffee Machine
Search Path (m) 8.68 6.70 5.80 6.74 4.93
Success Rate 1.0 1.0 1.0 1.0 1.0
Views 11.00 12.50 7.17 5.67 4.17
Search Time (s) 197 222 124 91 78
Laptop
Search Path (m) 28.27 26.86 13.13 7.69 8.40
Success Rate 0.83 0.50 1.00 1.00 1.00
Views 13.17 14.50 12.67 11.83 9.00
Search Time (s) 184 229 189 185 139
Cup
Search Path (m) 22.64 29.81 23.40 19.68 13.91
Success Rate 0.83 0.33 0.83 0.83 1.00
TABLE I: Benchmark results for object search in simulation experiments. Among methods that reached 100% success rate,
IHS unknown successfully found target objects within the smallest number of views and least search time.
the environment. kitchen and a living room. The robot stays localized in the
Foreachtargetobject,werun6trialspermethod.Ineach pre-mappedenvironmentbasedonitsLIDAR,andnavigates
trial, the robot starts atthe same location, depicted in Figure based on a MPEPC based path planner [21]. The target
4. The object search is terminated if (1) the belief over the object is a cup, and landmark objects include table, sofa,
target object location has converged, or (2) the maximum coffee machine and sink. IHS-Unknown reached average
searchtimeof5minshasbeenexceeded.Atrialissuccessful success rate of 0.7 (7 out of 10 trials). The average number
if the robot ﬁnds the target object before timeout. For each of view poses, search time and search path is 4.86, 103s,
target object and each method, we measure the number of and 8.32m repectively. The failure cases were due to false
view poses, search time, distance travelled by the robot, and negativedetectionofthecupduetolighting(weusedFaster
search success rate averaged across all trials. R-CNN [22] trained on COCO dataset [16]). Examples of
ThebenchmarkresultisasshowninTableI.Examplesof real-world experiments with a Fetch robot is available in
the resulting search path from each method are depicted in online video https://youtu.be/uWWJ5aV6ScE.
Figure 6. As we can see, UDS is not as efﬁcient because it
is not making use of the spatial relations between the target VII. CONCLUSION
and landmark objects in the environment. Given a noisy
prior on landmark object locations, IDS-Known-Dynamic In this paper we present an efﬁcient active visual object
outperforms IDS-Known-Static because it accounts for the searchapproachthroughtheintroductionoftheSLiMmodel.
uncertainty of the landmark object locations, whereas IDS- SLiM simultaneously maintains the belief over target and
Known-Static is misled by the noisy prior. landmark objects locations, while accounting for the prob-
Given no prior information, IHS-unknown outperforms abilistic inter-object spatial relations. Further, we propose a
IDS-unknown because it encourages the robot to explore hybrid search strategy that draws insights from both direct
promising regions that contain the target and/or useful land- and indirect object search. Given noisy or no prior on
mark objects, whereas IDS-unknown only considers promis- landmark objects locations, we demonstrate the beneﬁt of
ingregionsthatcontainthetargetobject.WithIHS-unknown, modeling landmark objects locations under uncertainty in
the robot beneﬁts from ﬁnding landmark objects which help SLiM, and the hybrid search strategy that encourages the
narrow down the search region for the target object. robot to explore promising areas that can contain the target
2) Real-World Experiments:: The real-world experiment and/or landmark objects in both simulation and real-world
is executed in an environment (8mx8m) that consists of a experiments.
1989
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. REFERENCES [21] J.J.Park,C.Johnson,andB.Kuipers. Robotnavigationwithmodel
predictiveequilibriumpointcontrol. In2012IEEE/RSJInternational
ConferenceonIntelligentRobotsandSystems,pages4945–4952,Oct
[1] A. Aydemir, A. Pronobis, M. Go¨belbecker, and P. Jensfelt. Active
2012.
visualobjectsearchinunknownenvironmentsusinguncertainseman-
[22] S.Ren,K.He,R.Girshick,andJ.Sun.Fasterr-cnn:towardsreal-time
tics. IEEETransactionsonRobotics,29(4):986–1002,2013.
objectdetectionwithregionproposalnetworks. IEEEtransactionson
[2] A. Aydemir, K. Sjo¨o¨, J. Folkesson, A. Pronobis, and P. Jensfelt.
patternanalysisandmachineintelligence,39(6):1137–1149,2017.
Search in the real world: Active visual object search based on
[23] K. Shubina and J. K. Tsotsos. Visual search for an object in a
spatial relations. In Robotics and Automation (ICRA), 2011 IEEE
3d environment using a mobile robot. Computer Vision and Image
InternationalConferenceon,pages2818–2824.IEEE,2011.
Understanding,114(5):535–547,2010.
[3] A.Aydemir,K.Sjo¨o¨,andP.Jensfelt. Objectsearchonamobilerobot
[24] K.Sjo¨,D.G.Lo´pez,C.Paul,P.Jensfelt,andD.Kragic.Objectsearch
using relational spatial information. In Proceedings of International
andlocalizationforanindoormobilerobot.JournalofComputingand
ConferenceonIntelligentAutonomousSystems,pages111–120,2010.
InformationTechnology,17(1):67–80,2009.
[4] J.Elfring,S.Jansen,R.vandeMolengraft,andM.Steinbuch. Active
[25] K.Sjo¨o¨,A.Aydemir,andP.Jensfelt. Topologicalspatialrelationsfor
objectsearchexploitingprobabilisticobject–objectrelations.InRobot
activevisualsearch. RoboticsandAutonomousSystems,60(9):1093–
SoccerWorldCup,pages13–24.Springer,2013.
1107,2012.
[5] M.A.T.FigueiredoandA.K.Jain. Unsupervisedlearningofﬁnite
[26] R.TorisandS.Chernova. Temporalpersistencemodelingforobject
mixture models. IEEE Transactions on Pattern Analysis & Machine
search. InRoboticsandAutomation(ICRA),2017IEEEInternational
Intelligence,(3):381–396,2002.
Conferenceon,pages3215–3222.IEEE,2017.
[6] T. D. Garvey. Perceptual strategies for purposive vision. Tech. Rep. [27] M. Veloso, J. Biswas, B. Coltin, and S. Rosenthal. Cobots: robust
AICenter,SRIInternational,333RavenswoodAve.,MenloPark,CA symbiotic autonomous mobile service robots. In Proceedings of the
94025.,1976. 24thInternationalConferenceonArtiﬁcialIntelligence,pages4423–
[7] N. Hawes, C. Burbridge, F. Jovan, L. Kunze, B. Lacerda, L. Mu- 4429.AAAIPress,2015.
drova, J. Young, J. Wyatt, D. Hebesberger, T. Kortner, et al. The [28] P. Viswanathan, D. Meger, T. Southey, J. J. Little, and A. K. Mack-
strandsproject:Long-termautonomyineverydayenvironments.IEEE worth. Automated spatial-semantic modeling with applications to
Robotics&AutomationMagazine,24(3):146–156,2017. place labeling and informed search. In Computer and Robot Vision,
[8] D.JohoandW.Burgard. Searchingforobjects:Combiningmultiple 2009CanadianConferenceon,pages284–291.IEEE,2009.
cuestoobjectlocationsusingamaximumentropymodel.InRobotics [29] C. Wang, J. Cheng, J. Wang, X. Li, and M. Q.-H. Meng. Efﬁcient
and Automation (ICRA), 2010 IEEE International Conference on, objectsearchwithbeliefroadmapusingmobilerobot.IEEERobotics
pages723–728,May2010. andAutomationLetters,3(4):3081–3088,2018.
[9] P. Khandelwal, S. Zhang, J. Sinapov, M. Leonetti, J. Thomason, [30] L.E.WixsonandD.H.Ballard.Usingintermediateobjectstoimprove
F.Yang,I.Gori,M.Svetlik,P.Khante,V.Lifschitz,etal. Bwibots:A the efﬁciency of visual search. International Journal of Computer
platformforbridgingthegapbetweenaiandhuman–robotinteraction Vision,12(2-3):209–230,1994.
research. The International Journal of Robotics Research, 36(5- [31] L. L. Wong, L. P. Kaelbling, and T. Lozano-Pe´rez. Manipulation-
7):635–659,2017. basedactivesearchforoccludedobjects. InRoboticsandAutomation
[10] T.KollarandN.Roy.Utilizingobject-objectandobject-scenecontext (ICRA), 2013 IEEE International Conference on, pages 2814–2819.
when planning to ﬁnd things. In Robotics and Automation (ICRA), IEEE,2013.
2009 IEEE International Conference on, pages 2168–2173. IEEE, [32] Y.Xiao,S.Katt,A.tenPas,S.Chen,andC.Amato. Onlineplanning
2009. for target object search in clutter under partial observability. In
[11] F.R.Kschischang,B.J.Frey,andH.-A.Loeliger. Factorgraphsand RoboticsandAutomation(ICRA),2019InternationalConferenceon,
thesum-productalgorithm.IEEETransactionsoninformationtheory, pages8241–8247.IEEE,2019.
47(2):498–519,2001. [33] Z.Zeng,Y.Zhou,O.C.Jenkins,andK.Desingh. Semanticmapping
[12] L. Kunze, M. Beetz, M. Saito, H. Azuma, K. Okada, and M. Inaba. with simultaneous object detection and localization. In Intelligent
Searching objects in large-scale indoor environments: A decision- RobotsandSystems(IROS),2018IEEE/RSJInternationalConference
theoretic approach. In Robotics and Automation (ICRA), 2012 IEEE on,pages911–918.IEEE,2018.
InternationalConferenceon,pages4385–4390.Citeseer,2012.
[13] L.Kunze,K.K.Doreswamy,andN.Hawes. Usingqualitativespatial
relations for indirect object search. In Robotics and Automation
(ICRA), 2014 IEEE International Conference on, pages 163–168.
IEEE,2014.
[14] J. K. Li, D. Hsu, and W. S. Lee. Act to see and see to act: Pomdp
planningforobjectssearchinclutter.InIntelligentRobotsandSystems
(IROS), 2016 IEEE/RSJ International Conference on, pages 5701–
5707.IEEE,2016.
[15] B.Limketkai,D.Fox,andL.Liao. Crf-ﬁlters:Discriminativeparticle
ﬁlters for sequential state estimation. In Robotics and Automation
(ICRA), 2007 IEEE International Conference on, pages 3142–3147.
IEEE,2007.
[16] T. Lin, M. Maire, S. J. Belongie, L. D. Bourdev, R. B. Girshick,
J.Hays,P.Perona,D.Ramanan,P.Dolla´r,andC.L.Zitnick.Microsoft
COCO:commonobjectsincontext. CoRR,abs/1405.0312,2014.
[17] P.Loncomilla,J.Ruiz-delSolar,andM.Saavedra. Abayesianbased
methodology for indirect object search. Journal of Intelligent &
RoboticSystems,90(1-2):45–63,2018.
[18] M. Lorbach, S. Ho¨fer, and O. Brock. Prior-assisted propagation of
spatialinformationforobjectsearch.InIntelligentRobotsandSystems
(IROS), 2014 IEEE/RSJ International Conference on, pages 2904–
2909.IEEE,2014.
[19] D.Meger,M.Muja,S.Helmer,A.Gupta,C.Gamroth,T.Hoffman,
M. Baumann, T. Southey, P. Fazli, W. Wohlkinger, et al. Curious
george:Anintegratedvisualsearchplatform. InComputerandRobot
Vision,2010CanadianConferenceon,pages107–114.IEEE,2010.
[20] J.M.Mooij. libdai:Afreeandopensourcec++libraryfordiscrete
approximate inference in graphical models. Journal of Machine
LearningResearch,11(Aug):2169–2173,2010.
1990
Authorized licensed use limited to: Heriot-Watt University. Downloaded on September 22,2020 at 01:07:46 UTC from IEEE Xplore.  Restrictions apply. 