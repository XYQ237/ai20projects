2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Sample-and-computation-efﬁcient Probabilistic Model Predictive
Control with Random Features
∗
Cheng-Yu Kuo1 , Yunduan Cui1, Takamitsu Matsubara1
Abstract—Gaussian processes (GPs) based Reinforcement an impractical MPC control period. It is resulting in a trade-
Learning (RL) methods with Model Predictive Control (MPC) off between ideal MPC control period and state prediction
have demonstrated their excellent sample efﬁciency. However,
precision.
since the computational cost of GPs largely depends on the
Recently, ﬁnite feature space approximating methods are
training samplesize, learning anaccurate dynamicsusing GPs
resultinlowcontrolfrequencyinMPC.Toalleviatethistrade- proposed to calculate the kernel expansions efﬁciently. Ran-
off and achieve a sample-and-computation-efﬁcient nature, we dom Kitchen Sink (RKS) [10] follows Bochner’s theorem
propose a novel model-based RL method with MPC. Our to precisely approximate the kernel expansions by randomly
approach employs a linear Gaussian model with randomized
sample features from frequency components of the Fourier
features using the Fastfood as an approximated GP dynamics.
transformed kernels. Fastfood enhances the RKS by further
Then, we derive an analytic moment-matching scheme in state
prediction with the model and uncertain inputs. As a result, improve the computation efﬁciency by approximating the
thecomputationalcostoftheMPCinourRLmethoddoesnot sampled matrix in RKS from scratch within low variance
dependonthetrainingsamplesizeandcanimprovethecontrol [11].Thesemethodsdramaticallyreducedthecomputational
frequency over previous methods. Through experiments with
cost of calculating the kernel expansions with minimal
simulated and real robot control tasks, the sample efﬁciency,
compromise in precision.
as well as the computation efﬁciency of our model-based RL
method, are demonstrated. With the above in mind, in this study, we develop a novel
MBRL approach with probabilistic MPC, which holds both
I. INTRODUCTION sample and computation efﬁcient characteristics. We extract
the random features from the Fastfood kernel expansion
Reinforcement learning (RL) enables a robot to learn a
to efﬁciently approximate GPs dynamics with limited fea-
speciﬁc task from scratch but often suffers from being data
tures. Then, we model the probabilistic system dynamics
inefﬁcient. A potential solution to increase data efﬁciency
by approximately representing the GPs dynamics with a
is the combination of model-based RL(MBRL) [1] and
linear Gaussian model [12] with the Fastfood features; this
Gaussian Process (GPs) [2]. As a state-of-the-art MBRL
alleviates the trade-off between MPC control period and
method, PILCO [3] explicitly incorporates GPs model un-
predictionprecision.Wederiveananalyticmoment-matching
certainty into planning and control to reduce the effect of
scheme with the linear model using random features for
noisyobservationsanddatascarcity.Assumingacontrollable
propagating the model uncertainty in state prediction. As a
target dynamics, PILCO learns an optimal policy by long-
result, the MPC control period will stay constant regardless
term planning from an initial state.
ofthetrainingsamplesize.Comparedtopreviousworks,the
Nevertheless,PILCO[3]hasnocountermeasurestounpre-
contributions of this paper are the following:
dictable in-trial disturbances in an open environment. Some
1) Propose a sample-and-computation-efﬁcient MBRL
probabilistic/stochastic Model Predictive Control (MPC) is
approach with probabilistic MPC, which is capable of
proposed to frequently plans for optimal control sequence
high-controlfrequencyunderanytrainingsamplesize.
by minimizing the long-term expected cost with uncertainty
2) Empirically verify the sample efﬁciency as well as the
[4]–[7]. Where the long-term expected cost is predicted by
computationalcostinourmethodthroughexperiments
propagating uncertainty through time via analytic moment-
with simulated and real robots.
matching method [8, 9].
The remainder of this paper is organized as follows:
However, the computational cost of exploiting moment-
Section II presents preliminaries with some related works
matching with these efﬁcient approximations still largely
to our approach and its’ shortcomings. Section III details
depends on training sample size in a quadratic way. A
how our approach manages the shortcomings in Section II.
largertrainingsamplesizeincreasestheprecisionofmodeled
Section IV shows the simulation and real experiment result
system dynamics, but the MPC control period will also be
with arm robot. Discussions follow in Section V.
extended. Therefore, there is a difﬁculty in achieving high-
frequency MPC with those approaches, where short MPC II. PRELIMINARIES
control period limits training sample size, which returns low
In this section, we will introduce the comprehension
precision. Oppositely, given enormous samples will lead to
knowledge to our approach. Start with a brief introduction
to the standard GPs probabilistic dynamics, following by
∗
Correspondingauthor:kuo.cheng-yu.jy5@is.naist.jp
a moment-matching approach with standard GPs and its
1 GraduateSchoolofScienceandTechnology,NaraInstituteofScience
andTechnology(NAIST),Nara,Japan shortcomings in the computational cost. Next, we introduce
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 307
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. ∈R ×
MPCwithlong-termcost-minimizingbyexploitingmoment- The entries of Q N N are given by
(cid:12) a (cid:12)
matching. Following by MBRL methods with MPC. (cid:12) (cid:12)
k (X˜ ,µ )k (X˜ ,µ )
Q = a i t a j t
A. GPs Dynamics a,ij 2Σ Λ−1+I 12 (10)
X×U→X t a
Consider an unknown dynamics f : with the × (cid:62) 1 − −
∈X⊂R ∈U⊂R exp(Z˜ (Σ + Λ ) 1Σ Λ 1Z˜ ),
input of state x D and control signal u U: ij,t t 2 a t a ij,t
− −
(cid:104) x(cid:105)t+1 =f(xt,ut)+, (1) where Z˜ij,t =((X˜i X˜j)/2) µt.
∼ N The computational cost of exploiting moment-matching
with system noise  (0,Σn), where Σn = with standard GPs is largely depend on the training sample
− −
diag σ 2,...,σ 2 .Theunknowndynamicsisthentrained size N in a quadratic way, owing to the calculation of Q .
n,1 n,D a
with training input tuples x˜ :=(x ,u ), and corresponding
t (cid:62)t t C. MPC with Long-term Cost Minimizing
training target y =[y ,...,y ] =x . For each target
t t,1 t,D t+1
dimensiona,alatentG(cid:18)Pmodely =f (x˜ )+ ist(cid:19)rained The MPC is a closed-loop feedback controller with each
· t,a a t a
with mean function µ () and covariance kernel function: timestepanopen-loopanH stepscontrolsequenceplanning.
a
For each time step t, the MPC observes the current state x
−1 − (cid:62) − − t
k (x˜ ,x˜ )=α2exp (x˜ x˜ ) Λ 1(x˜ x˜ ) , (2) from system feedbacks and repeats moment-matching state
a i j a 2 i j a i j predictions recursively to plan an open-loop H steps control
wdihaegroenaαla2misatrsiixg.naBlovtahriaanrcee,oΛpt−aim1izisedsqtuharroeudghlenMgtahxismcualme sSeeqq(cid:2)uueenncteialuQt,u..a.d,ruatt(cid:3)+icHP−r1ogbryammmininimg(iSz(cid:88)QinPg)l[o1n4g]-:term cost via
Marginal Likelihood Estimation(cid:0)(MMLE) [2, 13(cid:1)]. The pre- −
t+H 1
dictive distribution of a new input x˜∗ can be derived as: u ,...,u − = argmin (cid:96)(x ,u ). (11)
t t+H 1 s s
p(f (x˜∗)|X˜,y )∼GP µ (x˜∗),σ2(x˜∗) , (3) ut,...,ut+H−1 s=t
a a (cid:62) a a where (cid:96) is the immediate cost, deﬁned to accomplish the
µ (x˜∗)=k ∗β , (4)
a a, a intended task. The ﬁrst control signal u is then executed,
− (cid:62) − t
σa2(x˜∗)=ka,∗∗ ka,∗Kya1ka,∗, (5) shifts the MPC to the next time step xt+1. Repeating this
routine until reaching the goal state.
where X˜ = [x˜ ,...,x˜ ], y = [y ,...,y ] are
t,1 t,N a (cid:0)(cid:62)t,a,1 t,a,N(cid:1)
the training input and target set. k ∗ = k (X˜,x˜∗); D. MBRL with probabilistic MPC
(cid:0) (cid:1) a, a
ka,∗∗ = ka(x˜∗,x˜∗); Ka,ij = ka(x˜t,i,x˜t,j) is the cor- We follow the similar MBRL approach to [7], Algorithm
responding element−in Ka; Kya = Ka+σn2,aID and 1. At the ﬁrst trail, the GPs dynamics are initially updated
β = K +α2I 1y . with samples from operating random control signals to
a a a D a
the environment. Next, the RL process starts by running
B. Long-term State Prediction Using Moment-Matching
N trials in total with L each. At each rollout,
trial rollout
Uncertainty propagation using Moment-matching predicts given the observed current state, the MPC optimizes the
future states x with uncertainties [8, 9]. Given a prob- control sequence and operate the ﬁrst control signal to the
t+1∼ N ∈ R
abilistic state x (µ ,Σ ) D. Following the law environment. Corresponding samples are collected in each
t t t
of iterated expectations (Fubini’s theorem), the predictive rollout and update the GPs dynamic at the end of each trial.
meanµ andvarianceσ2 ofath latentmodelofx
a,t+1 a,t+1 t+1
are obtained using exploiting moment-matching. We obtain
µ by III. APPROACH
a,t+1
(cid:2) E (cid:3) | (cid:62) Based on Section II, in this section, we introduce our ap-
µ = [f (x ,u )µ ,Σ ]=β q , (6)
a,t+1 xt a t t t t a a proach,Sample-and-computation-efﬁcientProbabilisticMPC
where q =(cid:12)(cid:12)q ,...q (cid:62)(cid:12)(cid:12)∈RN with (SCP-MPC). Applying Linear Gaussian Model (LGM) with
a 1 N randomfeaturestoexploitingmoment-matching,wealleviate
q =α2 Σ Λ−1+I −12 the trade-off between MPC control period and prediction
i a t a (7) precision at “ActionSearch” stage in Algorithm 1.
× −1 − (cid:62) − −
exp( (X˜ µ) (Σ +Λ ) 1(X˜ µ)).
2 i t a i A. Fastfood Kernel Approximation and Feature Extraction
We obtain σ2 by The RKS [10] approximates the covariance kernel ex-
a,t+1
(cid:48)
σ2 =E [σ2(x ,u )|µ ,Σ ] pansions k(x,x) by(cid:90)drawing entire Zω i.i.d from Fourier
a,t+1 xt Ea t t t t| transformed kernel ρ(ω),
+( [µ (x ,u )2 µ ,Σ ] (8)
−E xt a t t| t t (cid:48) (cid:104) − (cid:48)(cid:105)
[µ (x ,u )µ ,Σ ]2); k(x,x)= ρ(ω)exp(i ω,x x )dω
xt a t t t t (12)
following Eq.(3), we further calculate ≈(cid:104) (cid:48) (cid:105)
φ (x),φ (x) ,
j j
− − (cid:62) −
σa2,t+1 =αa2 tr(Kya1Qa)+βaQaβa µ2a,t+1. (9) where φj(x)=n−21 exp(iZωx)∈Rn.
308
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. (cid:2) (cid:3)
∗ (cid:62) X×U→R
Algorithm 1: MBRL with MPC as Φ(x ,u )= 1 φ (x ,u ) : M.
t t t t
Initialization
B. Approximated GPs with Finite Random Features
number of trial N
trial ·
length of rollout for each trial L Werepresentthefunctionf()inEq.(1)byapproximating
rollout
step horizon of MPC prediction H the GPs dynamics via LGM [12] with Fastofood random
{} {}
samples for training dynamics model x= ,y= features Φ(x,u), LGM-FF.
cost function for intended task (cid:96)() The predictive distribution of(cid:0)output given inp(cid:1)ut tuple x˜∗
# Generate random samples with random actions is:
ResetPosition() ∗ · | ∼GP
for i=1,2,...,L do p(fa()x˜∗,X˜,ya) µa(x˜∗),σa2(x˜∗) , (15)
rollout (cid:62)
x = ReadSensor() µ (x˜∗)=w¯ Φ (x˜∗), (16)
i a a a
ui = RandomActions() σ2(x˜∗)=Φ (x˜∗)(cid:62)A−1Φ (x˜∗), (17)
Operate(u ) a a a a
i ∈R ×
yi ={Read}Senso{r() } where wa M D is corresponding weight.
x= x,x ,y= y,y Given the prior knowledge to the weight of ath latent
i i ∼ N
# MBRL with MPC model w (0,Σ ) where Σ = σ2 I . Each
a p,a p,a p,a M
model = trainModel(x,y) valueofw¯a islearnedthroughmaximumaposteriori(MAP)
for i=1,2,...,N do estimation [2, 12, 13], given as followed:
trial
ResetPosition() − −
for j =1,2,...,L do w¯a =σn,2aAa1Φa(X˜)ya, (18)
∗ rollout − (cid:62) −
x = ReadSensor() A =σ 2Φ (X˜)Φ (X˜) +σ 2I . (19)
∗ a n,a a a p,a M
u = ActionSearch(x ,H,model,(cid:96)()) − − ·
where σ 2, σ 2 and σ in Φ () are optimized via MMLE.
Operate(u(1)) n,a p,a f a
y∗ = ReadSensor() Theselectionoffeatureslargelydependsonparametersd,
{ ∗} { ∗} w¯ and σ . The weight w¯ and σ adjust the amplitude and
x= x,x ,y= y,y f f
frequencyofthefrequency-basedfeatures.Sincebothw¯ and
model = trainModel(x,y)
σ areoptimizedbyMMLE,numberoffeaturesM issimply
f
decided by gradually increase the value of d until the LGM
precisely ﬁts the samples. However, with frequency-based
Fastfood[11]furthergeneratesthesampledmatrixinRKS features, the minimum requirement of M mainly depends
from scratch and approximates kernel expansion via on the state dynamics.
The computational cost of learning the system dynamics
k(x,x(cid:48))≈(cid:104)φ(x),φ(x(cid:48))(cid:105), (13) with LGM is O(M3) given by the inversion of matrix
∈ R ×
wanhderVe φ∈(x)R=n×nd∈−. 12TNehxepn(iuVmxb)erwoitfhfVeatu=resσf1a√rdeSdHecGidΠedHBby, AwthheaicshtanisdMaﬁrdxMeGd, PwbshyeirstehOeM(sNyiss3t)et.hmeSdidniymcneeanmasliilocsnl.atoeIfnntfecmaotmuordpeealrssipsaoacrnee,
d=2m with m . trained independently, for a simpler notation, subscription
G is the diagonal Gaussi∼anNscaling matrix with each a is omitted in the following sections.
element drawn iid from G (0,1). B is the diagonal
ii
binary scaling matrix with each element drawn iid from C. Moment-Matching with LGM-FF
∈{± }
B 1 .Next,applyWalsh-HadamardtransformationH (cid:0) (cid:1)
ii Given a probabilistic state x and a deterministic con-
onGandB foradensermatrixwithvarietiesbetweenrows. t
trol signal u , the predictive state distribution p(x ) =
HGΠHB generates a matrix with m iid Gaussian random | t N t+1
p(f(x ,u )µ ,Σ ,u ) = µ ,σ2 are calculated
vairables in each row, where Π is permutation matrix to t t t t t t+1 t+1
by following Fubini’s law. In the followings, notation is
decorrelate two Hadamard transformation. We follow [15]
simpliﬁed as Φ := Φ(x ,u ); µ (cid:90):= µ(x ,u ); σ2 :=
to generate the diagonal scaling matrix S with element t t t t t t t
(cid:107) (cid:107)(cid:107) (cid:107)− σ2(x ,u ). For each latent model, we calculate µ by
S = ω G 1 by drawing ω from the spherically t t t+1
ii i Frob i (cid:90)
symmetricdistributiondeﬁnedbyρ(ω)inEq.(12).Thevalue µ =E [f(x ,u )|µ ,Σ ]= µ p(x )dx
of σ is optimized in Section III-B. t+1 xt t t t t t t t
f (20)
Rewrite a real map of the complex feature φ as: (cid:82) (cid:62) (cid:62)
=w¯ Φ p(x )dx =w¯ q,
(cid:104) (cid:48) (cid:105) − − (cid:48) − − (cid:48) t t t
φ(x),φ(x) =n 1exp(iV(x x))=n 1cos(V(x x)) (cid:20) (cid:0) (cid:1) (cid:21)
=n−1(cos(Vx)cos(Vx(cid:48))+sin(Vx)sin(Vx(cid:48))) where q= Φtp(cid:0)(xt)dxt =[1,q˜(cid:1)](cid:62) ∈RM is calculated by
(cid:104) ∗ ∗ (cid:48) (cid:105) − − ◦ ◦ (cid:62)
= φ ((cid:2)x),φ (x) , (cid:3) (14) q˜ = nn−1212eexxpp −1212((VVxxΣΣtt))◦22 ◦csoins((VV[[µµtt uutt]](cid:62))) ; (21)
∗ − (cid:62) ◦
where φ (x)=n 12 cos(Vx),sin(Vx) , [15]. denotes componen(cid:62)t-wise operations. A∈lsoR, V =[Vx,Vu]
Afteraddingabiasterm,ouruseoffeaturemapisdeﬁned such that V[µ ,u ] =V µ +V u n.
t t x t u t
309
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. Again, we obtain σ2 by following Fubini’s law
t+1
E |
σ2 =(cid:90) [σ2 µ ,Σ ]
t+1 Ext t | t t −E |
+( [µ2 µ ,Σ ] [µ µ ,Σ ]2)
(cid:90) xt t t t xt t t t
= Φ(cid:62)A−1Φ p(x )dx (22)
t t t t
(cid:62) (cid:62) − (cid:62)
+ Φ w¯w¯ Φ p(x )dx (w¯ q)2,
t t t t
E |
where [µ µ ,Σ(cid:18) ]2 fo(cid:90)llows Eq.(20). T(cid:19)he desired pre-
xt t t t
dicted variance σ2 with uncertain input x is
t+1 t Fig. 1: Exploiting moment-matching with GP and LGM-
(cid:90)
− (cid:62) FF and corresponding computational cost. Bottom-right:
σ2 =tr A 1 Φ Φ p(x )dx
t+1 t t t t state distribution at time state t. Upper-right: probabilistic
(cid:62)(cid:124) (cid:62)(cid:123)(cid:122) (cid:125) − dynamics learned from observed samples (black cross), with
+w¯ Φ Φ p(x )dx w¯ µ2 (23)
(cid:0) (cid:1)t t t t t+1 corresponding variance (shade). Upper-left: true predictive
distributions (shade) and its’ approximated Gaussian distri-
:=Q
− (cid:62) − butions (line).
=tr A 1Q +w¯ Qw¯ µ2 .
t+1
Theinnerproductsre-arrangedtopullexpressionsthatare
(cid:90) ∈R × TABLEI:KL-divergencebetweenpredictivedistributionsof
independent to x in the integrals. Q M M is given by
t   moment-matching with LGM-FF and GPs with correspond-
(cid:62)
1 q˜ ing mean and variance.
(cid:62)
Q= Φ Φ p(x )dx = CC CS , (24)
t t t t q˜ (cid:62) LGM-FF
CS SS GPs
M=3 M=5 M=9
∈R ×
where CC,CS,SS n n are calculated by Eq.(28-30). mean 0.2637 0.2616 0.2600 0.2634
The moment-matching prediction summarized as follow variance 0.2333 0.2269 0.2250 0.2347
(cid:62) KL-divergence 0 0.0008 0.0014 0.0004
µ =fµ(cid:0)(µ ,Σ(cid:1),u )=w¯ q, (25)
t+1 t t t
σ2 =fσ(µ ,Σ ,u ,µ )
t+1 −t t t (cid:62)t+1 − (26)
=tr A 1Q +w¯ Qw¯ µ2 . experiments, cost functions are deﬁned as follow:
t+1
− (cid:107) − (cid:107) (cid:107) (cid:107)
Bothw¯ andA 1arepre-calculatedinthetrainingstageby (cid:96)(xt,ut)=kFsKsref st 2+ku ut 1 (27)
Eq.(18).Thus,thecomputationalcostofexploitingmoment-
s = (x )
O ∈ t t
matching with LGM-FF is (M2) in calculating Q
RM×M, i.e., independent to training sample size N. It wheresref isthereferencetargetpositionintaskspace;st is
the end-effector position of the arm calculated via forward
results in a semi-constant time consumption in predictions FK
throughout all time steps, regardless of the growth of the kinematics . The weight variables are set as ks = 1.0
training sample size. and ku =0.0.
All computation are done by a computer with specs: Intel
Asingledimensionpredictiontaskshowstheperformance
Core i9-9900K, 64GB RAM, Nvidia GTX1060 graphics.
comparison of exploitingmoment-matching of standard GPs
and LGM-FF. Focusing on prediction accuracy of LGM-FF
A. Simulation Experiments
with various numbers of total features, M = [3,5,9]. All
We setup a simple two-DoF(Degrees of Freedom) arm
four models learn the system dynamics from 50 samples
to demonstrate the raw performance difference between our
drawn from an underlying linear function with noise, Figure
N approach (SCP-MPC) and SPMPC [7].
1. Given a probabilistic state-input x˜ = (µ = 0.2,σ2 =
0.22),weobtainfourstatepredictionstbyexploittingmomtent- 1) DetailsofTestBenchSetup: Thek-DoFarmsimulator
matching on each model. Estimated by KL-divergence, is constructed with k actuators and the ﬁrst actuator ﬁxed at
moment-matchingwithLGM-FFaccuratelyapproximatesits theorigin.Allactuatorsarelinkedtogetherbykbarsinsame
GPs counterpart with limited numbers of features, Table I. plane, with total length l and each bar length l/k. The goal
is to bring the arm tip to target position by MPC.
This shows the computation-efﬁcient nature of the moment- (cid:2) (cid:3) (cid:2) (cid:3)
Due to periodic behavior of rotation, we deﬁne the state
matching scheme with LGM-FF.
with the complex representation of angular position as
(cid:62)
x = sin(Θ ),cos(Θ ) , where Θ = θ ,...,θ
IV. EXPERIMENTRESULTS (cid:2)t t (cid:3) t (cid:2) t 1(cid:3),t k,t
and Θ is directly observed by the actuator encoder feed-
t
Inthissection,wefocusoncomparingtheperformanceof back. The corresponding control signal is deﬁned as U =
(cid:62) t
SCP-MPCwithSPMPC[7]insimulation.Wefurtherextend sin(u ),cos(u ) , where u = u ,...,u . θ and
t t t 1,t k,t i,t
SCP-MPC to real-time tracking with a real robot. In both u denotes the angular position and MPC control signal
i,t
310
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. Numbers of Rollout Step:1 10 20 30 40 50
Numbers of Trial:Random 1 2 3 4 5 6 7 8 9 10
 SPMPC   SCP-MPC 
2 2
os 0 0
p
y 
Fig. 2: Average time consumption to train the system dy-
namics model (left) and MPC control sequence planning in
each step (right). -2 -2
-2 0 2 -2 0 2
x pos x pos
4  SPMPC 
Size Cost) 2
Sample 50 nce to Target ( 04 0.5 1 5 15 100 SCP-M2P5C0 
Cost)mple Size500 Dista 02 0.5 1 5 15 100 250
t (Sa Time (seconds in log scale)
e
rg Fig.4:(Upper)PathofeachtrialofRLwithMPCandinitial
ance to TaSample SizeSample Size5001000 rteaaannccdheotmtroiatsla.armGgepratleyre-sggceaanrldeeirnargetipntrigemsteernicatolpn(osbusltmaucrpketsiopinant.htC)h.oel(oﬁLrnosawrleetprr)riaeDls.eins-t
t
s
Di
e
z
mple Si2000 tion of the SCP-MPC stays semi-constant regardless of the
a trainingsamplesize,Fig.2.Oppositely,theSPMPCseverely
S
suffers from the larger training sample size.
SCP-MPC
b) MPC performance comparison: Focusing on the
SPMPC
0 10 20 30 40 50 performance of accomplishing assigned task between SCP-
Numbers of Rollout Steps
MPC and SPMPC with various sample sizes pre-trained
Fig. 3: The comparison of MPC performance with various dynamics model. The the SCP-MPC results in comparative
sample size pre-trained system dynamics (10 trials). Color performance to SPMPC, but outperformed in computational
gradients represent steps in each rollout. cost, Fig. 3.
3) RL Performance Comparison: Both SCP-MPC and
SPMPCfollowAlgorithm1,tolearnthetargetreachingtask
from scratch. Figure. 4 shows that both systems starts to
(angular position translation) for ith actuator at time step t. converge since the second trial, where SCP-MPC out-stands
For each element in x , a latent GPs model f (x ,U ) is in semi-constant time consumption. The result shows that,
t a t t
trained to predict corresponding element in x . in simulation, the SCP-MPC results in a similar behavior to
t+1
Experimentvairablesissetasfollowed:two-DoFarm,k = the SPMPC, but with a much lower computational cost.
2.RolloutforeachtrialL =50.MPCpredictionhori-
zon H =3. Constraints orfolcloounttrol signal u ∈[−10,10]◦. B. Real Robot Experiments
k,t
Total length of k-DoF arm l = 2. Initial position: θ = 0 In this section, we apply SCP-MPC to the real-time
◦ i,1 ◦
for all i = 1,...,k. Target position: (lcos170 ,lsin170 ). trackingmovingtargetbyRLwithhigh-frequencyMPCtask
Number of features M =161. on a real robot.
2) MPCRawPerformanceComparison: Wecomparethe 1) Environmental Setup: We set up a two-DoF robot
rawperformanceofMPCpredictionbetweenSCP-MPCand arm identical to simulation environment with HEBI robotics
SPMPC. The dynamics models are pre-trained with various hardware,Fig.5:two“X8-9”actuatorsandtwo0.325m“X5”
of pre-collected random sample sets, with sample size of links, arm length l = 0.65m. We set 0.2 seconds ﬁxed
[50,100,500,1000,2000]. For each training sample size, we control period, real-time tracking a pattern 8 moving target
run Ntrial =10 trials. with position (0.9lcos(2πt/T), 0.6lsin(4πt/T), at time t
a) ComputationalCost: Inbothsystemdynamicstrain- in seconds. The cycle period is set to T = 30 seconds
ing and MPC control sequence optimizing, time consump- with L = T/0.2 for a full cycle target tracking. The
rollout
311
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. sequence to minimize the tracking error. The target stays
moving during the MPC planning process; therefore, higher
frequencycontrolperiodreturnsbettertrackingperformance,
but sample collected per seconds also increases. The mean
and standard deviation of the tracking error, Fig. 6 and
corresponding tracking trajectory, Fig.7, shows the capabil-
ity of SCP-MPC with high-frequency MPC control in the
real world. At all 250th trails, the SCP-MPC consistently
maintains 0.2 seconds constant control period handling up
to 37500 samples; this shows SCP-MPC is also capable
of learning high complexity models which require a large
training sample size to express its’ dynamics.
Fig. 5: HEBI robotics two-DoF arm setup with translucent
arm tracking trajectory. Green path shows target trajectory.
V. DISCUSSIONSANDFUTUREWORK
A higher frequency control increases the collected sample
per second but reduces the difference between each training
inputandtarget;therefore,itrequiresmoresamplestopuzzle
up the full system dynamics which will severely impact
the computation efﬁciency in conventional MPC approaches
[4,5,7,16].ThisworkpresentsSCP-MPCwhichintroduces
MPC to high-frequency control scenarios based on its’
sample-and-computation-efﬁcient characteristic.
Fig.6:AveragetrackingerrorofHEBItwo-DoFarmineach For the future work, we will compare the performance
trail. Blue zone represents standard deviation. with a similar approach [17], where the author samples the
features from RKS kernel expansion. Also, we will explore
a multi-layer cascade SCP-MPC or expand SCP-MPC to
(cid:2) (cid:3) highercomplexityscenarioswhichrequirealargenumberof
MPC objective is to plan a control sequence that minimize
samples to express its’ full dynamics, for example, legged
the distance (cid:2)between (cid:3)arm tip and the moving target. We
robot locomotion or high-DoF robots.
deﬁnethestateofthesystemasx = sin(cid:2)(Θ ),cos(Θ )(cid:3),Θ˙
(cid:62) t t t t
w(cid:2) here Θt(cid:3)= θ1,t,θ2,t , with corresponding discrete t(cid:62)im∈e A(cid:20)PP(cid:21)ENDIX (cid:20) (cid:21)
angular acceleration control signal u = ∆u ,∆u Math detail of Eq.(24) as follows
− ◦ t 1,t 2,t
10,10 /s. Experiment variables as followed: Initial po-
sition θ ,θ =0, MPC predict horizon H =3, number CC=n−1E [cos(V xt )cos(V xt )(cid:62)|µ ,Σ ]
1,t0 2,t0 xt (cid:20)u (cid:21) (cid:20)u(cid:21) t t (28)
of features M =73 and total trial Ntrial =250. − ◦ t ◦ t
2) SCP-MPC Real-time Tracking: We deﬁne the track- =n 1(G cos(Vsub)+H cos(Vadd)),
ing error as the distance between the arm tip and target − E x x (cid:62)|
CS=n 1 [cos(V t )sin(V t ) µ ,Σ ]
position at each time step. At each time step, the MPC xt (cid:20)u(cid:21) (cid:20)u(cid:21) t t (29)
t t
will observe the target position and plan an optimal control =n−1(−G◦sin(Vsub)+H◦sin(Vadd)),
− E x x (cid:62)|
SS=n 1 [sin(V t )sin(V t ) µ ,Σ ]
xt u u t t (30)
t t
− ◦ − ◦
m) =n 1(G cos(Vsub) H cos(Vadd)),
pos x ( with each element of G,H,Vsub,Vadd ∈Rn×n as follow
− −
Time (s) G =exp( 0.5([V Σ(cid:2)] [V Σ(cid:3)] )2), (31)
ij x t i x t j
−
H =exp( 0.5([V Σ ] +[V Σ ] )2), (32)
ij x (cid:2)t i x t(cid:3)j
m) (cid:62) − (cid:62)
os y ( Visjub =[V[µt,ut](cid:62)]i V[µt,ut](cid:62) j, (33)
p Vadd =[V[µ ,u ] ] + V[µ ,u ] . (34)
ij t t i t t j
Time (s)
REFERENCES
1 4 16 64 250
[1] A. S. Polydoros and L. Nalpantidis, “Survey of model-based rein-
Numbers of Trials
forcement learning: Applications on robotics,” Journal of Intelligent
&RoboticSystems,vol.86,no.2,pp.153–173,2017.
Fig.7:Trackingpositionofxandyaxisateachtrails.Target
[2] C. Rasmussen and C. Williams, Gaussian Processes for Machine
trajectory in black. Learning (Adaptive Computation and Machine Learning). The MIT
Press,2006.
312
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. [3] M.P.DeisenrothandC.E.Rasmussen,“PILCO:AModel-basedand
Data-efﬁcientApproachtoPolicySearch,”inProceedingsofthe28th
International Conference on International Conference on Machine
Learning,pp.465–472,2011.
[4] G.Cao,E.M.Lai,andF.Alam,“GaussianProcessModelPredictive
Control of an Unmanned Quadrotor,” Journal of Intelligent and
RoboticSystems,vol.88,no.1,pp.147–162,2017.
[5] S. Kamthe and M. P. Deisenroth, “Data-Efﬁcient Reinforcement
LearningwithProbabilisticModelPredictiveControl,”inInternational
ConferenceonArtiﬁcialIntelligenceandStatistics,vol.84,pp.1701–
1710,2018.
[6] L.HewingandM.N.Zeilinger,“CautiousModelPredictiveControl
using Gaussian Process Regression,” CoRR, vol. abs/1705.10702,
2017.
[7] Y. Cui, S. Osaki, and T. Matsubara, “Reinforcement Learning Boat
Autopilot: Sample-efﬁcient and Model Predictive Control-based Ap-
proach,” in 2019 IEEE/RSJ International Conference on Intelligent
RobotsandSystems,pp.2868–2875,2019.
[8] M. P. Deisenroth, M. F. Huber, and U. D. Hanebeck, “Analytic
Moment-basedGaussianProcessFiltering,”inProceedingsofthe26th
AnnualInternationalConferenceonMachineLearning,pp.225–232,
2009.
[9] M. P. Deisenroth, Efﬁcient reinforcement learning using Gaussian
processes. KITScientiﬁcPublishing,2010.
[10] A. Rahimi and B. Recht, “Random Features for Large-Scale Kernel
Machines,” in Proceedings of the Advances in Neural Information
ProcessingSystems20,pp.1177–1184,2008.
[11] Q. Le, T. Sarlós, and A. Smola, “Fastfood: Approximating Kernel
Expansions in Loglinear Time,” in Proceedings of the 30th Interna-
tionalConferenceonInternationalConferenceonMachineLearning
-Volume28,pp.244–252,2013.
[12] C.K.I.Williams,“PredictionwithGaussianProcesses:FromLinear
RegressiontoLinearPredictionandBeyond,”inLearninginGraph-
icalModels,pp.599–621,SpringerNetherlands,1998.
[13] C.M.Bishop,PatternRecognitionandMachineLearning. Springer,
2006.
[14] J.Nocedal,“SequentialQuadraticProgramming,”inNumericalOpti-
mization,pp.529–562,SpringerNewYork,2006.
[15] Z.Yang,A.Wilson,A.Smola,andL.Song,“AlaCarte–Learning
FastKernels,”inProceedingsoftheEighteenthInternationalConfer-
enceonArtiﬁcialIntelligenceandStatistics,pp.1098–1106,2015.
[16] A. S. K. Annamalai, R. Sutton, C. Yang, P. Culverhouse, and
S. Sharma, “Robust Adaptive Control of an Uninhabited Surface
Vehicle,” Journal of Intelligent & Robotic Systems, vol. 78, no. 2,
pp.319–338,2015.
[17] Y. Pan, X. Yan, E. A. Theodorou, and B. Boots, “Prediction under
UncertaintyinSparseSpectrumGaussianProcesseswithApplications
to Filtering and Control,” in Proceedings of the 34th International
ConferenceonMachineLearning,vol.70,pp.2760–2768,2017.
313
Authorized licensed use limited to: University of New South Wales. Downloaded on September 19,2020 at 11:20:13 UTC from IEEE Xplore.  Restrictions apply. 