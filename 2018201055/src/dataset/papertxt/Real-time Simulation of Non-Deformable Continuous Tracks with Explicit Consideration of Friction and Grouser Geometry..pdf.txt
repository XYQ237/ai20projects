2020 IEEE International Conference on Robotics and Automation  (ICRA)  
31 May - 31 August, 2020. Paris, France
A Fast Marching Gradient Sampling Strategy                                                    
for Motion Planning using an Informed Certificate Set 
Shenglei Shi, Jiankui Chen and Youlun Xiong 
  Abstract—We  present  a  novel  fast  marching  gradient  planning  algorithms.  Accordingly,  the  design  of  faster 
sampling  strategy  to  accelerate  the  convergence  speed  of  collision  checking  module  to  realize  rapid  convergence 
sampling-based motion planning algorithms. This strategy is  algorithms has emerged as a central topic in robotic motion 
based on an informed certificate set which consists of the robot  planning. Janson et al. [5] applied a lazy collision checking 
states with exact collision status as well as the minimum distance  module in the local planning process. That is, the algorithm 
and the gradient to the nearest obstacle. The informed certificate  ignores the presence of obstacles to virtually connect a new 
set covers almost the whole planning space such that it contains  sample to its neighbor nodes, and then truly connect the 
rich information for the planner. The best quality point in this  optimal collision-free local path. The similar lazy collision 
set is selected as the marching seed to guide the search graph  checking idea is also adopted in a candidate graph that allows 
move  steadily  to  the  goal  set.  The  distance  and  gradient 
the  existence  of  in-collision  edges  [6].  For  problems  to 
information of the marching seed helps to generate a new sample 
minimize the path length in Euclidean space, Gammell et al. 
with almost sure collision status. When a feasible solution has 
[7] show that the solution quality can only be improved by 
been found, this set can construct the restricted subset that can 
directly sampling a prolate hyper-ellipsoid subset. Pan and 
improve current path quality. This marching gradient sampling 
Manocha [8] utilized the k-nearest neighbors of a new sample 
strategy is applied to the RRT and RRT* algorithms. Simulation 
to predict its collision probability. Bialkowski et al. [9] stored 
experiments  demonstrate  that  the  convergence  speed  to  a 
additional information, a lower bound on a sample’s minimum 
feasible solution or to the optimal solution is almost twice faster 
than that of the safety certificate algorithms.  distance  to  the  obstacles,  to  the  data  structure.  This 
information is called safety certificate such that when a new 
I.  INTRODUCTION  sample is located within a safety certificate region of an old 
point, it’s collision-free. Finally, rapid convergence property 
Probabilistic sampling-based algorithms have been shown 
can also be achieved through other techniques. Otte and 
as a particularly successful approach to high-dimensional 
Correll  [10]  adopted  a  parallelization  framework  for 
robot  motion  planning  problems.  The  most  popular 
sampling-based  motion  planning  algorithms.  Message 
algorithms are PRM (Probabilistic roadmap) [1], [2] and RRT 
passing,  best  solution  sharing,  and  admissible  subset 
(Rapidly  exploring  random  tree)  [3].  However,  both 
restricting  are  particular  techniques  to  increase  the 
algorithms are only probabilistic complete that the probability 
convergence speed and the solution quality. For in-time online 
of the planner fails to find a solution, if one exists, decays to 
problems, Karaman et al. [11] proposed an anytime motion 
zero as the number of samples approaches infinity. Recently, 
planning framework to improve the practical performance. 
Karaman and Frazzoli [4] showed how asymptotic optimality 
can also be achieved with these methods and proposed the  In this paper, we place a stronger requirement on the 
PRM* and RRT* algorithms.  collision-checking procedure and assume that it returns the 
safety certificate as well as the gradient to leave away from the 
These algorithms randomly sample robot configurations in 
nearest obstacle. We fully exploited the capabilities of this 
the collision-free space, then connect them with local planning 
informed  certificate  set  in  addition  to  its  fast  collision 
method to obtain a graph data structure. The collision-free 
checking characteristic. We find this set can guide the search 
samples  generation  and  local  planning  are  enabled  by  a 
graph grow in a marching way to move steadily and quickly to 
“Boolean BlackBox” collision checking module. Hence, the 
the  goal  set.  In  most  sampling-based  motion  planning 
basic  components  in  sampling-based  motion  planning 
algorithms, the in-collision samples are always discarded. If 
algorithms include: (1) a sampling strategy to generate a 
given the gradient information, the in-collision samples can be 
sequence of points in the free configuration space; (2) a local 
flicked to valid collision-free samples. 
planning  method  to  return  a  path  between  two  given 
configurations; (3) a collision-checking module to determine 
the collision status of a sample point or a local path.  II.  FUNDAMENTALS AND MOTIVATIONS 
Collision checking is widely considered to be the most  The sampling-based motion planning problem definition 
expensive computation bottleneck in sampling-based motion  and the safety certificate method are introduced first. Then we 
will briefly explain why this certificate set is very informed to 
 
guide the search graph grow in a marching way, and how the 
S. Shi, J. Chen and Y. Xiong are with the State Key Laboratory of Digital 
gradient information assists fast motion planning.  
Manufacturing Equipment and Technology, School of Mechanical Science 
and Engineering, Huazhong University of Science and Technology, 1037 
Let X=[0,1]d  denote the configuration space, where the 
Luoyu Road, Wuhan, 430074, P.R. China (e-mail: shshlei@hust.edu.cn; 
Chenjk@hust.edu.cn; famt@hust.edu.cn).  dimension, d, is an integer larger than or equal to two. Each
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 1163
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply.    
point in this space represents a configuration x, and this space 
can be partitioned into two regions: collision-free region 
X and  in-collision  region X .  The  motion  planning 
free obs
problem is denoted by a triplet (X ,x,X ), where x is the 
free s goal s
starting  collision-free  configuration,  and  X is  an  open 
goal
subset of X . The planner seeks a collision-free feasible path   
free
:[0,1]d, that (0)x,(1)cl(X )and )X  for all  Fig. 1: In the early stage of the motion planning algorithms the 
s goal free
(0,1) wherecl()is the closure of a set. The sampling-based  set S always contains much more exploration information 
free
motion planners usually use a random sampling sequence to  than V. Sampling around the marching seed (the best quality 
return  a  graph  in  which  the  path  can  be  searched.  Let  point inS ) helps the exploring tree grow quickly to the goal 
free
G(V,E)denote the output of the algorithm, where Gis the  setX , while the traditional random sampling explores the 
goal
graph defined by a set of nodesVXfree and the set of edges  unreached space and enrichesS . 
free
between them EVV . 
to determine reserve or discard; (2) the optimization-based 
Bialkowski, et al. [9] defined a five-tuple augmented 
motion planning algorithms are “try-correct” framework, i.e., 
graph  AG(V,E,Sfree,Sobs,Dist)  to  store  additional  data  to  given a configuration of the robot then the algorithm uses the 
realize  the  safety  certificate  method.  S X ,S X   interactive information (e.g., distance and gradient) with the 
free free obs obs
denote the sets of points with exact collision status checked by  environment to improve current performance. In practical 
normal  method.  The  map Dist:S S  stores  the  applications, the correct procedure is more efficient to let the 
free obs 0 algorithm converge to a feasible solution or to the optimal 
distance to the obstacles for points in S or to the free space 
free solution with respect to a given cost functional. 
for  points  in S .  The  dataset (S ,S ,Dist) constructs  a 
obs free obs
certificate region, when new samples are generated in this  III.   MARCHING GRADIENT SAMPLING STRATEGY 
region, its collision status is well-known. Hence, this method 
reduces the normal expensive collision checking numbers.  In  this  section,  we  present  the  basic  version  of  the 
marching  gradient  sampling  strategy:  that  in  which  the 
The certificate method builds up a knowledgeable data set  gradient information is obtained in the configuration space. 
(S ,S ,Dist)in addition to the search graph (V,E). Here, we 
free obs
present a sampling strategy that guide the search graph grow  A.  Notations and Symbols 
in a marching way to move steadily to the goal set X . In the 
goal The symbols,and denote the logic operations AND, 
early  stage  of  the  motion  planning  algorithms  a  random  OR, and INVERT. The functionCost(x,x)returns the cost of 
sample usually fails to be added to V but will be added to 
the optimal path in (V,E)that starts from the node x  and 
S or S because of the local planning characteristic. If a 
free obs reachesx, while if eitherxorx is not inV  then the cost is 
random sample is far away from the graph (V,E) it will be  infinity. The function MinCost(x,S)returns two tuples(c,x)of 
pulled close to (V,E). If the local path is in collision the new  the minimum cost fromxto the point set S{x,x , ,x}and 
1 2 n
pulled point is not added to V either. Hence, the free set Sfreeor  the  corresponding  optimal  point  xS .  The  functions 
in-collision set Sobscontains exploratory information for V,  LineCost(x,x) and MinLineCost(x,S) have  similar  meanings, 
where  the  exploration  performance  is  the  core  of  except that the cost is calculated without considering the 
sampling-based motion planning algorithms. We define the  obstacles and the restriction in(V,E). 
point x in S or S that is closest to X as the marching 
free obs goal
seed. Then sampling around the marching seed will guide the  B.  Marching Gradient Feasible Sampling 
graph (V,E) move steadily to X as shown in Fig. 1. The 
goal The primitive subroutines, including the Sampling process, 
conventional random sampling strategy is still adopted to 
Nearest neighbor, k-Nearest neighbors, Near neighbors, and 
increase the exploration ability of the overall algorithm. 
Steering, are all the same as in [4]. Here, we just present the 
The gradient information is motivated by the optimization  different additional data structure and primitive subroutines. 
algorithms for motion planning in [12], [13], as it has the 
characteristic  to  “flick”  the  in-collision  samples  quickly.  1) Data Structure: LetAG(V,E,S ,S ,Dist,Grad)represent 
free obs
Given a point xX  (even if it’s in X ), the corresponding  the  6-tuple  augmented  graph, V,E,S ,S and Dist are  the 
obs free obs
gradient g to leave away from the nearest obstacle, and a new  same  as  in  [9].  The  map  Grad:S S d  stores  the 
free obs
sample x near x and  along  the  direction  g.  Then  it’s 
gradient information to leave away from the nearest obstacle. 
reasonably certain that the new sample xhas better collision 
V and E are initialized according to a particular algorithm 
properties than x . Comparing the sampling-based motion 
(e.g., RRT), S and S are initialized as empty sets. And for 
planning  algorithms  with  the  optimization-based  motion  free obs
planning algorithms, we can find that: (1) the sampling-based  convenience, we assume the augmented data structure AG can 
motion planning algorithms are “try-check” framework, i.e.,  be accessed directly and do not list it as an input for the 
sample a configuration randomly and check its collision status  algorithms presented in this paper.  
1164
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply.    
2) Set Source Indicator: The subroutineI(i){0,1,2}returns 
an  indicator  random  variable  for  the  event  that  how  to 
generate  the ith sample. Specifically, (a) if I(i)0 the ith 
sample is generated by the traditional sampling strategy used 
by a particular motion planning algorithm; (b) ifI(i)1the ith 
sample is generated by using the information in  S ; (c) 
free
if I(i)2 , the process is same as in (b) except that  S is 
free
replaced by S . A practical method is: 
obs  
I(i)MaxIndexrand(),i *rand(),i *rand()     (1)  Fig. 2: Given a robot configuration x, the minimum distance d 
f o and the gradient g to the nearest obstacle. The random state 
whererand()generates a uniformly distributed random variable  xis generated by moving x along a random directiongwith 
in [0，1], if,ioare weighting factors that determine how often  random step length s, wheregTg0and the step length s is 
the setsSfreeandSobsshould be exploited, and MaxIndex returns  restricted insmin,smax. 
the index of the maximum value. 
Algorithm 1: MarchingGradientSample(i ,i ) 
3)Marching seed: If the indicator variableI(i)is one or two,  i f o
then the ith sample is generated according to the point x in  1  II(i); 
best
Sfreeor Sobsthat has the best quality with respect to Xgoal. And a  2  if  I0 then return Samplei. 
particular quality metric is the distance:  3  else if I1 then 
4       x NearestS ,X ; 
x Nearest(S,X )                (2)  nearest free goal
best i goal 5       dDist(x ); gGrad(x ); 
nearest nearest
where  Si is Sfree or Sobs .  Intuitively,  sampling  around xbest  6       s 0.9*d, s d; 
min max
(Algorithm lines 1.4, 1.9 and Fig. 1(a)) will guide the search 
7       return GradientSample(x ,g,s ,s ). 
graph move steadily to the goal setX .  nearest min max
goal 8  else if I2 then 
4) Random direction generator: Given a unit vectorgd ,  9       x NearestS ,X ; 
nearest obs goal
the function SampleDirection:ggdreturns a random unit  10       dDist(x ); gGrad(x ); 
nearest nearest
vectorgthat has the propertygTg0.  11       s 1.1*d, s 2*d; 
min max
5) Gradient guided sample generator: Given a point x in  12       return GradientSample(x ,g,s ,s ). 
nearest min max
S S , the corresponding gradient g to the obstacle, and 
free obs
C. Marching Gradient Informed Optimal Sampling 
define  the  shortest  and  the  longest  moving  step  length 
s ands , respectively. The function GradientSample: (x,g,  If a feasible path has been found, i.e., a samplex X has 
min max g goal
s ,s )x returns a new pointxin the configuration space:  been added to V, let c denote the path cost. Given xX , 
min max free
srand(smin,smax)            (3)  let f(x)denote the cost of the optimal path fromxs to Xgoalthat 
xxs*SampleDirection(g) passes x, then the subsetX X that can improve current 
f free
where s is a random variable uniformly distributed between  found path can be expressed in terms of c: 
[smin,smax]. The determination ofsmin,smaxcan be: (1) ifxSfree,  Xf xXfree | f(x)c            (4) 
s 0.9*d,s d ; (2) if xS ,  s 1.1 *d , s 2*d , 
min max obs min max The expression of f(x)is usually unknown for most motion 
where d=Dist(x) .  Obviously,  if xSfree the  new  generated  planning problems, hence a lower bound approximation is a 
sample is collision-free. While if  xS the new sample’s  common  used  technique.  If  the  planning  space  is  the 
obs
collision status needs to be checked exactly. Fig. 2 shows the  Euclidean space, the approximation f(x) xx  xx is 
s g
gradient sample region. 
used in [7] to construct the informed hyper-ellipsoid subset. 
6)  Marching  Gradient  Sampling:  The  marching  gradient  That is, a direct line is connected between two configurations 
sampling sub-algorithm is shown in Algorithm 1, where the  without  considering  the  obstacles.  As  stated  in  [7],  the 
input i  and i are the weighting factors used in (1). The  probability of sampling a point in X approaches zero as the 
f o f
subroutine  Sample is  the  traditional  sampling  process.  found path approaches the optimal path, hence the traditional 
i
Algorithm 1 is a combination of the above subroutines. The  optimal  sampling-based  motion  planning  algorithms  have 
random indicatorIi, the random direction generator and the  slow  convergence  speed.  In  this  subsection,  we  use 
random gradient bias function (3) maintain the exploration  (Sfree,Sobs,Dist,Grad) to improve the sampling property, extend 
capability  of  the  motion  planning  algorithms.  And  the  the  informed  subset  method  to  non-Euclidean  space  and 
marching seed (2) makes full use of the exploitation ability of  increase the convergence speed to the optimal path. 
current obtained information. This sampling process reduces  The  certificate  region  constructed  by (S ,Dist) almost 
free
the collision checking numbers evidently.  covers the free space as the nodes number approaches infinity. 
1165
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply.    
Algorithm 2: Branch-and-Bound(S,c) 
i
1 while xPickNext(S)do 
i
2     if xV then 
3         if Costx,xLineCostx,x cthen 
s g
4             S S \x; 
i i
5     else if LineCostx,xLineCostx,x cthen 
s g
6         S S \x. 
i i
7 end 
   
Fig. 3: After the Branch-and-Bound algorithm the certificate 
Algorithm 3: x InformedBest(S) 
region of set S covers most of the space that can improve  best
free 1  S ; 
current path quality. (a) Calculating the convex hull of Sfreeand  2  ra1tio0, num0; 
expanding it by an adaptive factor, then the generated convex  3  c, x ; 
set has high probability to improve current path quality. (b)  best
4  while xPickNext(S)do 
Random sampling a point (the blue point) in Sfree, and using  5      if xV then 
the best quality point (the green point) near it as the marching  6          ratioratio+Costx,x/LineCostx,x; 
s s
seed to guide the exploration.  7          numnum1; 
And the left un-covered region is around the boundaries of the  8          if Costx,xLineCostx,x cthen 
s g
obstacles  [9].  Therefore, the set  S contains much more  9              cCostx,xLineCostx,x ; 
free s g
exploration information than V, and the cardinality of S is  10              x x; 
free best
much less than that of V as the planner tries to find the optimal  11          end 
12      else 
path. The branch and bound algorithm shown in Algorithm 2 
13          S S {x}; 
can increase the superiority of S furtherly. In Algorithm  1 1
free 14  end 
2,Si  denotes Sfreeor Sobs, c is the cost of current found path,  15  if num>0 then 
PickNext() takes out a point from the set in order. As we can  16      ratioratio/num; 
see, the Algorithm 2 deletes the unnecessary nodes in S for  17  else 
free 18      ratio1; 
finding the optimal path while maintaining the exploration 
19  while xPickNext(S)do 
ability. And the steps 2.2-2.5 never occurs forS .  1
obs 20      if ratio*LineCostx,xLineCostx,x cthen 
After the Branch-and-Bound algorithm, the points in set  s g
S andS contain the information that can almost improve  21          cratio*LineCostxs,xLineCostx,xg; 
free obs
current  path  quality.  Therefore,  the  marching  gradient  22          xbestx. 
23      end 
informed optimal sampling strategy proposed in this paper is 
24  end 
also a combination of traditional random sampling method, 
 
sampling according to S and sampling according to S . 
free obs Algorithm 4: MGInformedSample(i ,i,r) 
The traditional sampling method fully explores the space,  i f o
1  II(i); 
increases  the  nodes  number  in  S and  makes  S more 
free free 2  if  I0 then 
knowledgeable. While sampling according to Sobsexplores the  3      return UniformeSample expconv(S ). 
i free
information around the obstacles in the sense that the optimal  4  else if I1 then 
path always has small clearance to the obstacles. At last,  5      xUniformeSample(S ); 
free
sampling according to Sfreemakes the algorithm informed to  6      S Near(S ,x,r); 
near free
reduce the path cost quickly.  7      x InformedBest(S ); 
best near
Similar to the informed hyper-ellipsoid subset, the random 
8      dDist(x ), gGrad(x ); 
sampling process is restricted to a subspace deduced bySfree.  9      s 0.9*bedst, s d;  best
min max
In this paper, an enlarged convex hull ofSfreeis selected as the  10      return GradientSample(x ,g,s ,s ). 
best min max
random sampling space as shown in Fig. 3(a) and Algorithm  11  else if I2 then 
line 4.3, where the expansion factor is an adaptive variable.  12      xUniformeSample(S ); 
obs
The sampling process according toSobshas a small change, that  13      dDist(x); gGrad(x); 
instead of using the marching seed (2), a uniform sampling  14      s 1.1*d, s 2*d; 
min max
from Sobs (Algorithm line 4.12) is utilized to increase the  15      return GradientSample(xnearest,g,smin,smax). 
probability of improving the current path.  Since the uniform 
sampling can improve the whole path quality not just a small  in detail how to generate a sample according toS  that can 
free
segment nearX . In the following, we will show the method  improve the path quality in a marching way. 
goal
1166
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply.    
Algorithm 5: Modified RRT   Algorithm 6: Modified RRT* 
1  V{x};E;S ;S ;S ;  1  V{x};E;S ;S ;S ; 
s free obs goal s free obs goal
2  for i1,2, ,n do  2  issolvedFalse; isoptimalFalse; cgoal; 
3      (x ,I)MarchingGradientSample ;  3  for i1,2, ,ndo 
rand i
4      if I1  CollisionFreePoint(x )then  4      if issolvedthen 
rand
5          if xrandXgoal then  5          (xrand,I)MarchingGradientSamplei; 
6      else 
6              S S {x }; 
goal goal rand 7          (x ,I)MGInformedSample ; 
7         xnearestNearest(V,E),xrand;  8          (c,raxnd)MinLineCostx ,Si ; 
8         x Steer(x ,x );  g rand goal
new nearest rand 9          if LineCostx,x ccgoalthen 
9          if CollisionFreePath(x ,x ) then  s rand
nearest new 10              Continue; 
10              VV xnew; EE {xnearest,xnew};   11      if I1  CollisionFreePoint(x )then 
11              (c,xg)MinLineCostxnew,Xgoal;  12          if x X  then  rand
rand goal
12              if c  CollisionFreePath(xnew,xg) then  13              S S {x }; 
goal goal rand
13                  VV xg; EE {xnew,xg};  14          x Nearest(V,E),x ; 
nearest rand
14                  break.  15          x Steer(x ,x ); 
15      end  new nearest rand
16  end  16          if CollisionFreePath(xnearest,xnew) then 
17              MinCostConnection(x ); Rewire(x ); 
new new
We will first describe the Algorithm 3: InformedBest.  18              if issolvedthen 
Given  a  subset  SS ,  InformedBest  finds  the  most  19                  (c,x )MinLineCostx ,S ; 
free g new goal
informed point  x in S that can improve the current path  20                  if c  CollisionFreePath(x ,x ) then 
best new g
quality in the fastest way. Specifically, x is the point that  21                      VV x ; EE {x ,x }; 
best g new g
has  the  smallest  cost  value  in  terms  of  Cost(x,x)Line-  22                      issolvedTrue; 
s
Cost(x,xg)for all xS, as shown in Algorithm lines 3.8-3.11.  23                      cgoalCost(xs,xg);  
Nevertheless,  for  a  point xS V ,  there  is  not  the  cost  24                      Branch-and-Bound(Sfree,cgoal); 
functionCost(x,x). Hence, an approximation (Algorithm lines  25                      Branch-and-Bound (Sobs,cgoal); 
s
3.6-3.7, 3.15-3.24) is calculated according to the main idea  26              else if Mod(i,no)=0then 
that the points in a small neighborhood always have similar  27                  cgoalnMinCost(xs,Sgoal); 
characteristics. And this approximation is based the ratio of  28                  if cgoalcgoalnthen 
Cost(x,x) and LineCost(x,x) . Then using the InformedBest  29                      isoptimalTrue;break; 
s s
function,  the  sampling  strategy  according  to  Sfree can  be  30                  else if cgoalcgoalbthen 
constructed in Algorithm lines 4.5-4.7 and is shown in Fig.  31                      cgoalcgoaln  
3(b). A uniform random sample is picked out from Sfreeto  32                      Branch-and-Bound(Sfree,cgoal); 
enhance the algorithm’s exploitation capability. And the most  33                      Branch-and-Bound (Sobs,cgoal). 
informed point is selected from its neighborhood to increase  34  end 
the algorithm’s marching convergence speed. 
IV.  SIMULATION EXPERIMENTS 
D. Examples with RRT and RRT* 
In this section we perform experiments in a simulated 
We now show how the popular sampling-based motion  environment to evaluate the performance of the marching 
planning algorithms, RRT and RRT*, can be modified to use  gradient sampling strategy guided RRT and RRT* algorithms. 
the  marching  gradient  sampling  strategy.  The  modified  Let ALG be a label indicating one of the algorithms, the 
convergence speed to a feasible path or to the optimal path is 
versions of RRT and RRT* are shown in Algorithm 5 and 
compared between the algorithm ALG without and with this 
Algorithm 6, respectively. The Algorithm 1 is used in both 
strategy. We denote the algorithms as ALGc and ALGcmg, 
modified algorithms to find out a feasible path quickly, then 
respectively, where the notation c is the safety certificate 
the Algorithm 4 is applied to the modified RRT* algorithm to 
method and the notation mg is the marching gradient sampling 
increase the convergence speed to the optimal solution. In  strategy. The simulation environment consists of a unit-square 
both algorithms, at line 5.12 and line 6.20 is the largest  workspace  with  470  randomly  placed  convex  polygonal 
moving step length between two configurations. In Algorithm  obstacles (see Fig. 4), and a point robot moves in it without 
6,  at line 6.28 denotes the optimal tolerance, n  at line 6.26  kinematics constraint. One hundred collision-free start state 
o
and goal state pairs are randomly generated in this space to 
is a positive integer that denotes the period of optimal solution 
conduct the simulations, and the start-goal states maintain the 
checking, the function Mod calculates the remainder of a 
constraint x x 0.71. For each problem fifty trials are 
number, and  at line 6.30 is a lower bound of cost decreasing  s g
b performed for both ALGc and ALGcmg algorithms (upon the  
that triggers the branch and bound process. 
1167
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply.    
to generate samples in the subspace that can truly improve 
current path quality and to converge informedly to the optimal 
path. The distance and gradient information helps generate 
samples with almost sure collision status and reduces the 
collision  checking  numbers.  We  used  Monte  Carlo 
simulations to evaluate the performance and convergence 
  speed  of  this  sampling  strategy  upon  RRT  and  RRT* 
Fig. 4: A unit-square with 470 randomly placed obstacles are  algorithms and compared it to the safety certificate strategy. 
designed as the experiment scenario.  The results demonstrate that our sampling strategy is twice 
faster to converge to the feasible path or the optimal path 
while maintaining the same solution quality. 
VI.  ACKNOWLEDGMENT 
The authors wish to acknowledge the support from the 
National Natural Science Foundation of China (Grant NO. 
51975236)  and  the  Program  for  Guangdong  Key  Areas 
 
Research and Development (Grant No. 2019B010924005). 
Fig.  5:  The  solution  computed  by  RRTc  and  RRTcmg 
algorithms. (a) The path cost of the 100 randomly generated 
REFERENCES 
problems. (b) The computation time used by the algorithms. 
[1]  S. M. LaValle, Planning algorithms. Cambridge university press,2006. 
[2]  L. E. Kavraki, P. Svestka, J.-C. Latombe, and M. H. Overmars, 
“Prob-abilistic  roadmaps  for  path  planning  in  high-dimensional 
configurationspaces,” IEEE transactions on Robotics and Automation, 
vol. 12, no. 4,pp. 566–580, 1996. 
[3]   S. M. LaValle and J. J. Kuffner Jr, “Randomized kinodynamic 
plan-ning,”The international journal of robotics research, vol. 20, no. 
5,pp. 378–400, 2001. 
[4]  S.  Karaman  and  E.  Frazzoli,  “Sampling-based  algorithms  for 
  optimalmotion planning,”Int. J. Robot. Res., vol. 30, no. 7, pp. 
Fig. 6: The solution computed by RRTc* and RRTcmg*  846–894,2011. 
[5]  L.  Janson,  E.  Schmerling,  A.  Clark,  and  M.  Pavone,  “Fast 
algorithms. (a) The path cost of the 100 randomly generated 
marchingtree: A fast marching sampling-based method for optimal 
problems. (b) The computation time used by the algorithms  motionplanning in many dimensions,”The International journal of 
roboticsresearch, vol. 34, no. 7, pp. 883–921, 2015. 
[6]  O. Salzman and D. Halperin, “Asymptotically near-optimal rrt forfast, 
hundred pre-defined problems), and the average value denotes 
high-quality motion planning,”IEEE Transactions on Robotics,vol. 32, 
the solution. Simulations are conducted on a 4.20GHz Intel 
no. 3, pp. 473–483, 2016. 
Core i7-7700K CPU with 8GBRAM in MATLAB.  [7]  J.  D.  Gammell,  T.  D.  Barfoot,  and  S.  S.  Srinivasa,  “Informed 
samplingfor asymptotically optimal path planning,”IEEE Transactions 
The feasible/optimal path cost and the computation time of 
onRobotics, vol. 34, no. 4, pp. 966–984, 2018. 
the one hundred problems computed by ALGc and ALGcmg 
[8]  J.  Pan  and  D.  Manocha,  “Fast  probabilistic  collision  checking 
algorithms are shown in Fig. 5 and Fig. 6, respectively. The  forsampling-based  motion  planning  using  locality-sensitive 
problem NO. is sorted by ALGc’s corresponding value in  hashing,”TheInternational Journal of Robotics Research, vol. 35, no. 
ascending order. That is, the problem NO. in different figures  12, pp. 1477–1496, 2016. 
[9]  J.  Bialkowski,  M.  Otte,  S.  Karaman,  and  E.  Frazzoli, 
may be different. Figs. 5(a) and 6(a) show that both algorithms 
“Efficientcollision checking in sampling-based motion planning via 
achieve the same performance in solution quality, and Figs. 
safetycertificates,”The International Journal of Robotics Research, vol. 
5(b) and 6(b) demonstrate that ALGcmg’s computation speed  35,no. 7, pp. 767–796, 2016. 
is near 2x speedup than that of the ALGc algorithm.  [10] M. Otte and N. Correll, “C-forest: Parallel shortest path planning 
withsuperlinear speedup,”IEEE Transactions on Robotics, vol. 29, no. 
3,pp. 798–806, 2013. 
V.  CONCLUSION 
[11]  S.  Karaman,  M.  R.  Walter,  A.  Perez,  E.  Frazzoli,  and  S. 
In this paper, we present a marching gradient sampling  Teller,“Anytime  motion  planning  using  the  rrt,”  in2011  IEEE 
InternationalConference on Robotics and Automation. IEEE, 2011, pp. 
strategy to accelerate the convergence speed of sampling- 
1478–1483. 
based  motion  planning  algorithms.  This  strategy  uses  an  [12] M.  Zucker,  N.  Ratliff,  A.  D.  Dragan,  M.  Pivtoraiko,  M. 
informed  certificate  set  to  solve  both  the  feasible  path  Klingensmith,C. M. Dellin, J. A. Bagnell, and S. S. Srinivasa, “Chomp: 
Covarianthamiltonian  optimization  for  motion  planning,”The 
planning problem and the optimal path planning problem. The 
InternationalJournal of Robotics Research, vol. 32, no. 9-10, pp. 
informed certificate data set contains exact collision status  1164–1193, 2013. 
checked robot states together with the minimum distance and  [13] J. Schulman, Y. Duan, J. Ho, A. Lee, I. Awwal, H. Bradlow, J. Pan,S. 
Patil,  K.  Goldberg,  and  P.  Abbeel,  “Motion  planning  with 
gradient to the nearest obstacle. This data set assists the 
sequentialconvex optimization and convex collision checking,”The 
sampling subroutine in a marching way to converge to a  InternationalJournal  of  Robotics  Research,  vol.  33,  no.  9,  pp. 
feasible path quickly. Then the algorithm utilizes the data set  1251–1270, 2014. 
1168
Authorized licensed use limited to: Carleton University. Downloaded on September 21,2020 at 11:46:43 UTC from IEEE Xplore.  Restrictions apply. 