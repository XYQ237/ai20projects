2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Extracting Legged Locomotion Heuristics with Regularized Predictive Control
Gerardo Bledt1 and Sangbae Kim1
Abstract—Optimization based predictive control is a pow- Offline RPC
erful tool that has improved the ability of legged robots to
execute dynamic maneuvers and traverse increasingly difﬁcult
terrains. However, it is often challenging and unintuitive to
designmeaningfulcostfunctionsandbuildhigh-ﬁdelitymodels
whileadheringtotimingrestrictions.Anovelframeworktoex-
tractanddesignprincipledregularizationheuristicsforlegged Data Driven Analysis
locomotion optimization control is presented. By allowing a
simulation to fully explore the cost space ofﬂine, certain states
and actions can be constrained or isolated. Data is ﬁt with
simple models relating the desired commands, optimal control
actions, and robot states to identify new heuristic candidates.
Basicparameterlearningandadaptationlawsarethenapplied
to the models online. This method extracts simple, but pow-
erful heuristics that can approximate complex dynamics and
account for errors stemming from model simpliﬁcations and
parameter uncertainty without the loss of physical intuition
while generalizing the parameter tuning process. Results on
theMiniCheetahrobotverifytheincreasedcapabilitiesdueto Fig. 1: Data Driven Heuristic Extraction. Methods pre-
the newly extracted heuristics without any modiﬁcation to the sented in this paper improve the robot’s capabilities by
controller structure or gains.
extracting heuristic models from simulated data.
I. INTRODUCTION
Legged robots have the potential to be highly dynamic
MIT Cheetah 2 showed the beneﬁts of both heuristics
machines capable of outperforming humans and animals in
and optimization by injecting heuristic regularization into
locomotiontasksoverirregularanddangerousenvironments.
predictivecontrol.Thisincreasedtherobot’sabilitytoreject
Unfortunately,theyhavenotyetdeliveredonthatpromiseas
disturbances and decreased computation time as well as
they still lack the agility and robustness needed to traverse
frequency of undesirable local minima [11]. The robot was
arbitrary terrains with the same grace as animals. However,
able to stabilize multiple gaits at a variety of different
recentadvancesintheﬁeldareshowingincreasinglyimpres-
velocities and environmental uncertainty using a single cost
sive behaviors and robustness to both external disturbances
function and set of gains across all situations. Further work
and unexpected obstacles.
proved this type of controller to be tractable on the MIT
Heuristic-basedleggedlocomotioncontrolhasshownsuc-
Cheetah 3 quadruped hardware platform [12].
cess in traversing rough terrains, particularly with degraded
Parameter adaptation and automatic tuning is notably dif-
perception. Since experts already have knowledge about
ﬁcult in legged systems because of the rapid, harsh discrete
locomotion,itisoftenabetterchoicetosimplyencodeintel-
mode changes as feet enter and exit stance and swing
ligentheuristicsratherthanleaveittoanoptimizationsolver.
phases. Early work on automatic tuning for robotic systems
Focchiatal.demonstrateaheuristicplanningframeworkon
concluded that because of the discontinuous gradients it
the HyQ robot to overcome uncertain conditions [1].
was best to develop a controller able to move stably before
Whole-body optimization-based controls using a full dy-
employing the parameter tuning [13]. Other work success-
namics model have been successful in both humanoids
fully used evolutionary optimization that did not attempt to
[2], [3] and quadrupeds [4], [5]. Model Predictive Control
approximate gradients to learn to walk [14], while another
(MPC) approaches have been gaining popularity for their
showed an automatic gain tuning method vastly improved
ability use simple control models for prediction, while still
the robot’s performance without tedious hand tuning [15].
achieving good performance [6], [7], [8]. Results on the
Recently, neural networks have shown promising results
MIT Cheetah 3 robot platform using a linear convex MPC
forlearningcontrolpoliciesthroughsimulation.Hwangboet
frameworkdemonstratedhighlydynamic,robustlocomotion
al. show a simulation-based learned policy ported over for
with various gaits [9], [10].
real hardware locomotion [16]. Work from DeepMind has
Regularized Predictive Control (RPC) allows known dy-
showntheabilitytolearntomoveincomplexenvironments
namics and locomotion principles to be exploited through
on various different dynamic systems [17]. However, as is
heuristic regularization. Previous work on a model of the
often a drawback of neural networks, it is not always clear
how to modify speciﬁc policy parameters in order to tune
1Department of Mechanical Engineering, MIT, Cambridge, MA
02139,USA:gbledt@mit.edu, sangbae@mit.edu the behaviors without the need to retrain the entire network.
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 406
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. A. Contributions
0.3
0.9 0.9
The main contribution of the paper is a framework that 0.25 0.8 0.8
0.2 0.7 0.7
provides methods for the extraction of simple legged loco- 0.6 0.6
0.15 0.5 0.5
motion heuristics from robot experience data. The result is 0.1 0.4 0.4
0.3 0.3
autonomousdiscoveryofsimple,butpowerfulregularization 0.05 0.2 0.2
heuristics that improve the performance of the RPC without 0 0.10 0.10
any explicit changes to control gains or controller structure. -0.05-1 -0.5 0 0.5 1 -0.1-1 -0.5 0 0.5 1 -0.1-1 -0.5 0 0.5 1
(a)JD(χ) (b)JR(χ) (c)J(χ)
Each simple heuristic is generalizable, easily tunable, and
Fig. 2: Regularizing Nonlinear Cost Functions. A generic
carries a clear physical meaning. With newly extracted
nonlinear cost function (2a) with multiple local minima is
heuristicsfromusingthisframework,therobotisabletospin
additively regularized with a simple quadratic cost function
in place rapidly at 4rad and turn at 2rad while moving at a
s s (2b).Theresultingcostfunction(2c)capturesasmoothened
highspeedof1.5m.Previously,thesemaneuverswerecould
s nonlinear function with only one minimum.
not be executed stably with the exact same controller. The
heuristics found through the framework are generalizable
andadequateforlocomotionunderunexpecteddisturbances.
(cid:80)
in [11]. Generally it can be written
−
N 1
II. REGULARIZEDPREDICTIVECONTROL min J(χ)= χ˜TW χ˜
k k k
χ
k=0
As opposed to traditional MPC techniques, RPC directly
exploits simple heuristics to simplify complex cost spaces s.t. xk+1 =Akxk+Bkh(≤χk,Φk)+dk
and ﬁnd feasible solutions quickly. Rather than treating the (cid:2) (cid:48) (cid:3) ζk(χk,Φk) 0 ≤
problem of robot locomotion as a black box optimization, ζk(χk,χk+1,Φk,Φk+1) 0
simple physics-based heuristics are encoded into the cost ∀ ∈{ − }
where χ = xT uT T , k 0,...,N 1 are decision
function and constraints to bias the optimization towards k k k
variables and the number of timesteps, N, is user selected.
a sensible solution while remaining free to explore the (cid:48)
Physical feasibility constraints are ζ and ζ as described in
surrounding cost space for the possibility of a better result.
[12], and (cid:20)the gait ph(cid:21)ase is Φ(cid:34)as intro(cid:35)duced i(cid:34)n [18].(cid:35)The
Heuristics for the decis(cid:0)ion variab(cid:1)les, χ, are embedded simpliﬁed discrete dynamics matrices are written
directly into the cost function through error terms
(cid:2) χ˜ =Hχ χ(cid:3),Φ,xd −χ (1) Ak = 0I66 dtIk6I6 Bk = dd2tt2kkII−−11 dk = dd2tt2kkaagg
where the heuristics H are functions of the robot states, whereI istheinertiatensorandag isthegravityvector.The
χ nonlinear inputs ma(cid:20)ke u(cid:21)p the combined forces and torques
x = pT ΘT p˙T Θ˙ T T, desired states, x , and the
d on the CoM as
scheduledgaitphase,Φ,asdeﬁnedin[18].Therobotmodel
ischosentobeasimplelumpedmassmodelwithamassless f(cid:20) (cid:21)
h(χ ,Φ )=(cid:88)B
leg assumption making the states the position of the CoM, k k τ (cid:2) (cid:3)
p, the roll-pitch-yaw Euler Angle CoM orientation, Θ, the 4
I
velocity in the world frame, p˙, and the Euler angle rates, = 3 s f
Θ˙ . Inputs are chosen to be the foot location vectors for i=1 R(Θk)T ri,k × Φ,i,k i,k
(cid:2) (cid:3)
eachfootifromtheCoM,ri,andthecorrespondingground with R(Θ ) being the rotation matrix of the CoM, and
ruea=ctiornTforfcTe, f.i.,.whriTch a(cid:2)freT oTr.dTerhe(cid:3)edcoinmbthineatiinopnuotfvsetcattoesr sstΦat,ei,kde∈pe{n0kde:nstwoinngt,h1e:scchoendtauclet}dbgeaiintgphthaeseboofoleeaacnhcfoonotta.ct
1 1 4 4
and inputs for all predicted timesteps are chosen to be the To demonstrate the effects of regularization, a simple ex-
decision variables, χ = xT uT T. The power of the ample is depicted in Figure 2. The underlying cost function
k k k
RPC framework is that it allows extremely rich information (2a) is chosen to be nonlinear with multiple local minima.
about the robot to be embedded in the optimization with no A quadratic regularization function (2b) is designed to be
modiﬁcation to the controller structure. additive and smooth out the dynamics cost where the result
Theinputsaresolvedforthroughanonlinearoptimization is a well-conditioned combined cost function (2c) with no
using a direct transcription method [19]. The objective is to extraneous local minima. Through regularization, the shape
minimize the quadratic cost function on the deviation from of the cost function is changed without canceling out the
the state and input heuristics. We pose the optimization- original nonlinear function.
based control essentially as a nonlinear MPC that relies AlthoughtheseheuristicsbeneﬁttheRPC,designingthem
heavily on regularization heuristics rather than an accurate in practice is challenging and can be unintuitive. Simply
model or realistic dynamics. In fact, the model has massless adding a regularization function does not improve the op-
legsandalmostcompletelylinearizeddynamicsasdescribed timization problem. In fact, it can often yield detrimental
407
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. We propose a more autonomous method to quickly dis-
covertheserelationships.This paperwillfocusonusingthe
0.9 0.9
0.8 0.8 data gathered from simulations running the RPC ofﬂine in
0.7 0.7 different scenarios. Since the solution times do not need to
0.6 0.6
adheretoanyreal-timeconstraintsofﬂine,thecostspacecan
0.5 0.5
0.4 0.4 be fully explored for nonintuitive local minima and tested
0.3 0.3 forgenerality.Runningthecontrollerinasimulatedenviron-
0.2 0.2 mentalsoallowsrestrictionofcertainstatestoinvestigatethe
0.1 0.1
performance without some of the nonlinear coupling effects
0 0
-0.1 -0.1 that would be present in the real system.
-1 -0.5 0 0.5 1 -1 -0.5 0 0.5 1
(a)BadRegularization (b)GoodRegularization The states, inputs, commands, gait schedule, and combi-
(cid:2) (cid:3)
Fig.3:DesigningRegularizationFunctions.Regularization nations of each from the simulations make up the set
fhuanvcintigonasssighnoiuﬁldcansmt eofofethcttohne tdhyenoamptiicmsalfusnocltuitoinonw. hile not V = xT uT xTd ΦT (p˙×Θ˙ )T t ... T (3)
to be tested as potential functions of each other. Various
simple model ﬁts are applied to the data sets and highly
results.Figure3showshowapoorlydesignedregularization
correlated models are identiﬁed as candidates for a new
function(3a)canpullthecombinedminimumawayfromthe
heuristic policy. These candidates are further analyzed for
underlyingoptimum,whereasawelldesignedregularization
repeatability and compared with the results of the predictive
function(3b)simpliﬁesthesurroundingcostspace,butdoes
optimization to determine if the proposed model is a valid
not affect the optimal solution. The key is to design good
extracted heuristic. The framework computes model ﬁts on
heuristics that meaningfully shape the cost space.
the robot data during simulation where forward, lateral, and
Qualitatively, a heuristic is good if it causes the system
turning rate commands are provided.
to behave as desired when executed. Quantitatively, a set
The ﬁts tested for statistical correlation are polynomial
of heuristics is considered good if the optimal solution of (cid:88)
and sum of sines ﬁts where the model is described as
the underlying function, the heuristic regularization portion,
∈
and combined cost function are all approximately equal to H D [0,9]
each other for all states within the set of desired reasonable Polynomial: vi(vj)= (cid:88) avnivjn (4)
locomotion states written as n=0
∈
D [1,8]
∗ ≈ ∗ ≈ ∗ ∀{ | ∈ } H
χ χ χ , xx X (2) Sum of Sines: (v )= bvisin(cviv +dvi) (5)
R D vi j n n j n
This viable operating space, X, is intentionally deﬁned n=1
vaguely allowing for different desired performance metrics. with D being the degree of polynomial and the number
of summed sine terms respectively for the heuristic model
Forexample,thesetofheuristicsforquasi-staticlocomotion H
may not be adequate for more dynamic movement. What vi(vj) where the dependent variable, vi, is written as a
may be considered failure for one robot, may be perfectly function of the independent variable, vj and both are taken
within reasonable locomotion for another robot. While the from V. These models were deliberately chosen over more
complicated highly nonlinear functions or neural networks
individual parts of the cost function may look very different
becausetheyareeasilytunableandcanprovideintuitionfor
from each other, the optimal solutions for each part should
the underlying physical relationships. It is straightforward
be near each other in most cases.
to determine the effects of varying the parameters of a
III. EXTRACTINGHEURISTICS polynomialorsinewavemodel,whileapproximatinghighly
To design these heuristics, we propose using the frame- nonlinear behaviors.
work described in Figure 4. The framework pairs expert Figure 5 shows an example result for the R2 values for
design with data-driven analysis. Humans provide natural a ﬁrst order polynomial model ﬁt on data gathered from
intuition that algorithms may not ﬁnd as easily. Meanwhile, varying the commanded forward speed of the robot. Similar
computers can analyze large amounts of data and recognize plots were made for the various model ﬁts in (4) and (5). In
patterns automatically that may not be obvious to an expert. thepast,someoftheserelationshipswerediscoveredthrough
The framework seeks to exploit the advantages of each experimental observation and parameters were hand tuned,
method to build the richness of the regularization heuristics but with this framework, the model types and associated
that will be embedded in the robot for better online control. parameters automatically discovered. This simpliﬁes the
Expert design encompasses observing nature and analyzing process, while retaining intuition over the robot control.
simple physics. For example, the notion of vertical impulse
scaling [20], or the widely used capture point [21]. These IV. EVALUATINGHEURISTICS
required experts in the ﬁeld to make clever assumptions and Extracted heuristic models are dependent on the explo-
simpliﬁcations for force generation and footstep placement rationdoneinsimulation,aswellasthechoiceofdependent
in speciﬁc cases. andindependentvariablestotestforcorrelation.Thismeans
408
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. Offline Heuristic Design
Expert Design OOnnlliinnee  RRPPCC
Observing nature Analyzing physics
Data Driven Analysis
Offline RPC
Parameter Learning
Fig.4:HeuristicExtractionFramework.ExpertdesignanddataanalysisfromrunningtheRPCofﬂinebothyieldheuristics
that can be used to inform the controller online. Basic Reinforcement Learning adapts parameters to account for model
inaccuracies and timing discretization delays that prove to be difﬁcult to model.
0.8 0.15
0.6 0.1
0.4 0.05
0.2 0
0 -0.05
-0.2 -0.1
-0.4 -0.15
-0.6 -0.2
-0.8-2 -1.5 -1 -0.5 0 0.5 1 1.5 2 -0.25-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
H H
(a) θ(p˙y) (b) φ(p˙x)
(a)VariableRelationships (b)HeuristicCandidatesR2
Fig. 6: Linear Velocity Induced Orientation. The frame-
Fig. 5: Identifying Heuristic Model Candidates. Model
workidentiﬁedthetendencytowardslinearorientationoffset
ﬁtsarecomputedforeachofthevariablerelationshipsin6a
in pitch and roll with faster forward and lateral trotting.
to identify new heuristic candidates for a subset of V. The
R2 values for a 1st order polynomial ﬁt are seen in 6b.
functionofthegaitphasewithR2 =0.835describedbythe
new heuristic
that while the framework can identify potential candidate
H
modelsbetweentwostates,theydonotnecessarilyrepresent (Φ)=bφsin(cφΦ+dφ)
φ 1 1 1 (8)
meaningful heuristics. It is still necessary to have a knowl-
=0.023sin(12.553Φ+2.999).
edgeableexpertdesignexplorationmethodsanddifferentiate
between models with overﬁtting or false dependencies. The results of which are depicted in Figure 7. Interestingly,
Twoofthestrongercorrelationsfoundwerelineardepen- this matches the intuition for a periodic pitch limit cycle
dencies of roll, θ, on the robot’s lateral velocity, p˙ , and during a trot gait where c = 2πf and the two diagonal
y 1
pitch, φ, based on the forward velocity, p˙ . The ﬁts had pairs of legs perform complementary actions over a single
x ≈
an R2 value of 0.9827 and 0.9533 respectively. These were gait cycle, f =2, giving cφ 12.566.
1
found to be By combining the two extracted heuristics for pitch in
H − equations (7) and (8), we get
(p˙ )=aθp˙ +aθ = 0.339p˙ +0.00027 (6)
θ y 1 y 0 y H H H
H −
φ(p˙x)=aφ1p˙x+aφ0 =0.073p˙x 0.0475 (7) φ(p˙x,Φ)= φ(p˙x)+ φ(Φ) (9)
=a p˙ +a +b sin(c Φ+d ).
and shown in Figure 6 for both cases. The dominant linear 1 x 0 1 1 1
nature of the relationships is clear, although this does not Figure8showsthatalthoughthecommandedrobotspeedis
fully ﬁt the data. 1.5m with no pitch, the robot’s dynamics vary in practice.
s
The same simulations were run again and analyzed, Howeverusingheuristic(9)wecanapproximatethecomplex
but this time new heuristics were discovered. Namely, a dynamics that take place naturally using only the simple
sinusoidal relationship for the periodic pitch behavior as a intuitive models that are easy to modify.
409
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. 0.03
0.02
0.03 0.01
0.02 0
-0.01
0.01 -0.02
-0.03
0
-0.04
-0.01 -0.05
-0.02 -0.060 2 4 6 8 10 12 14 16
-0.03 (a)PitchCompensation (b)LearnedParameterAdaptation
-0.04 Fig. 9: Learned Pitch Compensation Parameters. Both
-0.05 parametersaφandaφarelearnedonlinetosatisfythereward
0 0.2 0.4 0.6 0.8 1 functionand0average1dtobeconstantsintherobot’smemory.
Fig. 7: Periodic Pitch Behavior. The robot exhibits natural (cid:2) (cid:3)
pitch dynamics that are be extracted from simulation data. ± ◦
disappeared with a pitch error of 0.16 0.52 for forward
∈ −
velocities of p˙ 2,2 m. Regardless of the underlying
x s
0.06 cause of the errors, we are able to ﬁnd a simple, easily
0.06
0.05 tunable approximate model to compensate for them.
0.05 0.04
0.03 Thesamemethodwasappliedtoiterativelytobuildtheset
0.04 0.02 ofheuristics,H.Inadditiontothepreviouslydiscussedpitch
0.01
0.03 0 androllcompensationandtheperiodicorientationbehavior,
0
0.02 0.2 heuristics were extracted for foot placement during straight
0.4 1.35 walking,in-placeturning,andhighspeedturning,aswellas
0.01 0.6 1.45 1.4
0.8 1.55 1.5 a curious error where the robot began to dip in height as it
10.35 1.4 1.45 1.5 1.55 1.6 1.65 1 1.65 1.6 movedfaster.TheextractedmodelsarelistedinTableI.Note
Fig. 8: Intuitive Approximation. The dark red shows the that the simplest model was chosen to prevent overﬁtting
despitemanydatasetsalsobeingslightlybetterapproximated
adjusted reference pitch during a steady state trot from the
by higher degree polynomials and larger sum of sines.
simple heuristics and matches closely to the actual pitch of
NewlyextractedheuristicswereaddedtotheRPCinsim-
therobotinorangefromacommanded1.5m forwardspeed.
s ulationtoverifythateachonewouldgeneralizetosituations
other than the exploration in which they were extracted. As
new heuristics are injected into the RPC optimization, the
Since the data was gathered in simulation without real-
(cid:2) (cid:3) (cid:2) (cid:3)
capabilitiesoftherobotincrease.InFigure10therobotwas
time computation restrictions, the parameters used for the
∈
heuristics may often differ on the actual system or even c−ommanded forward and lateral velocitie∈s fr−om (p˙x,p˙y)
on the same simulated model with real-time restrictions in 3.5,3.5 m and turning rates of ψ˙ 4.0,4.0 rad.
s s
place. Therefore, a very simple parameter learning law was Maximum forward and lateral velocities, as well as turning
developed to adjust the valu(cid:13)e(cid:80)s during op(cid:13)eration. A reward rate were all doubled when all models were added.
(cid:13) (cid:13)
function is deﬁned as (cid:13) (cid:13) RPC was implemented on the MIT Cheetah 3 and Mini
− CheetahrobotsusingtheIPOPTsolver[22]inC++withthe
R −
H = (cid:80)(vd vi) (10) optimizationrunningatasituationally-variablefrequencyof
vi Φ
100-200Hz as described in [12]. New behaviors such as the
wheretherobotisrewardedfortrackingthedesiredbehavior
rapid in-place turning and high speed turning which were
summed over a gait period, . The parameter update law
(cid:40) not previously possible when using a na¨ıve optimization are
Φ
for the linear model case is written to be nowabletobeexecutedasseeninFigure11.Whenturning
−∇R | | inplace,thefeetareplacedalongthedirectionoftheturnas
avi =avi − H , v <v
a0v1,,ikk =a0v1,,ikk−11− ∇RvHjvvii ,|vjj|≥vjj,,mmiinn. (11) tthuernrionbgowtiisthgicvoemnmaacnodmsmoafn{dp˙ox,fdψ,˙ψd˙d=} =6.5{ms1..5fmosr,h2irgashd}sp,etehde
This adaptation law was able to successfully learn param- footplacementisdominatedbytheneedtoapplycentrifugal
eters that reduced errors in the robot at runtime as seen in forcesbyplacingthemroughlyoutalongtheturningradius.
Figure 9. Thecontrollergeneralizestohandleunexpectedsituations
as the heuristics bias the optimization towards a solution
V. RESULTS without constraining it, meaning that the optimization can
The exact reason for the velocity induced orientation er- still search for better footstep locations and forces. The
rorsisnotimmediatelyclear,butcanlikelybeacombination controller was tested for robustness by giving the robot an
of various factors including unmodeled dynamics, incor- impulsivepushasseeninFigure12a,aswellascommanded
rectfrictionparameters,timestepdiscretization,optimization to trot forward at p˙ = 1.5m over random debris scattered
d s
solve time, or something we have not thought of. With the over the ground as seen in Figure 12b. In both cases, the
heuristic implemented on the robot, pitch and roll errors robot is able to reject disturbances. More experiment videos
410
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. 3.5 3.5 3.5 3.5 3.5
0.0 0.0 0.0 0.0 0.0
-3.5 -3.5 -3.5 -3.5 -3.5
-3.5 0.0 3.5 -3.5 0.0 3.5 -3.5 0.0 3.5 -3.5 0.0 3.5 -3.5 0.0 3.5
3.5 3.5 3.5 3.5 3.5
0.0 0.0 0.0 0.0 0.0
-3.5 -3.5 -3.5 -3.5 -3.5
-4.5 0.0 4.5 -4.5 0.0 4.5 -4.5 0.0 4.5 -4.5 0.0 4.5 -4.5 0.0 4.5
H H H × H
(a)NoHeuristics (b) r(p˙) (c) r(ψ˙) (d) r(p˙ Θ˙) (e) Θ(p˙,Φ)
Fig. 10: Viable Operating Regions. Each plot from 10a to 10e adds one of the heuristics discussed in the paper. As new
heuristics are discovered and subsequently injected into the optimization, the set of viable operating regions where the robot
is in stable locomotion increases. The dark areas signify where a fall did not occur, but does not qualify the movements.
TABLE I: Extracted Heuristics
Heuristic ExtractedHeuristicModel
H
ForwardStepping Hr(p˙)=ar1p˙+ar0
In-PlaceTurning H ×r(ψ˙)=ar1ψ˙×+ar0
HighSpeedTurning r(pH˙ Θ˙)=ar1(p˙ Θ˙)+ar0
OrientationCompensation H Θ(p˙)=aΘ1 p˙+aΘ0 (a)PushRejection (b)RoughTerrain
PeriodicOrientation HΘ(Φ)=bΘ1 sin(cΘ1 Φ+dΘ1 )
HeightCompensation z(p˙x)=az2p˙2x+az1p˙x+az0. Fig. 12: Robust Locomotion. Heuristics generalize to be
robust to external disturbances and unstructured terrain.
H∗
the heuristic solution. Finding is likely unfeasible, but
H
the proposed method can be used to build the set , and
H∗
better approximate for a large number of cases. This
will take the burden off of the optimization as the initial
guess and regularized solution will be closer to the actual
dynamics-based optimal solution.
(a)In-PlaceTurning (b)HighSpeedTurning
Recentworkhasshowngreatresultsintheareaofrobotic
Fig.11:Improved Performance.Extractedheuristicsallow
learning and is being considered as a possible enhancement
the robot to spin in place at 2πrad (11a) and make high to the framework. However, in this work we argue that it
s
speed turns of 2rad while moving forward at 1.5m (11b). is important to have a good grasp of the physical intuition
s s H
behind the controller. By choosing the set of heuristics, ,
tobebuiltupfromsimplefunctionsasdescribedinthepaper
are shown in the attached video [23]. Results support the
you retain control over important state relationships and
goalofaframeworktosystematicallyimprovesrobotperfor-
haveanawarenessforthecontroller’spossiblestrengthsand
mance by extracting heuristics that approximate unmodeled
weaknesses, while allowing a learning or parameter adapta-
dynamics and compensate errors with simple models.
tion law pick the values of the gains through the robot’s
experience. A policy network may be able to adaptively
VI. CONCLUSION
change which heuristics are active in certain situations and
The results have shown controller performance improved would be worth exploring. The generality of the controller
without any explicit changes to the control gains or the makes it possible to explore a variety of techniques without
H
controller structure. Theoretically, if a set of heuristics, , any major changes to the core robot control architecture.
∗ ∗ ∗ ∀{ | ∈ }
is found where χ = χ = χ , xx X rather
than the approximRate equaDtion (2), then these heuristics ACKNOWLEDGMENTS
H H∗
are the solution to the optimization, = , for all This work was supported by the Toyota Research Insti-
of the viable operating conditions, X. This then implies tute, Centers for ME Research and Education at MIT and
that there is no more need for heavy optimization as the SUSTech,NaverLabs,andtheAirForceOfﬁceofScientiﬁc
optimal dynamics-based solution would always be equal to Research. Video link: https://youtu.be/7 c82NYmk4Q.
411
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. REFERENCES vol.340ofLectureNotesinControlandInformationSciences,pp.65–
93,SpringerBerlinHeidelberg,2006.
[1] M.Focchi,R.Orsolino,M.Camurri,V.Barasuol,C.Mastalli,D.G. [20] H.W.Park,S.Park,andS.Kim,“Variable-speedquadrupedalbound-
Caldwell,andC.Semini,“Heuristicplanningforroughterrainloco- ingusingimpulseplanning:Untetheredhigh-speed3drunningofMIT
motion in presence of external disturbances and variable perception cheetah2,”in2015IEEEInternationalConferenceonRoboticsand
quality,”CoRR,vol.abs/1805.10238,2018. Automation(ICRA),pp.5163–5170,May2015.
[2] S. Kuindersma, R. Deits, M. Fallon, A. Valenzuela, H. Dai, F. Per- [21] J. Pratt, J. Carff, S. Drakunov, and A. Goswami, “Capture point: A
menter, T. Koolen, P. Marion, and R. Tedrake, “Optimization-based step toward humanoid push recovery,” in IEEE-RAS Int. Conf. on
locomotion planning, estimation, and control design for the atlas HumanoidRobots,(Genova,Italy),pp.200–207,Dec.2006.
humanoid robot,” Autonomous Robots, vol. 40, pp. 429–455, Mar [22] A.Wa¨chterandL.T.Biegler,“Ontheimplementationofaninterior-
2016. point ﬁlter line-search algorithm for large-scale nonlinear program-
[3] F. Farshidian, M. Neunert, A. W. Winkler, G. Rey, and J. Buchli, ming,”Math.Program.,vol.106,pp.25–57,Mar.2006.
“Anefﬁcientoptimalplanningandcontrolframeworkforquadrupedal [23] “Extracting legged locomotion heuristics with regular-
locomotion,”inICRA,2017. ized predictive control,” https://youtu.be/7c82NYmk4Q,
[4] A. W. Winkler, F. Farshidian, M. Neunert, D. Pardo, and J. Buchli, https://www.youtube.com/user/MITbiomimetics.
“Online walking motion and foothold optimization for quadruped
locomotion,” 2017 IEEE International Conference on Robotics and
Automation(ICRA),pp.5308–5313,2017.
[5] C. D. Bellicoso, F. Jenelten, C. Gehring, and M. Hutter, “Dy-
namic locomotion through online nonlinear motion optimization for
quadrupedalrobots,”no.99,2018-01-17.
[6] M. J. Powell, E. A. Cousineau, and A. D. Ames, “Model predictive
control of underactuated bipedal robotic walking,” in Proc. of the
IEEE Int. Conf. on Robotics and Automation, pp. 5121–5126, May
2015.
[7] Y. Tassa, T. Erez, and E. Todorov, “Synthesis and stabilization of
complexbehaviorsthroughonlinetrajectoryoptimization,”inProc.of
theIEEE/RSJInt.Conf.onIntelligentRobotsandSystems,pp.4906–
4913,Oct2012.
[8] M. Naveau, M. Kudruss, O. Stasse, C. Kirches, K. Mombaur, and
P. Soures, “A reactive walking pattern generator based on nonlinear
model predictive control,” IEEE Robotics and Automation Letters,
vol.2,pp.10–17,Jan2017.
[9] G. Bledt, M. J. Powell, B. Katz, J. D. Carlo, P. M. Wensing, and
S. Kim, “MIT cheetah 3: Design and control of a robust, dynamic
quadruped robot,” in Proceedings of the IEEE/RSJ International
ConferenceonIntelligentRobotsandSystems,(Madrid,Spain),Oct.
2018.
[10] J.D.Carlo,P.M.Wensing,B.Katz,G.Bledt,andS.Kim,“Dynamic
locomotion in the MIT cheetah 3 through convex model-predictive
control,” in Proceedings of the IEEE/RSJ International Conference
onIntelligentRobotsandSystems,(Madrid,Spain),Oct.2018.
[11] G. Bledt, P. M. Wensing, and S. Kim, “Policy-regularized model
predictive control to stabilize diverse quadrupedal gaits for the MIT
cheetah,” in Proceedings of the IEEE/RSJ International Conference
onIntelligentRobotsandSystems,(Vancouver,Canada),Sept.2017.
[12] G. Bledt and S. Kim, “Implementing regularized predictive control
for simultaneous real-time footstep and ground reaction force opti-
mization,”inProceedingsoftheIEEE/RSJInternationalConference
onIntelligentRobotsandSystems,(Macau,China),Nov.2019.
[13] R. Ringrose, “Automatically tuning control systems for simulated
leggedrobots,”inAAAI1994,1994.
[14] S. Chernova and M. Veloso, “An evolutionary approach to gait
learning for four-legged robots,” in 2004 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS) (IEEE Cat.
No.04CH37566),vol.3,pp.2562–2567vol.3,Sep.2004.
[15] J. D. Weingarten, G. A. D. Lopes, M. Buehler, R. E. Groff, and
D. E. Koditschek, “Automated gait adaptation for legged robots,” in
IEEE International Conference on Robotics and Automation, 2004.
Proceedings. ICRA ’04. 2004, vol. 3, pp. 2153–2158 Vol.3, April
2004.
[16] J. Hwangbo, J. Lee, A. Dosovitskiy, D. Bellicoso, V. Tsounis,
V.Koltun,andM.Hutter,“Learningagileanddynamicmotorskills
forleggedrobots,”ScienceRobotics,vol.4,no.26,2019.
[17] N.Heess,D.TB,S.Sriram,J.Lemmon,J.Merel,G.Wayne,Y.Tassa,
T.Erez,Z.Wang,S.M.A.Eslami,M.A.Riedmiller,andD.Silver,
“Emergenceoflocomotionbehavioursinrichenvironments,”CoRR,
vol.abs/1707.02286,2017.
[18] G. Bledt, P. M. Wensing, S. Ingersoll, and S. Kim, “Contact model
fusion for event-based locomotion in unstructured terrains,” in 2018
IEEEInternationalConferenceonRoboticsandAutomation(ICRA),
(Brisbane,Australia),Accepted2018.
[19] M.Diehl,H.Bock,H.Diedam,andP.-B.Wieber,“Fastdirectmultiple
shooting algorithms for optimal robot control,” in Fast Motions
in Biomechanics and Robotics (M. Diehl and K. Mombaur, eds.),
412
Authorized licensed use limited to: Carleton University. Downloaded on September 20,2020 at 15:01:06 UTC from IEEE Xplore.  Restrictions apply. 