2020 IEEE International Conference on Robotics and Automation (ICRA)
31 May - 31 August, 2020. Paris, France
Implementing Tactile and Proximity Sensing for Crack Detection
Francesca Palermo1†, Jelizaveta Konstantinova1,3, Kaspar Althoefer1,
Stefan Poslad1, Ildar Farkhatdinov1,2†
Abstract—Remote characterisation of the environment dur-
ingphysicalrobot-environmentinteractionisanimportanttask
commonly accomplished in telerobotics. This paper demon-
strates how tactile and proximity sensing can be efﬁciently
used to perform automatic crack detection. A custom-designed
integrated tactile and proximity sensor is implemented. It
measuresthedeformationofitsbodywheninteractingwiththe
physicalenvironmentanddistancetotheenvironment’sobjects
withthehelpofﬁbreoptics.Thissensorwasusedtoslideacross
differentsurfacesandthedatarecordedduringtheexperiments
wasusedtodetectandclassifycracks,bumpsandundulations.
Theproposedmethodusesmachinelearningtechniques(mean
absolute value as feature and random forest as classiﬁer) to
detect cracks and determine their width. An average crack
detectionaccuracyof86.46%andwidthclassiﬁcationaccuracy
of57.30%isachieved.Kruskal-Wallisresults(p<0.001)indicate
statisticallysigniﬁcantdifferencesamongresultsobtainedwhen Fig.1. Hybridﬁbreopticalforce/proximityﬁngertipsensor:a.schematic
analysing only force data, only proximity data and both force design of the main mechanical components; b. the tip of the sensor with
integratedﬁbreopticsbasedsensingelements.ElementsD1,D2,D3indicate
and proximity data. In contrast to previous techniques, which
thethreepairofﬁbreopticswhichrespondtothedeformationofthesofter
mainlyrelyonvisualmodality,theproposedapproachbasedon
middle part of the sensor. P corresponds to the proximity ﬁbre optical
opticalﬁbresissuitableforoperationinextremeenvironments,
sensingelement.
such as nuclear facilities in which nuclear radiation may
damage the electronic components of video cameras.
I. INTRODUCTION incorrect design or environment changes (e.g., temperature
Background. Most of commercially exploited human- or pressure). The effects of undetected fractures may lead to
machineinterfacesforteleroboticsrelyonvisualinformation larger macro-scale catastrophic failures making the cracked
to collect information on the remote environment [1], [2] surface vulnerable to strength loss.
which can be insufﬁcient in complex, dynamic and unstruc- Existing techniquesforcrackdetectionrelyonthevisual
tured environments with limited luminosity [3], [4]. It is analysis of the analysed segment [10], the implementation
especially difﬁcult to perform surface and object material of eddy current [11], in the case of metallic structures, or
characterisation when only visual feedback is available. ultrasonic techniques [12]. Chen et al. [13] propose a fusion
Hence,theintroductionofaremotetouchfeedbackmodality betweenaconvolutionalneuralnetworkandaNaiveBayesto
becomes of great importance. Tactile feedback can provide analyse video frames for crack detection in nuclear reactors.
important information about the remote environment and The proposed framework achieves a 98.3% hit rate against
substantiallyimprovetheefﬁciencyandsafetyoftelerobotics 0.1 false positives per frame. Schmugge et al. [14] suggest
tasks. Remote materials and objects characterisation is a an ofﬂine crack detection method for nuclear power plant
typical application in telerobotics: remote control of mobile inspection video recordings by ﬁne-tuning a deep neural
robots [5], [6], surgical robotics and training [7], nuclear network for detecting local patches containing cracks which
waste management and remote material handling [8], [9]. are then grouped in spatial-temporal space for group-level
An important task often performed in remote hazardous classiﬁcation which obtains an increase of 40% in the F1-
environments is the detection and characterisation of me- Score with respect to the compared methods. Liliopolus
chanical fractures of objects such as containers, tanks, pipes et al. [15] analyse the evolution of a cracking concrete
and other systems used for storing and processing chemical structure obtained by applying digital image correlation,
and radioactive waste. A surface crack may be caused by acoustic emission and ultrasonic pulse velocity techniques.
The results highlight the time of onset and location of crack
1 TheCentreforAdvancedRobotics@QueenMary(ARQ),Schoolof initiation as well as the width and depth of the cracks.
Electronic Engineering and Computer Science, Queen Mary University of
As described above existing crack detection methods are
London,London,UnitedKingdom
2DepartmentofBioengineering,ImperialCollegeofScience,Technology based on computer vision techniques and can fail in remote
andMedicine;London,UnitedKingdom. environments with limited luminosity. Furthermore, vision-
3 Robotics Research, Ofﬁce of the CTO, Ocado Technology, United
based methods are not capable of acquiring material prop-
Kingdom
†{f.palermo,i.farkhatdinov}@qmul.ac.uk erties such as texture and hardness. In contrast to the visual
978-1-7281-7395-5/20/$31.00 ©2020 IEEE 632
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. modality,tactileandproximitysensingcanprovideimportant
information on material properties such as shape, texture
andhardness[16],[17].Tactilesensorswereefﬁcientlyused
to characterise different materials in robotic teleoperation.
Liu et al. [18] developed a 6-axis force/torque ﬁnger-shaped
sensor capable of estimating the instantaneous friction force
and normal force to recognize physical properties of the
surface of unknown objects. An average classiﬁcation accu-
racyof88.5%isobtainedwhenimplementinganaïveBayes
classiﬁeron12differenttextures.Amultimodaltactilesensor
andhuman-likeexplorationstrategieshasbeenusedbyWong
et al. [19] to characterise geometry of a robot’s environment
including curvature and dimensions. An expanded tactile
sensors module has been implemented for rubber stamps
inscribedwithalphabetsletterrecognition[20].Thestiffness
of objects has been investigated [21], [22] implementing a
hybrid force and proximity ﬁnger-shaped sensor achieving
Fig.2. Theexperimentalsetupforthedataacquisitioncomposedofﬁbre
87% classiﬁcation accuracy on a set of household objects optics based sensor attached to desktop robotic interface (Touch/Phantom
with different stiffness values. An optical sensor has been Omni),Keyenceﬁbreoptictransducersandasampleobject.
implemented by Huang et al. [23] to detect target objects in
dynamicenvironmentspriortocontactallowingtheteleoper-
atortofeeltheobjectwithoutanactualcontactimprovingthe with the environment. The sensor employs three pairs of
beneﬁtsoftouchinteractiontotheoperator,withoutnegative optical ﬁbre cables (D1, D2, D3) to measure the sensor’s
consequences of the robot contacting unknown geometrical body deformation of the ﬂexible middle part based on the
structures. Surprisingly, not many approaches use tactile changes in reﬂected light intensity. The sensor is capable of
sensing for crack detection and characterisation. measuring bending torque and normal contact force during
Present work demonstrates how tactile and proximity physical interaction with the environment. The fourth pair
sensing can be efﬁciently used to perform automatic crack of optical ﬁbre cables (P) is used to sense the proximity
detection. The proposed method applies machine learning between external objects and the tip of the ﬁnger.
techniques to detect cracks and bumps based on the de- The sensor’s ﬁbre optic cables are attached to an opto-
formation and proximity signals which are recorded during electronic system to convert light intensities into voltage
physical interaction between a custom-designed robotic ﬁn- signals. In this work, Keyence FS-N11MN light-to-voltage
ger and the remote environment. In case a crack is detected, transducers 1 are implemented. Thus, the change of light
theproposedautomatedtechniquemeasureitswidth.Aﬁbre intensity modulation is measured, and, using a calibration
opticsensorhasbeenimplementedfordataacquisitiondueto matrixconvertedtoforce,torqueanddistancemeasurements.
itscompactdimensions(∼55mm),weight(∼200g),lowcost,
the strong immunity to electromagnetic interference and the
the improved environmental resistance. This approach may B. Classiﬁcation algorithm
beimplementedalsoinextremeenvironments(e.g.innuclear
The goal of the proposed classiﬁcation algorithm is to
plants), since gamma radiation does not interfere with the
detect and characterise mechanical fractures, such as cracks,
basic sensing mechanism of ﬁbre optic-based sensors [24].
based on the force and proximity data recorded from the
Tothebestoftheauthors’knowledge,thisisoneoftheﬁrst
sensors of section II-A. The time history of the force and
works on crack recognition based on hybrid ﬁbre optical
proximity data is recorded and feature extraction is per-
force and proximity sensor.
formed; the resultant output is to be used as an input for the
The paper is organized as follows. The proposed crack
classiﬁcation algorithm. Feature extraction is performed on
detection method is introduced in section II. Section III
eachconsequent25mslongtimewindowwithanincrement
describestheexperimentalmethodologyofthework.Section
of 5 ms. The size of the time window was selected based
IV introduces the results of the investigation. Section V
on the sampling frequency. Data are sampled at 400 Hz
presents the conclusions.
correspondingtoonedatasampleevery2.5ms.Thus,feature
II. CRACKDETECTIONWITHTACTILESENSING extraction is executed on windows of 10 data points with a
windowshiftoftwodatapoints.Thewindowlengthhasbeen
A. Tactile and proximity sensor
chosen empirically through grid search analysis. The Mean
In this work, an integrated force and proximity ﬁnger-
AbsoluteValue(MAV),atimedomainfeature,wasextracted
shaped sensor described in [21] is used for automatic crack
as feature. The advantage of Time Domain features is that
detection. The sensor is shown in Figure 1. The sensor is
made of 3D printed rigid (VeroClear Glossy) and ﬂexible
1https://www.keyence.com/products/sensor/
(Nylon) components allowing it to bend during interaction fiber-optic/fs-n/models/fs-n11mn/
633
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. Fig.3. Visualizationofthesetofobjectsexploredduringtheexperiments.ThetestsetfortheCrackRecognitionAnalysisisformedbynocrack,crack,
bump and wavy pattern surfaces. The series for the Crack Width classiﬁcation experiment is made up of the same surface with distinct width holes of
0,1,2,5,8and10millimetres.
theyarefasttocalculatesincetheydonotrequireanymathe- II-A,hasbeenattachedtotheend-effectorofaTouchdesktop
maticaltransformation.Ontheother hand,theyaresensitive haptic interface (formerly known as Phantom Omni) as
to noise. This feature has been previously implemented in shown in Figure 2. The Phantom Omni was programmed to
surface Electromyography (sEMG) and demonstrated high slidethetactilesensoralongastaticsamplesurfacefollowing
performance [25], [26]. A Random Forest Classiﬁer was apre-programmedperiodicmovement.Datafromtactileand
used to determine both the surface pattern of examined proximity sensors were recorded through an Arduino Mega
material and the size of the detected cracks. Random Forest ADKmicro-controllerat400Hzandlatersynchronizedwith
classiﬁer [27] uses several classiﬁcation trees to improve the theabsolutepositionofthetipofthetactilesensorcalculated
classiﬁcation rate. Each tree computes the analysis and the through the encoder readings of the Phantom Omni. Data
forest chooses the most voted result among the trees or the acquisitionandcontrolwereimplementedthroughdedicated
one with the highest classiﬁcation accuracy. Random Forest software libraries (OpenHaptics and Robotic Operating Sys-
classiﬁer has been already evaluated for remote sensing [28] tem) running on an Ubuntu desktop computer. The material
anditcansuccessfullyhandlehighdatadimensionalitysince samples, as well as the Phantom Omni interface, were
it is both fast and insensitive to overﬁtting. To recognize the staticallyﬁxedtoalaboratorydesktominimiseanyvibration
surface of the material, the classiﬁcation labels were equal and unwanted displacements.
to: ’no crack’, ’crack’, ’bump’, ’wavy texture’ (representing
B. Data acquisition protocol
an undulating surface). Additionally, one more forest tree
classiﬁerwasimplementedtoestimatethewidthofthecrack In this work, two experiments were conducted: crack
once one is detected. The same data structure and Mean detection and crack width classiﬁcation. A set of 10 objects
Absolute Value feature were used for the training of the withdifferentsurfaces(nocrack,cracksofdifferentwidths,a
crack width classiﬁer. The training labels corresponded to bumpandawavypattern)weremanufacturedemploying3D
the width of the crack in millimeters: 0, 1, 2, 5, 8, 10. Both printing technology (Ultimaker III 2, 0.2 mm layer height).
analyses have been performed with MATLAB R2018 on a The wavy pattern consists of a repeated pattern of waves of
Dell Latitude 7280 laptop running on Windows 10. 1mmamplitudeand5mmmagnitude.Thesamplesareshown
inFigure3.Eachtypeofthesesampleobjectscorrespondsto
III. EXPERIMENTALMETHODOLOGY alabelusedintheclassiﬁers.ThePhantomOmnimovedthe
tactile sensor across the sample objects: the periodic sliding
A. Setup
hasamagnitudeof1.6cmandafrequencyof1000Hz.The
Tocollectdataandtesttheproposedcrackdetectionalgo-
rithm, the tactile and proximity sensor, described in section 2https://ultimaker.com/3d-printers/ultimaker-3
634
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. TABLEI
average sliding velocity was 3.89 mm/s. The initial position
CLASSIFICATIONACCURACYFORCRACKRECOGNITION
of the tactile sensors was not controlled and varied from
trial to trial at approximately 5-10 mm from the crack edge. Feature Mean StandardDeviation
No normal force was applied by the sensor to the sampled Raw-Proximity 57.12% 3.94
MAV-Proximity 53.43% 2.57
surfaces except the force caused by the sensor’s weight.
Raw-Force 71.72% 8.80
For both classiﬁers, tactile and proximity signals from 12 MAV-Force 79.87% 8.45
repeated continuous sliding movements were recorded. This Raw-Force+Proximity 81.78% 7.33
continuous recording was reiterated ﬁve times. MAV-Force+Proximity 86.43% 7.72
C. Data Analysis TABLEII
CRACKWIDTHCLASSIFICATIONACCURACY
Figure 4 shows a sample of raw data acquired on ’no
crack’, ’crack’, ’bump’ and ’wavy surface’ for a continuous Feature Mean StandardDeviation
recording. Mean Absolute Value (MAV) feature extraction Raw-Proximity 35.08% 3.20
MAV-Proximity 31.31% 2.47
wasperformedforasliding25mswindowofeachrecorded
Raw-Force 37.81% 6.14
signal. A set of six repeated continuous sliding movements MAV-Force 45.85% 5.99
was used for training the random forest classiﬁer to detect Raw-Force+Proximity 48.94% 5.45
cracks and a separate set of six recordings was used for MAV-Force+Proximity 57.30% 6.66
testing the performance of the method after training. Hence,
50% of the data was used for testing. First, raw and MAV
of the classiﬁcation analysis of the different features and the
data are classiﬁed using only the proximity data (P) or
value obtained (p<0.001) indicates that the null hypothesis
the force data (D1, D2, D3). Then, raw and MAV data
of having all data samples from the same distribution is
with combined proximity and force data are classiﬁed. Each
rejected. Thus, there are signiﬁcant differences among the
observation is trained on itself and tested against the rest of
implemented features.
the set one at a time (e.g., observation 2 is trained on itself
andtestedagainstobservations1,3,4,and5)forintersession B. Crack Width Classiﬁcation
investigation.Intotal,20resultsforeachanalysedfeatureare
The scope of the crack width classiﬁcation experiment is
obtained. Kruskal-Wallis statistical analysis, which indicates
to classify the width in millimetres (mm) of the fracture of
if the data samples come from the same distribution, is
the explored object. Figure 6 shows the complete results for
performed on the whole set of results. The same training
the classiﬁcation analysis.
and testing approaches were used for the width detection
Table II shows that the lowest classiﬁcation accuracy of
classiﬁer.
31.31% is obtained when classifying Mean Absolute Value
data with only proximity data. Whilst, the best classiﬁcation
IV. RESULTS
accuracy of 57.30% is achieved when implementing MAV
RandomForestClassiﬁer,asupervisedlearningalgorithm, feature force data together with proximity. Nevertheless, us-
with 100 trees is implemented. First, raw and MAV data ingonlytheMAVfeature,withoutanyproximitydata,allows
with only proximity data (P) and only force data, from us to obtain results that are higher than the chance level for
the three ﬁbre optics pairs of cable (D1, D2, D3), are the considered number of labels (∼16.6%). Kruskal-Wallis
used by the classiﬁer as the baseline. Then, raw and MAV results(p<0.001)indicatestatisticallysigniﬁcantdifferences
resultswithbothforceandproximitydataareevaluated.The amongresultsobtainedwhenanalysingonlyforcedata,only
classiﬁcationalgorithmhasbeenchoseninsteadofregression proximity data and both force and proximity data.
since this work focuses on discrete labels. In the future,
regressionanalysiswillbeemployedandevaluatedforcrack V. CONCLUSION
width recognition. Thisworkdemonstratedhowtactileandproximitysensing
canbeefﬁcientlyusedtoperformautomaticcrackdetection.
A. Crack Recognition
The proposed method uses machine learning techniques to
The goal of the Crack Recognition experiment is to detect cracks and bumps based on ﬁbre optical proximity
recognize the presence of a crack in the object. Figure 5 signals which are recorded during physical interaction be-
shows the complete results for the classiﬁcation analysis. tweenacustom-designedroboticﬁngerandtheremoteenvi-
From Table I, it is possible to infer that the lowest clas- ronment. Experimental validation of the proposed method
siﬁcation accuracy of 53.43% is obtained when classifying has shown that it is possible to achieve almost 86.46%
Mean Absolute Value (MAV) data with only proximity data. crackdetectionand57%crackwidthclassiﬁcationaccuracy.
Whilst,thebestclassiﬁcationaccuracyof86.43%isachieved Kruskal-Wallisresults(p<0.001)indicatestatisticallysignif-
when implementing the MAV feature for both force and icantdifferencesamongresultsobtainedwhenanalysingonly
proximity data. Still, using only the MAV feature, without forcedata,onlyproximitydataandbothforceandproximity
anyproximitydata,allowsustoobtainresultsthatarehigher data.
than the chance level for the considered number of labels In contrast to previous techniques, which rely on visual
(25%).TheKruskal-Wallistestwasperformedontheresults modality, the proposed approach based on optical ﬁbres
635
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. Fig.4. Representationofrawdataoftheﬁbreopticalforce/proximitysensorforasetofsurfacesamples:’nocrack’,’crack’,’bump’and’wavypattern’.
Eachcolumnshowsmagnitudeoftheopticalsignalforagivenopticalﬁbresignalwhenthesensorwasdisplacedonthesamplesurface.
Fig. 5. Classiﬁcation accuracy results for the crack recognition analysis. Fig. 6. Crack width classiﬁcation accuracy results. Raw and MAV data
RawandMAVdatawithonlyproximitydataandonlyforcedataareused withonlyproximitydataandonlyforcedataareusedasbaseline.Central
as baseline. Central red mark indicates the median. The bottom and top redmarkindicatesthemedian.Thebottomandtopedgesoftheboxindicate
edges of the box indicate the 25th and 75th percentiles, respectively. The the25thand75thpercentiles,respectively.Theoutliersareshownwiththe
outliersareshownwiththesymbol’+’. symbol’+’.
is suitable for operation in extreme environments, such as foritssupportofthiswork.AlthoeferandFarkhatdinovwere
nuclear facilities where radiation damages electronic com- partially supported by the Alan Turing Institute, UK.
ponents such as video cameras.
REFERENCES
Futureresearchandapplicationswillfocusonaintegrating
[1] A. Shaukat, Y. Gao, J. A. Kuo, B. A. Bowen, and P. E. Mort,
multi-modal approach with visual patches and development
“Visualclassiﬁcationofwastematerialfornucleardecommissioning,”
ofareal-timeclassiﬁerwithbetteraccuracytorecognizethe RoboticsandAutonomousSystems,vol.75,pp.365–378,2016.
presence of a crack online and creating a 3D reconstruction [2] L.Sun,C.Zhao,Z.Yan,P.Liu,T.Duckett,andR.Stolkin,“Anovel
weakly-supervised approach for rgb-d-based nuclear waste object
of it on Unity.
detection,”IEEESensorsJournal,vol.19,no.9,pp.3487–3500,2018.
[3] D.W.Hainsworth,“Teleoperationuserinterfacesforminingrobotics,”
ACKNOWLEDGMENT AutonomousRobots,vol.11,no.1,pp.19–28,2001.
[4] M. Tavakoli, A. Aziminejad, R. V. Patel, and M. Moallem, “High-
ﬁdelity bilateral teleoperation systems and the effect of multimodal
The authors would like to thank the National Centre for
haptics,”IEEETransactionsonSystems,Man,andCybernetics,Part
NuclearRobotics(UKEPSRCgrantNCNREP/R02572X/1) B(Cybernetics),vol.37,no.6,pp.1512–1528,2007.
636
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. [5] Q.LinandC.Kuo,“Onapplyingvirtualrealitytounderwaterrobot [17] T.P.Tomo,S.Somlor,A.Schmitz,L.Jamone,W.Huang,H.Kristanto,
tele-operation and pilot training,” International Journal of Virtual andS.Sugano,“Designandcharacterizationofathree-axishalleffect-
Reality(IJVR),vol.5,no.1,pp.71–91,2015. basedsoftskinsensor,”Sensors,vol.16,no.4,p.491,2016.
[6] I. Farkhatdinov, J.-H. Ryu, and J. Poduraev, “Control strategies and [18] H.Liu,X.Song,J.Bimbo,L.Seneviratne,andK.Althoefer,“Surface
feedback information in mobile robot teleoperation,” IFAC Proceed- material recognition through haptic exploration using an intelligent
ingsVolumes,vol.41,no.2,pp.14681–14686,2008. contact sensing ﬁnger,” in 2012 IEEE/RSJ International Conference
[7] A.M.Okamura,“Methodsforhapticfeedbackinteleoperatedrobot- onIntelligentRobotsandSystems. IEEE,2012,pp.52–57.
assistedsurgery,”IndustrialRobot:AnInternationalJournal,vol.31, [19] R.D.P.Wong,R.B.Hellman,andV.J.Santos,“Hapticexplorationof
no.6,pp.499–508,2004. ﬁngertip-sized geometric features using a multimodal tactile sensor,”
[8] K. A. Manocha, N. Pernalete, and R. V. Dubey, “Variable position in Next-Generation Robots and Systems, vol. 9116. International
mapping based assistance in teleoperation for nuclear cleanup,” in SocietyforOpticsandPhotonics,2014,p.911605.
Robotics and Automation, 2001. Proceedings 2001 ICRA. IEEE In- [20] H.-K.Lee,S.-I.Chang,andE.Yoon,“Aﬂexiblepolymertactilesen-
ternationalConferenceon,vol.1. IEEE,2001,pp.374–379. sor:Fabricationandmodularexpandabilityforlargeareadeployment,”
[9] V.Pruks,I.Farkhatdinov,andJ.-H.Ryu,“Preliminarystudyonreal- Journalofmicroelectromechanicalsystems,vol.15,no.6,pp.1681–
timeinteractivevirtualﬁxturegenerationmethodforsharedteleoper- 1686,2006.
ation in unstructured environments,” in International Conference on [21] J.Konstantinova,G.Cotugno,A.Stilli,Y.Noh,andK.Althoefer,“Ob-
Human Haptic Sensing and Touch Enabled Computer Applications. jectclassiﬁcationusinghybridﬁberopticalforce/proximitysensor,”in
Springer,2018,pp.648–659. 2017IEEESENSORS. IEEE,2017,pp.1–3.
[10] A.MohanandS.Poobal,“Crackdetectionusingimageprocessing:A [22] J. Konstantinova, A. Stilli, and K. Althoefer, “Fingertip ﬁber optical
criticalreviewandanalysis,”AlexandriaEngineeringJournal,vol.57, tactilearraywithtwo-levelspringstructure,”Sensors,vol.17,no.10,
no.2,pp.787–798,2018. p.2337,2017.
[23] K. Huang, P. Lancaster, J. R. Smith, and H. J. Chizeck, “Visionless
[11] Y. Yao, S.-T. E. Tung, and B. Glisic, “Crack detection and charac-
tele-exploration of 3d moving objects,” in 2018 IEEE International
terization techniques—an overview,” Structural Control and Health
ConferenceonRoboticsandBiomimetics(ROBIO). IEEE,2018,pp.
Monitoring,vol.21,no.12,pp.1387–1413,2014.
2238–2244.
[12] Y.Chang,Y.Zi,J.Zhao,Z.Yang,W.He,andH.Sun,“Anadaptive
[24] F.Berghmans,A.F.Fernandez,B.Brichard,F.Vos,M.C.Decreton,
sparsedeconvolutionmethodfordistinguishingtheoverlappingechoes
A. I. Gusarov, O. Deparis, P. Megret, M. Blondel, S. Caron et al.,
of ultrasonic guided waves for pipeline crack inspection,” Measure-
“Radiationhardnessofﬁberopticsensorsformonitoringandremote
mentScienceandTechnology,vol.28,no.3,p.035002,2017.
handlingapplicationsinnuclearenvironments,”inProcessMonitoring
[13] F.-C.ChenandM.R.Jahanshahi,“Nb-cnn:deeplearning-basedcrack
with Optical Fibers and Harsh Environment Sensors, vol. 3538.
detection using convolutional neural network and naïve bayes data
InternationalSocietyforOpticsandPhotonics,1999,pp.28–39.
fusion,” IEEE Transactions on Industrial Electronics, vol. 65, no. 5,
[25] M. Hakonen, H. Piitulainen, and A. Visala, “Current state of digital
pp.4392–4400,2017.
signal processing in myoelectric interfaces and related applications,”
[14] S. J. Schmugge, L. Rice, N. R. Nguyen, J. Lindberg, R. Grizzi,
BiomedicalSignalProcessingandControl,vol.18,pp.334–359,2015.
C.Joffe,andM.C.Shin,“Detectionofcracksinnuclearpowerplant
[26] F. Palermo, M. Cognolato, A. Gijsberts, H. Müller, B. Caputo, and
usingspatial-temporalgroupingoflocalpatches,”in2016IEEEWinter
M.Atzori,“Repeatabilityofgrasprecognitionforrobotichandpros-
ConferenceonApplicationsofComputerVision(WACV). IEEE,2016,
thesiscontrolbasedonsemgdata,”in2017InternationalConference
pp.1–7.
onRehabilitationRobotics(ICORR). IEEE,2017,pp.1154–1159.
[15] S. Iliopoulos, D. Aggelis, L. Pyl, J. Vantomme, P. Van Marcke,
[27] L.Breiman,“Randomforests,”Machinelearning,vol.45,no.1,pp.
E.Coppens,andL.Areias,“Detectionandevaluationofcracksinthe
5–32,2001.
concretebufferofthebelgiannuclearwastecontainerusingcombined
[28] M.BelgiuandL.Dra˘gu¸t,“Randomforestinremotesensing:Areview
ndt techniques,” Construction and Building Materials, vol. 78, pp.
of applications and future directions,” ISPRS Journal of Photogram-
369–378,2015.
metryandRemoteSensing,vol.114,pp.24–31,2016.
[16] Z. Kappassov, J.-A. Corrales, and V. Perdereau, “Tactile sensing in
dexterous robot hands,” Robotics and Autonomous Systems, vol. 74,
pp.195–220,2015.
637
Authorized licensed use limited to: UNIVERSITY OF ROCHESTER. Downloaded on September 20,2020 at 15:47:19 UTC from IEEE Xplore.  Restrictions apply. 