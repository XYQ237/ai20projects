10.31第一阶段汇报

刘睿衡 2018202200

1.总概

从国庆节确定选题到10.30第三次汇报，其实中间时间并不长。加上我们小组（李浩铭2018202186 郭泳雨2018202188 刘睿衡2018202200）的选题是搞小车，买东西快递就花了不少时间，中间还有硬件问题不得已退货重发，一直到第二周（10.21）才拿到最终的车子。自知出师不利的我们组在第三周加班加点研究代码，风餐露宿夜以继日悬梁刺股，终于是基本搞定了小车的运行方式，并尝试了硬件系统（蜂鸣、红外、声波等）提供的寻路等功能，在最后加入摄像头捕捉图像，初步实现了黑色轨迹带的识别，并根据布置好的水电黑胶带道路实现寻路。当然，摄像头应用远不止于此，接下来我们将把麦克风和摄像头结合，实现没有提前设置的自动驾驶、语音控制、自动跟踪导航等。

2.关于选题的二三事

我作为本组代表第一次去展示的时候，我们讨论设计方案是无人机飞行控制。后来经过专家（包括但不限于西安交通大学、北京航空航天大学专门搞机械的同学）提示，飞行控制涉及复杂物理与机械知识，如果不使用现成控制库将是十分复杂的问题。于是我们决定发挥自己长处，转向应用控制，用视频流、音频流等控制移动。经过资料查询我们得知，无人机控制要求精确，太便宜的视频音频传输装置会产生高延迟与高误差，在飞行中是致命的。因此我们选择了小车，车辆对于环境安全要求要比飞机低的多，能够允许比较大的误差与网络延迟，可以满足我们的实验要求。

3.车辆远程控制

车辆由树莓派芯片实现控制。在树莓派的配置上，我们比较大方的安装了4G内存，舍弃了其原装的比较辣鸡的系统，找了个更好用更完善的Ubuntu16.04发行版进行重装烧制。当然发行版并不是专业的机器人开发操作系统，里面甚至有扫雷等游戏，给整个系统部署初期带来了不小的麻烦。但发行版有比较好用的WIFI连接，设置为自动连接后就能够直接与路由器配对，绕开了原本十分麻烦的连接配对，能够十分方便的在电脑上调试代码，并以路由器搭建本地网络传输到Ubuntu上对小车进行控制。利用远程桌面VNC我们能够直观的操作小车的Ubuntu系统，利用Ubuntu自带的视频、音频处理模块我们能够顺利处理通过摄像头、麦克风传输的流文件，实现了小车的远程控制。

4.车辆基本驾驶

车辆移动由GPIO库进行了封装，直接操作电机命令转动，四个轮子分别控制转动以实现车辆的前进后退与转向

    def t_up(speed,t_time):
        L_Motor.ChangeDutyCycle(speed)
        GPIO.output(AIN2,False)#AIN2
        GPIO.output(AIN1,True) #AIN1

        R_Motor.ChangeDutyCycle(speed)
        GPIO.output(BIN2,False)#BIN2
        GPIO.output(BIN1,True) #BIN1
        time.sleep(t_time)
给定移动速度与持续时间，就能够实现基本移动操作

    try:
    while True:
        t_up(50,3)
        t_down(50,3)
        t_left(50,3)
        t_right(50,3)
        t_stop(3)


5.硬件控制

车辆提供了一些硬件功能，例如红外与蜂鸣器，能够实现一些基本的硬件级别的交互与智能。例如蜂鸣器，能够通过设置其振动频率来达到发出不同的音符的目的：

    song_1 = [	CM[3], CM[5], CM[6], CM[3], CM[2], CM[3], CM[5], CM[6],			
    CH[1], CM[6], CM[5], CM[1], CM[3], CM[2], CM[2], CM[3], 
	CM[5], CM[2], CM[3], CM[3], CL[6], CL[6], CL[6], CM[1],
	CM[2], CM[3], CM[2], CL[7], CL[6], CM[1], CL[5]	]

这里对底层的振动频率进行了封装，CM、CH、CL分别对应中音高音低音，而后面的数字则为音高。

同样的，红外控制也是通过底层硬件接口实现的。用的BOARD编码方式
    
    GPIO.setup(PWMA,GPIO.OUT)
    GPIO.setup(PWMB,GPIO.OUT)
    L_Motor= GPIO.PWM(PWMA,100)
    L_Motor.start(0)
    R_Motor = GPIO.PWM(PWMB,100)
    R_Motor.start(0)
这里设置两个红外控制接口，PWMA和PWMB，红外怎么控制的我们不得而知，如果是STM32的主板就得自己调波长，这里GPIO就这么点控制代码，后台已经实现了避障。

6.视觉寻迹

这是我们组针对视频流的第一个操作实验，也算是最简单的一组实验。这里利用摄像头传回的流信息，对每一帧图像进行分析，找到对应颜色色块（这里默认是黑色），计算色块中心位置，与之前进行对比，确定路径轨迹，尽可能保证路径中点始终在屏幕中间。

    gray = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray,(5,5),0)
调用opencv2，调节颜色设置

    cx = int(M['m10']/M['m00'])
    cy = int(M['m01']/M['m00'])
        
    cv2.line(crop_img,(cx,0),(cx,720),(255,0,0),1)
    cv2.line(crop_img,(0,cy),(1280,cy),(255,0,0),1)
        
    cv2.drawContours(crop_img, contours, -1, (0,255,0), 1)
cx与cy定义了图像灰度维度，并在最后调用drawcontour函数来实现控制。

经过我们的测试，在寝室中用电工黑胶带铺了一条路，小车在没有干扰的情况下能够做到寻迹。不足的是，图像传输延迟较大，因此车速无法设置的过快。车速过快就会出现原地空转的情况。同时，限于摄像头像素限制，无法拍摄高精度图片，我们在实验中出现了opencv将人的影子识别成了路径，造成了中心点计算混乱的情况。我们调整了灰度识别参数，如果直接调255识别纯黑又会出现识别不到图像的情况。总之我们认为这是设备问题。

7.未来规划

下一次我们打算调试麦克风的语音功能，用语音控制车辆；进一步的，将语音控制与摄像头结合进行自动导航。

更复杂的内容我们在之后再进行研究吧。