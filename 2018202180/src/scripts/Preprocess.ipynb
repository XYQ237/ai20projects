{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('nn': conda)",
   "display_name": "Python 3.7.9 64-bit ('nn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9616ec0cf0e0dd041cba3c8886d471a5cc72bbf20e2c795f4079199200777fdd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.MIND import MIND_iter,MIND_map\n",
    "from utils.utils import constructBasicDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'mode':'demo',\n",
    "    'batch_size':2,\n",
    "    'his_size':2,\n",
    "    'title_size':18,\n",
    "    'gpu':'cuda:0',\n",
    "    'attrs': ['title','category','subcategory']\n",
    "}\n",
    "\n",
    "# customize your path here\n",
    "\n",
    "news_file_train = 'D:/Data/NR_data/dev/news_train.tsv'\n",
    "news_file_test = 'D:/Data/NR_data/dev/news_test.tsv'\n",
    "behavior_file_train = 'D:/Data/NR_data/dev/behaviors_train.tsv'\n",
    "behavior_file_test = 'D:/Data/NR_data/dev/behaviors_test.tsv'\n",
    "\n",
    "# if user2id,word2id,news2id haven't been constructed\n",
    "if not os.path.exists('data/nid2idx_{}_{}.json'.format(hparams['mode'],'train')):\n",
    "    constructBasicDict(news_file_train,behavior_file_train,hparams['mode'],'train',hparams['attrs'])\n",
    "\n",
    "if not os.path.exists('data/nid2idx_{}_{}.json'.format(hparams['mode'],'test')):\n",
    "    constructBasicDict(news_file_test,behavior_file_test,hparams['mode'],'test',hparams['attrs'])\n",
    "\n",
    "device = torch.device(hparams['gpu']) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# map style dataloader to return one log for training\n",
    "dataset_train = MIND_map(hparams=hparams,mode='train',npratio=4,news_file=news_file_train,behaviors_file=behavior_file_train)\n",
    "\n",
    "# iter style dataloader to return one candidate for evaluating\n",
    "dataset_test = MIND_iter(hparams=hparams,mode='test',news_file=news_file_test,behaviors_file=behavior_file_test)\n",
    "\n",
    "vocab_train = dataset_train.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab_train.load_vectors(embedding)\n",
    "\n",
    "vocab_test = dataset_test.vocab\n",
    "vocab_test.load_vectors(embedding)\n",
    "\n",
    "loader_train = DataLoader(dataset_train,batch_size=hparams['batch_size'],shuffle=True,pin_memory=True,num_workers=3)\n",
    "loader_test = DataLoader(dataset_test,batch_size=hparams['batch_size'],pin_memory=True,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(loader_train))\n",
    "b = next(iter(loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'user_index': tensor([[ 727],\n",
       "          [1389]], dtype=torch.int32),\n",
       "  'clicked_title': tensor([[[ 6262,  4554,     6,    71,    30,    40,  5749,  3524, 26295,  3525,\n",
       "               21,     8,   482,     0,     0,     0,     0,     0],\n",
       "           [  814,   906,  2632,    65,    36,    74,  3988,  2892,   716,  1135,\n",
       "                9,  5183,    14,   948,     0,     0,     0,     0]],\n",
       "  \n",
       "          [[    8,  2051,  4245,     9,  4381,  2441,     5,  2892,  8924,  5667,\n",
       "              519,     0,     0,     0,     0,     0,     0,     0],\n",
       "           [  317,    71,   192,  5430,    47,   144,    80,   845,    10,   331,\n",
       "                0,     0,     0,     0,     0,     0,     0,     0]]],\n",
       "         dtype=torch.int32),\n",
       "  'clicked_category': tensor([[[26],\n",
       "           [24]],\n",
       "  \n",
       "          [[26],\n",
       "           [ 3]]], dtype=torch.int32),\n",
       "  'clicked_subcategory': tensor([[[122],\n",
       "           [343]],\n",
       "  \n",
       "          [[321],\n",
       "           [ 13]]], dtype=torch.int32),\n",
       "  'candidate_title': tensor([[[  814,   906,    17,   716,  1135,   179,  3088,    14,   350,   202,\n",
       "             1084,   688,    10,   386,  5555,    18,    64,  7424],\n",
       "           [    8,  1140,   714,     9,   128,   162,   306,  2339,     8,    70,\n",
       "             3634,   714,   481,    40,   830,     0,     0,     0],\n",
       "           [ 1278,  1315,   296,   371,  1279,    18, 15358,   659,   120,     6,\n",
       "               66,   685,     6,  8861, 13334,     0,     0,     0],\n",
       "           [  107,  3475,  2171,   694,    48, 29304, 21792,  2975,     0,     0,\n",
       "                0,     0,     0,     0,     0,     0,     0,     0],\n",
       "           [  153,   929,     5,   226,   147,   436,  2965,   818,    38,     9,\n",
       "              537,  1003,     5,  9812,     0,     0,     0,     0]],\n",
       "  \n",
       "          [[ 7049,   762,     9,  1675,    10,   168,  1793,     6,  2101,   473,\n",
       "             4936,    11,   984,    40,   830,     0,     0,     0],\n",
       "           [10852,   162,   737,  2451,   462,   358,  1400,     7,  2647,   754,\n",
       "             9673,    11,   462,     9,    92,     0,     0,     0],\n",
       "           [   52,   300,   585,   887,   587,     7,   273,     0,     0,     0,\n",
       "                0,     0,     0,     0,     0,     0,     0,     0],\n",
       "           [ 8982,     6,  3068,     6,   235,    58,  3892,   149,  5384,  6659,\n",
       "              201,  1205,    56,  6740,    65,     7,     8,  3844],\n",
       "           [  604,    71,  3851,     7,     8,   849,     0,     0,     0,     0,\n",
       "                0,     0,     0,     0,     0,     0,     0,     0]]],\n",
       "         dtype=torch.int32),\n",
       "  'candidate_category': tensor([[[ 24],\n",
       "           [ 22],\n",
       "           [ 22],\n",
       "           [  3],\n",
       "           [ 24]],\n",
       "  \n",
       "          [[ 66],\n",
       "           [  3],\n",
       "           [  3],\n",
       "           [ 22],\n",
       "           [135]]], dtype=torch.int32),\n",
       "  'candidate_subcategory': tensor([[[ 343],\n",
       "           [ 182],\n",
       "           [ 141],\n",
       "           [  39],\n",
       "           [  85]],\n",
       "  \n",
       "          [[ 208],\n",
       "           [  13],\n",
       "           [  23],\n",
       "           [4241],\n",
       "           [ 734]]], dtype=torch.int32),\n",
       "  'labels': tensor([[1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0]], dtype=torch.int32)},\n",
       " {'impression_index': tensor([0, 0]),\n",
       "  'user_index': tensor([[1],\n",
       "          [1]], dtype=torch.int32),\n",
       "  'clicked_title': tensor([[[ 4357,    10,  3816,  4712,  2547,  1900,     6,   124,     8,  7388,\n",
       "            12463,     0,     0,     0,     0,     0,     0,     0],\n",
       "           [  689,   650,   609,    31,  1099,  1314,   150,  1415,  7890,  3029,\n",
       "                7,     0,     0,     0,     0,     0,     0,     0]],\n",
       "  \n",
       "          [[ 4357,    10,  3816,  4712,  2547,  1900,     6,   124,     8,  7388,\n",
       "            12463,     0,     0,     0,     0,     0,     0,     0],\n",
       "           [  689,   650,   609,    31,  1099,  1314,   150,  1415,  7890,  3029,\n",
       "                7,     0,     0,     0,     0,     0,     0,     0]]],\n",
       "         dtype=torch.int32),\n",
       "  'clicked_category': tensor([[[61],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[61],\n",
       "           [ 3]]], dtype=torch.int32),\n",
       "  'clicked_subcategory': tensor([[[200],\n",
       "           [ 13]],\n",
       "  \n",
       "          [[200],\n",
       "           [ 13]]], dtype=torch.int32),\n",
       "  'candidate_title': tensor([[[ 259, 6983,    5, 1321, 1349,    6,  293, 1009,  728,    9, 4381,\n",
       "            6896,    0,    0,    0,    0,    0,    0]],\n",
       "  \n",
       "          [[  73,  527,  305, 5209,   65, 1438,  435,   11,   14,  174,   17,\n",
       "             768, 2668,   98, 5415,    7,   14, 1762]]], dtype=torch.int32),\n",
       "  'candidate_category': tensor([[[ 4]],\n",
       "  \n",
       "          [[25]]], dtype=torch.int32),\n",
       "  'candidate_subcategory': tensor([[[ 15]],\n",
       "  \n",
       "          [[488]]], dtype=torch.int32),\n",
       "  'labels': tensor([[0],\n",
       "          [0]], dtype=torch.int32)})"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tailor Data to demo size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailorData('D:/Data/NR_data/MINDsmall_dev/behaviors.tsv',300)\n",
    "tailorData('D:/Data/NR_data/MINDsmall_train/behaviors.tsv',300)"
   ]
  }
 ]
}